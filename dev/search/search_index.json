{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Rattler-Build","text":""},{"location":"#rattler-build-a-fast-conda-package-builder","title":"rattler-build: a fast conda-package builder","text":"<p>The <code>rattler-build</code> tooling and library creates cross-platform relocatable binaries / packages from a simple recipe format. The recipe format is heavily inspired by <code>conda-build</code> and <code>boa</code>, and the output of a regular <code>rattler-build</code> run is a package that can be installed using <code>mamba</code>, <code>rattler</code> or <code>conda</code>.</p> <p><code>rattler-build</code> does not have any dependencies on <code>conda-build</code> or <code>Python</code> and works as a standalone binary.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can grab a prerelease version of <code>rattler-build</code> from the Github Releases.</p> <p>It is (of course) also available from conda-forge:</p> <pre><code>pixi global install rattler-build\n# or with micromamba\nmicromamba install rattler-build -c conda-forge\n</code></pre> <p>Alternatively, you can install <code>rattler-build</code> via Homebrew:</p> <pre><code>brew install rattler-build\n</code></pre>"},{"location":"#dependencies","title":"Dependencies","text":"<p>Currently <code>rattler-build</code> needs some dependencies on the host system which are executed as subprocess. We plan to reduce the number of external dependencies over time by writing what we need in Rust to make <code>rattler-build</code> fully self-contained.</p> <ul> <li><code>tar</code> to unpack tarballs downloaded from the internet in a variety of formats.   <code>.gz</code>, <code>.bz2</code> and <code>.xz</code> are widely used and one might have to install the   compression packages as well (e.g. <code>gzip</code>, <code>bzip2</code>, ...)</li> <li><code>patch</code> to patch source code after downloading</li> <li><code>install_name_tool</code> is necessary on macOS to rewrite the <code>rpath</code> of shared   libraries and executables to make it relative</li> <li><code>patchelf</code> is required on Linux to rewrite the <code>rpath</code> and <code>runpath</code> of shared   libraries and executables</li> <li><code>git</code> to checkout Git repositories (not implemented yet, but will require git   in the future)</li> <li><code>msvc</code> on Windows because we cannot ship the MSVC compiler on conda-forge   (needs to be installed on the host machine)</li> </ul> <p>On Windows, to obtain these dependencies from conda-forge, one can install <code>m2-patch</code>, <code>m2-bzip2</code>, <code>m2-gzip</code>, <code>m2-tar</code>.</p>"},{"location":"#usage","title":"Usage","text":"<p><code>rattler-build</code> comes with three commands: <code>build</code>, <code>test</code> and <code>rebuild</code>.</p> <p>The <code>build</code> command takes a <code>--recipe recipe.yaml</code> as input and produces a package as output. The <code>test</code> subcommand can be used to test existing packages (tests are shipped with the package).</p> <p>The <code>rebuild</code> command can be used to attempt a reproducible rebuild of an existing package.</p>"},{"location":"#the-recipe-format","title":"The recipe format","text":"<p>Note You can find all examples below in the <code>examples</code> folder and run them with <code>rattler-build</code>.</p> <p>A simple example recipe for the <code>xtensor</code> header-only C++ library:</p> <pre><code>context:\n  name: xtensor\n  version: 0.24.6\n  sha256: f87259b51aabafdd1183947747edfff4cff75d55375334f2e81cee6dc68ef655\n\npackage:\n  name: ${{ name|lower }}\n  version: ${{ version }}\n\nsource:\n  url: https://github.com/xtensor-stack/xtensor/archive/${{ version }}.tar.gz\n  sha256: ${{ sha256 }}\n\nbuild:\n  number: 0\n  # note: in the new recipe format, `skip` is a list of conditional expressions\n  #       but for the \"YAML format\" discussion we pretend that we still use the\n  #       `skip: bool` syntax\n  skip: ${{ true if (win and vc14) }}\n  script:\n    - if: win\n      then: |\n        cmake -G \"NMake Makefiles\" -D BUILD_TESTS=OFF -D CMAKE_INSTALL_PREFIX=%LIBRARY_PREFIX% %SRC_DIR%\n        nmake\n        nmake install\n      else: |\n        cmake ${CMAKE_ARGS} -DBUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=$PREFIX $SRC_DIR -DCMAKE_INSTALL_LIBDIR=lib\n        make install\n\nrequirements:\n  build:\n    - ${{ compiler('cxx') }}\n    - cmake\n    - if: unix\n      then: make\n  host:\n    - xtl &gt;=0.7,&lt;0.8\n  run:\n    - xtl &gt;=0.7,&lt;0.8\n  run_constrained:\n    - xsimd &gt;=8.0.3,&lt;10\n\ntests:\n  - script:\n    - if: unix or emscripten\n      then:\n        - test -d ${PREFIX}/include/xtensor\n        - test -f ${PREFIX}/include/xtensor/xarray.hpp\n        - test -f ${PREFIX}/share/cmake/xtensor/xtensorConfig.cmake\n        - test -f ${PREFIX}/share/cmake/xtensor/xtensorConfigVersion.cmake\n    - if: win\n      then:\n        - if not exist %LIBRARY_PREFIX%\\include\\xtensor\\xarray.hpp (exit 1)\n        - if not exist %LIBRARY_PREFIX%\\share\\cmake\\xtensor\\xtensorConfig.cmake (exit 1)\n        - if not exist %LIBRARY_PREFIX%\\share\\cmake\\xtensor\\xtensorConfigVersion.cmake (exit 1)\n\nabout:\n  homepage: https://github.com/xtensor-stack/xtensor\n  license: BSD-3-Clause\n  license_file: LICENSE\n  summary: The C++ tensor algebra library\n  description: Multi dimensional arrays with broadcasting and lazy computing\n  documentation: https://xtensor.readthedocs.io\n  repository: https://github.com/xtensor-stack/xtensor\n\nextra:\n  recipe-maintainers:\n    - some-maintainer\n</code></pre>      A recipe for the `rich` Python package (using `noarch`)    <pre><code>context:\n  version: \"13.4.2\"\n\npackage:\n  name: \"rich\"\n  version: ${{ version }}\n\nsource:\n  - url: https://pypi.io/packages/source/r/rich/rich-${{ version }}.tar.gz\n    sha256: d653d6bccede5844304c605d5aac802c7cf9621efd700b46c7ec2b51ea914898\n\nbuild:\n  # Thanks to `noarch: python` this package works on all platforms\n  noarch: python\n  script:\n    - python -m pip install . -vv --no-deps --no-build-isolation\n\nrequirements:\n  host:\n    - pip\n    - poetry-core &gt;=1.0.0\n    - python 3.10\n  run:\n    # sync with normalized deps from poetry-generated setup.py\n    - markdown-it-py &gt;=2.2.0\n    - pygments &gt;=2.13.0,&lt;3.0.0\n    - python 3.10\n    - typing_extensions &gt;=4.0.0,&lt;5.0.0\n\ntests:\n  - python:\n      imports:\n        - rich\n      pip_check: true\n\nabout:\n  homepage: https://github.com/Textualize/rich\n  license: MIT\n  license_file: LICENSE\n  summary: Render rich text, tables, progress bars, syntax highlighting, markdown and more to the terminal\n  description: |\n    Rich is a Python library for rich text and beautiful formatting in the terminal.\n\n    The Rich API makes it easy to add color and style to terminal output. Rich\n    can also render pretty tables, progress bars, markdown, syntax highlighted\n    source code, tracebacks, and more \u2014 out of the box.\n  documentation: https://rich.readthedocs.io\n  repository: https://github.com/Textualize/rich\n</code></pre> A recipe for the `curl` library <pre><code>context:\n  version: \"8.0.1\"\n\npackage:\n  name: curl\n  version: ${{ version }}\n\nsource:\n  url: http://curl.haxx.se/download/curl-${{ version }}.tar.bz2\n  sha256: 9b6b1e96b748d04b968786b6bdf407aa5c75ab53a3d37c1c8c81cdb736555ccf\n\nbuild:\n  number: 0\n\nrequirements:\n  build:\n    - ${{ compiler('c') }}\n    - if: win\n      then:\n        - cmake\n        - ninja\n    - if: unix\n      then:\n        - make\n        - perl\n        - pkg-config\n        - libtool\n  host:\n    - if: linux\n      then:\n        - openssl\n\nabout:\n  homepage: http://curl.haxx.se/\n  license: MIT/X derivate (http://curl.haxx.se/docs/copyright.html)\n  license_file: COPYING\n  summary: tool and library for transferring data with URL syntax\n  description: |\n    Curl is an open source command line tool and library for transferring data\n    with URL syntax. It is used in command lines or scripts to transfer data.\n  documentation: https://curl.haxx.se/docs/\n  repository: https://github.com/curl/curl\n</code></pre>  For this recipe, two additional script files (`build.sh` and `build.bat`) are needed.  **build.sh**  <pre><code>#!/bin/bash\n\n# Get an updated config.sub and config.guess\ncp $BUILD_PREFIX/share/libtool/build-aux/config.* .\n\nif [[ $target_platform =~ linux.* ]]; then\n    USESSL=\"--with-openssl=${PREFIX}\"\nelse\n    USESSL=\"--with-secure-transport\"\nfi;\n\n./configure \\\n    --prefix=${PREFIX} \\\n    --host=${HOST} \\\n    ${USESSL} \\\n    --with-ca-bundle=${PREFIX}/ssl/cacert.pem \\\n    --disable-static --enable-shared\n\nmake -j${CPU_COUNT} ${VERBOSE_AT}\nmake install\n\n# Includes man pages and other miscellaneous.\nrm -rf \"${PREFIX}/share\"\n</code></pre>  **build.bat**  <pre><code>mkdir build\n\ncmake -GNinja ^\n      -DCMAKE_BUILD_TYPE=Release ^\n      -DBUILD_SHARED_LIBS=ON ^\n      -DCMAKE_INSTALL_PREFIX=%LIBRARY_PREFIX% ^\n      -DCMAKE_PREFIX_PATH=%LIBRARY_PREFIX% ^\n      -DCURL_USE_SCHANNEL=ON ^\n      -DCURL_USE_LIBSSH2=OFF ^\n      -DUSE_ZLIB=ON ^\n      -DENABLE_UNICODE=ON ^\n      %SRC_DIR%\n\nIF %ERRORLEVEL% NEQ 0 exit 1\n\nninja install --verbose\n</code></pre>"},{"location":"automatic_linting/","title":"Automatic linting in VSCode","text":"<p>The new recipe format comes with a strict JSON scheme. You can find the scheme in this repository.</p> <p>It's implemented with <code>pydantic</code> and renders to a JSON schema file. The YAML language server extension in VSCode can recognize the scheme and give helpful hints during editing.</p> <p>With the YAML language server installed the automatic linting can be enabled by adding the following line to the top of the recipe file:</p> <pre><code># yaml-language-server: $schema=https://raw.githubusercontent.com/prefix-dev/recipe-format/main/schema.json\n</code></pre>"},{"location":"available_jinja/","title":"Jinja functions that can be used in the recipe","text":"<p><code>rattler-build</code> comes with a couple of useful helpers that can be used in the recipe.</p> <ul> <li><code>${{ compiler('c') }}</code></li> <li><code>${{ pin_subpackage(\"mypkg\", min_pin=\"x.x\", max_pin=\"x.x.x\") }}</code> creates a pin to another output in the recipe.</li> </ul> <ul> <li><code>${{ hash }}</code> this is the variant hash and is useful in the build string computation</li> <li><code>${{ python | version_to_buildstring }}</code> converts a version from the variant to a build string (removes <code>.</code> and takes only the first two elements of the version).</li> <li>default jinja filters are available: <code>lower</code>, <code>upper</code>, indexing into characters: <code>https://myurl.com/{{ name[0] }}/{{ name | lower }}_${{ version }}.tar.gz</code>.   A list of all the builtin filters can be found under: Link</li> </ul>"},{"location":"build_script/","title":"Build scripts","text":"<p>The <code>build.sh</code> file is the build script for Linux and macOS and <code>build.bat</code> is the build script for Windows. These scripts contain the logic that carries out your build steps. Anything that your build script copies into the <code>$PREFIX</code> or <code>%PREFIX%</code> folder will be included in your output package.</p> <p>For example, this <code>build.sh</code>:</p> <pre><code>mkdir -p $PREFIX/bin\ncp $RECIPE_DIR/my_script_with_recipe.sh $PREFIX/bin/super-cool-script.sh\n</code></pre> <p>There are many environment variables defined for you to use in build.sh and build.bat. Please see environment variables for more information.</p> <p><code>build.sh</code> and <code>build.bat</code> are optional. You can instead use the <code>build/script</code> key in your <code>recipe.yaml</code>, with each value being either a string command or a list of string commands. Any commands you put there must be able to run on every platform for which you build. For example, you can't use the <code>cp</code> command because <code>cmd.exe</code> won't understand it on Windows.</p> <p><code>build.sh</code> is run with <code>bash</code> and <code>build.bat</code> is run with <code>cmd.exe</code>.</p>"},{"location":"build_script/#environment-variables","title":"Environment variables","text":""},{"location":"build_script/#environment-variables-set-during-the-build-process","title":"Environment variables set during the build process","text":"<p>During the build process, the following environment variables are set, on Windows with <code>build.bat</code> and on macOS and Linux with <code>build.sh</code>. By default, these are the only variables available to your build script. Unless otherwise noted, no variables are inherited from the shell environment in which you invoke <code>conda-build</code>. To override this behavior, see :ref:<code>inherited-env-vars</code>.</p> <code>ARCH</code> Either <code>32</code> or <code>64</code>, to specify whether the build is 32-bit or 64-bit. The value depends on the ARCH environment variable and defaults to the architecture the interpreter running conda was compiled with. <code>CMAKE_GENERATOR</code> The CMake generator string for the current build environment. On Linux systems, this is always <code>Unix Makefiles</code>. On Windows, it is generated according to the Visual Studio version activated at build time, for example, <code>Visual Studio 9 2008 Win64</code>. <code>CONDA_BUILD=1</code> Always set to indicate that the conda-build process is running. <code>CPU_COUNT</code> Represents the number of CPUs on the system. <code>SHLIB_EXT</code> Denotes the shared library extension specific to the operating system (e.g., .so for Linux, .dylib for macOS, and .dll for Windows). <code>HTTP_PROXY</code> Inherited from the user's shell environment, specifying the HTTP proxy settings. <code>HTTPS_PROXY</code> Similar to HTTP_PROXY, this is inherited from the user's shell environment and specifies the HTTPS proxy settings. <code>LANG</code> Inherited from the user's shell environment, defining the system language and locale settings. <code>MAKEFLAGS</code> Inherited from the user's shell environment. This can be used to set additional arguments for the make command, such as -j2 to utilize 2 CPU cores for building the recipe. <code>PY_VER</code> Specifies the Python version against which the build is occurring. This can be modified with a <code>variant_config.yaml</code> file. <code>PATH</code> Inherited from the user's shell environment and augmented with the activated host and build prefixes. <code>PREFIX</code> The build prefix to which the build script should install the software. <code>PKG_BUILDNUM</code> Indicates the build number of the package currently being built. <code>PKG_NAME</code> The name of the package that is being built. <code>PKG_VERSION</code> The version of the package currently under construction. <code>PKG_BUILD_STRING</code> The complete build string of the package being built, including the hash (e.g., py311h21422ab_0). <code>PKG_HASH</code> Represents the hash of the package being built, excluding the leading 'h' (e.g., 21422ab). This is applicable from Conda-build 3.0 onwards. <code>PYTHON</code> The path to the Python executable in the host prefix. Python is installed in the host prefix only when it is listed as a host requirement. <code>R</code> The path to the R executable in the build prefix. R is installed in the build prefix only when it is listed as a build requirement. <code>RECIPE_DIR</code> The directory where the recipe is located. <code>SP_DIR</code> The location of Python's site-packages, where Python libraries are installed. <code>SRC_DIR</code> The path to where the source code is unpacked or cloned. If the source file is not a recognized archive format, this directory contains a copy of the source file. <code>STDLIB_DIR</code> The location of Python's standard library. <code>build_platform</code> Represents the native subdirectory of the conda executable, indicating the platform for which the build is occurring. <p>Removed from <code>conda-build</code> are: - <code>NPY_VER</code> - <code>PY3K</code></p>"},{"location":"build_script/#windows","title":"Windows","text":"<p>Unix-style packages on Windows are built in a special <code>Library</code> directory under the build prefix. The environment variables listed in the following table are defined only on Windows.</p> Variable Description <code>LIBRARY_BIN</code> <code>&lt;build prefix&gt;\\Library\\bin</code>. <code>LIBRARY_INC</code> <code>&lt;build prefix&gt;\\Library\\include</code>. <code>LIBRARY_LIB</code> <code>&lt;build prefix&gt;\\Library\\lib</code>. <code>LIBRARY_PREFIX</code> <code>&lt;build prefix&gt;\\Library</code>. <code>SCRIPTS</code> <code>&lt;build prefix&gt;\\Scripts</code>. <p>Not yet supported in <code>rattler-build</code>:</p> <ul> <li><code>CYGWIN_PREFIX</code></li> <li><code>VS_MAJOR</code></li> <li><code>VS_VERSION</code></li> <li><code>VS_YEAR</code></li> </ul> <p>Additionally, the following variables are forwarded from the environment:</p> <ul> <li><code>ALLUSERSPROFILE</code></li> <li><code>APPDATA</code></li> <li><code>CommonProgramFiles</code></li> <li><code>CommonProgramFiles(x86)</code></li> <li><code>CommonProgramW6432</code></li> <li><code>COMPUTERNAME</code></li> <li><code>ComSpec</code></li> <li><code>HOMEDRIVE</code></li> <li><code>HOMEPATH</code></li> <li><code>LOCALAPPDATA</code></li> <li><code>LOGONSERVER</code></li> <li><code>NUMBER_OF_PROCESSORS</code></li> <li><code>PATHEXT</code></li> <li><code>ProgramData</code></li> <li><code>ProgramFiles</code></li> <li><code>ProgramFiles(x86)</code></li> <li><code>ProgramW6432</code></li> <li><code>PROMPT</code></li> <li><code>PSModulePath</code></li> <li><code>PUBLIC</code></li> <li><code>SystemDrive</code></li> <li><code>SystemRoot</code></li> <li><code>TEMP</code></li> <li><code>TMP</code></li> <li><code>USERDOMAIN</code></li> <li><code>USERNAME</code></li> <li><code>USERPROFILE</code></li> <li><code>windir</code></li> <li><code>PROCESSOR_ARCHITEW6432</code></li> <li><code>PROCESSOR_ARCHITECTURE</code></li> <li><code>PROCESSOR_IDENTIFIER</code></li> </ul>"},{"location":"build_script/#unix","title":"Unix","text":"<p>The environment variables listed in the following table are defined only on macOS and Linux.</p> Variable Description <code>HOME</code> Standard $HOME environment variable. <code>PKG_CONFIG_PATH</code> Path to <code>pkgconfig</code> directory, defaults to `$PREFIX/lib/pkgconfig <code>SSL_CERT_FILE</code> Path to <code>SSL_CERT_FILE</code> file. <code>CFLAGS</code> Empty, can be forwarded from env to set additional arguments to C compiler. <code>CXXFLAGS</code> Same as CFLAGS for C++ compiler. <code>LDFLAGS</code> Empty, additional flags to be passed to the linker when linking object files into an executable or shared object."},{"location":"build_script/#macos","title":"macOS","text":"<p>The environment variables listed in the following table are defined only on macOS.</p> Variable Description <code>MACOSX_DEPLOYMENT_TARGET</code> Same as the Anaconda Python macOS deployment target. Currently <code>10.9</code> for intel 32- and 64bit macOS, and 11.0 for arm64. <code>OSX_ARCH</code> <code>i386</code> or <code>x86_64</code> or <code>arm64</code>, depending on the target platform"},{"location":"build_script/#linux","title":"Linux","text":"<p>The environment variable listed in the following table is defined only on Linux.</p> Variable Description <code>LD_RUN_PATH</code> Defaults to <code>&lt;build prefix&gt;/lib</code>. <code>QEMU_LD_PREFIX</code> The prefix used by QEMU's user mode emulation for library paths. <code>QEMU_UNAME</code> Set qemu uname release string to 'uname'. <code>DEJAGNU</code> The path to the dejagnu testing framework used by the GCC test suite. <code>DISPLAY</code> The X11 display to use for graphical applications. <code>BUILD</code> Target triple (<code>{build_arch}-conda_{build_distro}-linux-gnu</code>) where build_distro is one of <code>cos6</code> or <code>cos7</code>, for Centos 6 or 7"},{"location":"cli_usage/","title":"CLI Usage","text":""},{"location":"cli_usage/#shell-completions","title":"Shell Completions","text":"<p>We support shell completions through clap-complete. You can generate them for your shell using the <code>completion</code> command.</p> <p>E.g.,</p> <pre><code>rattler-build completion --shell=zsh &gt; ${ZSH_COMPLETIONS_PATH:~/.zsh/completions}/_rattler-build\ncompinit\n</code></pre> <p>Ensure that whereever you install the is pointed to by your FPATH (for zsh or equivalent in other shells). Now you can use TAB or your configured completion key. :3</p> <pre><code>$ rattler-build &lt;TAB&gt;\nbuild    -- Build a package\nhelp     -- Print this message or the help of the given subcommand(s)\nrebuild  -- Rebuild a package\ntest     -- Test a package\n</code></pre> <p>Example for Fish Shell just generate the <code>completions.fish</code> and add to <code>~/.config/fish/completions</code>. <pre><code>rattler-build completion --shell=fish &gt; ${ZSH_COMPLETIONS_PATH:~/.config/fish/completions}/rattler-build.fish\n</code></pre></p>"},{"location":"cli_usage/#package-format","title":"Package format","text":"<p>You can specify the package format (either <code>.tar.bz2</code> or <code>.conda</code>) by using the <code>--package-format</code> flag. You can also set the compression level with <code>:&lt;level&gt;</code> after the package format. The <code>&lt;level&gt;</code> can be <code>max</code>, <code>min</code>, <code>default</code> or a number corresponding to the compression level. <code>.tar.bz2</code> supports compression levels between <code>1</code> and <code>9</code> while <code>.conda</code> supports compression levels between <code>-7</code> and <code>22</code>. For <code>.conda</code>, you can also set the <code>--compression-threads</code> flag to specify the number of threads to use for compression.</p> <pre><code># default\nrattler-build build --package-format tarbz2 -r recipe/recipe.yaml\n# maximum compression\nrattler-build build --package-format conda:max --compression-threads 10 -r recipe/recipe.yaml\n</code></pre>"},{"location":"compilers/","title":"Compilers and cross-compilation","text":"<p>To use a compiler in your project, it's best to use the <code>${{ compiler('lang') }}</code> template function. The compiler function works by taking a language, determining the configured compiler for that language, and adding some information about the target platform to the selected compiler. To configure a compiler for a specific language, the <code>variant_config.yaml</code> file can be used.</p> <p>For example, in a recipe that uses a C-compiler, you can use the following code:</p> <pre><code>requirements:\n  build:\n    - ${{ compiler('c') }}\n</code></pre> <p>To set the compiler that you want to use, create a variant config that looks like the following:</p> <pre><code>c_compiler:\n  - gcc\n\n# optionally you can specify a version\nc_compiler_version:\n  - 9.3.0\n</code></pre> <p>When the template function is evaluated, it will look something like: <code>gcc_linux-64 9.3.0</code>. You can define your own compilers. For example, for <code>rust</code> you can use <code>${{ compiler('rust') }}</code> and <code>rust_compiler_{version}</code> in your variant config.</p>"},{"location":"compilers/#cross-compilation","title":"Cross compilation","text":"<p>Cross compilation is supported by rattler-build and the compiler template function is part of what makes it possible. When you want to cross-compile from <code>linux-64</code> to <code>linux-aarch64</code> (intel to ARM), you can pass <code>--target-platform linux-aarch64</code> to the <code>rattler-build</code> command. This will cause the compiler template function to select a compiler that is configured for <code>linux-aarch64</code>. The above example would resolve to <code>gcc_linux-aarch64 9.3.0</code>. Provided that the package is available for <code>linux-64</code> (your build platform), the compilation should succeed.</p> <p>The distinction between <code>build</code> and <code>host</code> section begins to make sense when thinking about cross compilation. The <code>build</code> enviromemnt is resolved to packages that need to run at compilation time. For example, <code>cmake</code>, <code>gcc</code>, <code>autotools</code> are all tools that need to be executed. Therefore, the <code>build</code> environment resolves to packages for the <code>linux-64</code> architecture (in our example). On the other hand, the <code>host</code> packages resolve to <code>linux-aarch64</code> - those are packages that we want to link against.</p> <pre><code># packages that need to run at build time (cmake, gcc, autotools, etc.)\n# in the platform that rattler-build is executed on (the build_platform)\nbuild:\n  - cmake\n  - ${{ compiler('c') }}\n# packages that we want to link against in the architecture we are\n# cross-compiling to the target_platform\nhost:\n  - libcurl\n  - openssl\n</code></pre>"},{"location":"experimental_features/","title":"Experimental Features","text":"<p>Warning</p> <p>These are experimental features of rattler-build and may change or go away completely.</p> <p>Currently only <code>build</code> &amp; <code>rebuild</code> command supports the following experimental features.</p> <p>To enable them use the <code>--experimental</code> flag with the command. Or, use the environment variable, <code>RATTLER_BUILD_EXPERIMENTAL=1</code>.</p>"},{"location":"experimental_features/#jinja-functions","title":"Jinja functions","text":""},{"location":"experimental_features/#load_from_filefile_path","title":"<code>load_from_file(&lt;file_path&gt;)</code>","text":"<p>The jinja function <code>load_from_file</code> allows loading from files, specifically, it allows loading from <code>toml</code>, <code>json</code> and <code>yaml</code> to an object to allow to fetch things directly from it. While it loads all other files as strings.</p>"},{"location":"experimental_features/#usage","title":"Usage","text":"<p>This is useful when you have the project description in a well defined project file, such as, <code>Cargo.toml</code>, <code>package.json</code>, <code>pyproject.toml</code>, <code>package.yaml</code>, or <code>stack.yaml</code>. And would like to keep the recipe as simple as possible, while not worrying about keeping changes in sync, perhaps using it with CI/CD.</p> <p>Or, from some other source that provides a well-defined output format.</p> <p>Example against <code>Cargo.toml</code> inside <code>rattler-build</code> github repository:</p> recipe.yaml<pre><code>context:\n  name: ${{ load_from_file(\"Cargo.toml\").package.name }}\n  version: ${{ load_from_file(\"Cargo.toml\").package.version }}\n  source_url: ${{ load_from_file(\"Cargo.toml\").package.homepage }}\n  rust_toolchain: ${{ load_from_file(\"rust-toolchains\") }}\n\npackage:\n  name: ${{ name }}\n  version: ${{ version }}\n\nsource:\n  git: ${{ source_url }}\n  tag: ${{ source_tag }}}}\n\nrequirements:\n  build:\n    - rust ==${{ rust_toolchain }}\n\nbuild:\n  script: cargo build --release -p ${{ name }}\n\ntest:\n  - script: cargo test -p ${{ name }}\n  - script: cargo test -p rust-test -- --test-threads=1\n\nabout:\n  home: ${{ source_url }}\n  repository: ${{ source_url }}\n  documentation: ${{ load_from_file(\"Cargo.toml\").package.documentation }}\n  summary: ${{ load_from_file(\"Cargo.toml\").package.description }}\n  license: ${{ load_from_file(\"Cargo.toml\").package.license }}\n</code></pre>"},{"location":"experimental_features/#git-functions","title":"Git functions","text":"<p>Git functions are useful for getting the latest tag and commit hash. These can be used in the <code>context</code> section of the recipe, to fetch version information from the git repository.</p> Examples <pre><code># latest tag in the repo\ngit.latest_tag(&lt;git_repo_url&gt;)\n\n# latest tag revision(aka, hash of tag commit) in the repo\ngit.latest_tag_rev(&lt;git_repo_url&gt;)\n\n# latest commit revision(aka, hash of head commit) in the repo\ngit.head_rev(&lt;git_repo_url&gt;)\n</code></pre>"},{"location":"experimental_features/#usage_1","title":"Usage","text":"<p>These can be useful for automating minor things inside the recipe itself. Such as if the current version is the latest version, if the current hash is the latest hash, etc.</p> recipe.yaml<pre><code>context:\n  git_repo_url: \"https://github.com/prefix-dev/rattler-build\"\n  latest_tag: ${{ git.latest_tag( git_repo_url ) }}\n\npackage:\n  name: \"rattler-build\"\n  version: ${{ latest_tag }}\n\nsource:\n  git: ${{ git_repo_url }}\n  tag: ${{ latest_tag }}\n</code></pre> <p>Though it's important to understand currently we don't guarantee caching for repo fetch for git functions this may lead to some performance issues.</p>"},{"location":"highlevel/","title":"What is rattler-build?","text":"<p><code>rattler-build</code> is a tool to build and package software so that it can be installed on any operating system \u2013 with any compatible package manager such as <code>mamba</code>, <code>conda</code>, or <code>rattler</code>. We are also intending for rattler build to be used as a library to drive builds of packages from any other recipe format in the future.</p>"},{"location":"highlevel/#how-does-rattler-build-work","title":"How does rattler-build work?","text":"<p>Building of packages consists of several steps. It all begins with a <code>recipe.yaml</code> file that specifies how the package is to be built and what the dependencies are. From the recipe file, <code>rattler-build</code> executes several steps:</p> <ol> <li>Parse the recipe file and evaluate conditional parts (we will see that later,    but parts of the recipe can be conditional e.g. on Windows vs. macOS)</li> <li>Retrieve all source files specified in the recipe, such as <code>.tar.gz</code> files,    <code>git</code> repositories or even local paths. Additionally, this step will apply    patches that can be specified alongside the source file.</li> <li>Download and install dependencies into temporary \"host\" and \"build\"    workspaces. Any dependencies that are needed at build time are installed in    this step.</li> <li>Execute the build script to build/compile the source code, and \"install\" it    into the host environment.</li> <li>Collect all files that are new in the \"host\" environment (because the build    script just created them) and apply some transformations if necessary    (specifically we edit the rpath on Linux and macOS to help make binaries    relocatable).</li> <li>Bundle all the files in a package and write out any additional metadata into    the <code>info/index.json</code>, <code>info/about.json</code> and <code>info/paths.json</code> files. This    also creates the test files that are bundled with the package.</li> <li>If any tests are specified in the recipe, then we run them. If the package    passes all the tests, it's considered done, otherwise we move it to a    \"broken\" place.</li> </ol> <p>After this process, a package is created. This package can be uploaded e.g. to a custom prefix.dev private or public channel.</p>"},{"location":"highlevel/#how-to-run-rattler-build","title":"How to run rattler-build","text":"<p>Running rattler-build is straight-forward, just execute (on the command line):</p> <pre><code>rattler-build build --recipe myrecipe/recipe.yaml\n</code></pre> <p>Or add a custom channel that is not conda-forge which is the default one.</p> <pre><code>rattler-build build -c robostack --recipe myrecipe/recipe.yaml\n</code></pre>"},{"location":"highlevel/#overview-of-a-recipeyaml","title":"Overview of a recipe.yaml","text":"<p>A recipe.yaml file is separated into multiple sections and can conditionally include or exclude sections. Recipe files also support a limited amount of string interpolation with <code>Jinja</code> (<code>minijinja</code> in our case).</p> <p>A simple example for the <code>zlib</code> package would look as follows:</p> recipe.yaml<pre><code># variables from the context section can be used in the rest of the recipe\n# in jinja expressions\ncontext:\n  version: 1.2.13\n\npackage:\n  name: zlib\n  version: ${{ version }}\n\nsource:\n  url: http://zlib.net/zlib-${{ version }}.tar.gz\n  sha256: b3a24de97a8fdbc835b9833169501030b8977031bcb54b3b3ac13740f846ab30\n\nbuild:\n  # build numbers can be set arbitrarily\n  number: 0\n  script:\n    # build script to install the package into the $PREFIX (host prefix)\n    - if: unix\n      then:\n      - ./configure --prefix=$PREFIX\n      - make -j$CPU_COUNT\n    - if: win\n      then:\n      - cmake -G \"Ninja\" -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=%LIBRARY_PREFIX%\n      - ninja install\n\nrequirements:\n  build:\n    # compiler is a special function.\n    - ${{ compiler(\"c\") }}\n    # The following two dependencies are only needed on Windows,\n    # and thus conditionally selected\n    - if: win\n      then:\n        - cmake\n        - ninja\n    - if: unix\n      then:\n        - make\n</code></pre> <p>The sections of a recipe are:</p> sections description <code>context</code> in this section you can define variables that can be used in the Jinja context later in the recipe (e.g. name and version are commonly interpolated in strings) <code>package</code> this section defines the name and version of the package you are currently building and will be the name of the final output <code>source</code> defines from where the source code is going to be downloaded from and checksums <code>build</code> the settings for the build and the build script <code>requirements</code> allows the definition of build, host, run and run-constrained dependencies."},{"location":"internals/","title":"Internals of rattler-build","text":""},{"location":"internals/#making-packages-relocatable-with-rattler-build","title":"Making Packages Relocatable with Rattler-Build","text":"<p>Often, the most challenging aspect of building a package using <code>rattler-build</code> is making it relocatable. A relocatable package can be installed into any prefix, allowing it to be used outside the environment in which it was built. This is in contrast to a non-relocatable package, which can only be utilized within its original build environment.</p> <p><code>rattler-build</code> automatically performs the following actions to make packages relocatable:</p> <ol> <li>Binary object file conversion: Binary object files are converted to use    relative paths using <code>install_name_tool</code> on macOS and <code>patchelf</code> on Linux.    This uses <code>$ORIGIN</code> for elf files on Linux and <code>@loader_path</code> for Mach-O files    on macOS to make the rpath relative to the executable / shared library.</li> <li>Text file prefix registration: Any text file without NULL bytes    containing the placeholder prefix have the registered prefix replaced with the    install prefix.</li> <li>Binary file prefix detection and registration: Binary files containing    the build prefix can be automatically registered. The registered files will    have their build prefix replaced with the install prefix at install time.    This works by padding the install prefix with null terminators, such that the    length of the binary file remains the same. The build prefix must be long    enough to accommodate any reasonable installation prefix. On macOS and Linux,    <code>rattler-build</code> pads the build prefix to 255 characters by appending    <code>_placehold</code> to the end of the build directory name.</li> </ol>"},{"location":"package_spec/","title":"Package specification","text":"<p><code>rattler-build</code> produces \"conda\" packages. These packages work with the <code>mamba</code> and <code>conda</code> package managers, and they work cross-platform on Windows, Linux and macOS.</p> <p>By default, a conda package is a <code>tar.bz2</code> archive which contains</p> <ul> <li>Metadata under the <code>info/</code> directory.</li> <li>A collection of files that are installed directly into an install prefix.</li> </ul> <p>The format is identical across platforms and operating systems. During the install process, all files are extracted into the install prefix, except the ones in <code>info/</code>. Installing a conda package into an environment is similar to executing the following commands:</p> <pre><code>cd &lt;environment prefix&gt;\ntar xjf mypkg-1.0.0-h2134.tar.bz2\n</code></pre> <p>Only files, including symbolic links, are part of a conda package. Directories are not included. Directories are created and removed as needed, but you cannot create an empty directory from the tar archive directly.</p> <p>There is also a newer archive type, suffixed with <code>.conda</code>. This archive type consists of an outer \"zip\" archive that is not compressed, and two inner archives that are compressed with <code>zstd</code>, which is very fast for decompression.</p> <p>The inner archives are split into <code>info</code> and <code>pkg</code> files, which makes it possible to extract only the <code>info</code> part of the archive (only the metadata), which is often smaller in size.</p>"},{"location":"package_spec/#package-filename","title":"Package filename","text":"<p>A conda package conforms to the following filename:</p> <pre><code>&lt;name&gt;-&lt;version&gt;-&lt;hash&gt;.tar.bz2 OR &lt;name&gt;-&lt;version&gt;-&lt;hash&gt;.conda\n</code></pre>"},{"location":"package_spec/#package-metadata","title":"Package metadata","text":"<p>The <code>info/</code> directory contains all metadata about a package. Files in this location are not installed under the install prefix. Although you are free to add any file to this directory, conda only inspects the content of the files discussed below.</p>"},{"location":"package_spec/#infoindexjson","title":"<code>info/index.json</code>","text":"<p>This file contains basic information about the package, such as name, version, build string, and dependencies. The content of this file is stored in <code>repodata.json</code>, which is the repository index file, hence the name <code>index.json</code>. The JSON object is a dictionary containing the keys shown below.</p> <ul> <li><code>name</code> - string - The lowercase name of the package. May contain lowercase characters, underscore and dashes.</li> <li><code>version</code> - string - The package version. May not contain \"-\". Acknowledges   PEP 440.</li> <li><code>build</code> - string - The build string. May not contain \"-\". Differentiates   builds of packages with otherwise identical names and versions, such as:</li> <li>A build with other dependencies, such as Python 3.4 instead of Python 2.7.</li> <li>A bug fix in the build process.</li> <li>Some different optional dependencies, such as MKL versus ATLAS linkage.     Nothing in conda actually inspects the build string. Strings such as     <code>np18py34_1</code> are designed only for human readability and conda never parses     them.</li> <li><code>build_number</code> - integer - A non-negative integer representing the build   number of the package. Unlike the build string, the <code>build_number</code> is   inspected by conda. Conda uses it to sort packages that have otherwise   identical names and versions to determine the latest one. This is important   because new builds that contain bug fixes for the way a package is built may   be added to a repository.</li> <li><code>depends</code> - list of strings - A list of dependency specifications, where each   element is a string, as outlined in :ref:<code>build-version-spec</code>.</li> <li><code>constrains</code> - list of matchspecs - A list of optional dependency constraints.   The packages listed under <code>constrains</code> are not installed by default, but if   they are installed they have to respect the constraints.</li> <li><code>subdir</code> - string - Optional. The subdir (like <code>linux-64</code>) of this package.</li> <li><code>arch</code> - string - Optional. The architecture the package is built for.   EXAMPLE: <code>x86_64</code>. This key is generally not used.</li> <li><code>platform</code> - string - Optional. The OS that the package is built for. EXAMPLE:   <code>osx</code>. This key is generally not used. Packages for a specific architecture   and platform are usually distinguished by the repository subdirectory that   contains them---see :ref:<code>repo-si</code>.</li> </ul>"},{"location":"package_spec/#infopathsjson","title":"<code>info/paths.json</code>","text":"<p>The <code>paths.json</code> file lists all files that are installed into the environment.</p> <p>It consists of a list of path entries, each with the following keys:</p> <ul> <li><code>_path</code> - string - the relative path of the file</li> <li><code>path_type</code> - optional, string - the type of linking, can be <code>hardlink</code>,   <code>softlink</code>, or <code>directory</code>. Default is <code>hardlink</code>.</li> <li><code>file_mode</code> - optional, string - the file mode can be <code>binary</code> or <code>text</code>. This   is only relevant for prefix replacement</li> <li><code>prefix_placeholder</code> - optional, string - the prefix placeholder string that   is encoded in the text or binary file, and that is replaced at installation   time. Note that this prefix placeholder uses <code>/</code> even on Windows.</li> <li><code>no_link</code> - bool, optional - whether this file should be linked or not   when installing the package, defaults false (linking the file from the cache   into the environment)</li> <li><code>sha256</code> - string - the SHA256 hash of the file. For symbolic links it   contains the SHA256 hash of the file pointed to.</li> <li><code>size_in_bytes</code> - number - the size in bytes of the file. For symbolic links,   it contains the file size of the file pointed to.</li> </ul> <p>Due to the way the binary replacement works, the placeholder prefix must be longer than the install prefix.</p>"},{"location":"package_spec/#infolicense","title":"<code>info/license/&lt;...&gt;</code>","text":"<p>All licenses mentioned in the recipe are copied to this folder.</p>"},{"location":"package_spec/#infoaboutjson","title":"<code>info/about.json</code>","text":"<p>Optional file. Contains the entries of the about section of the recipe of the <code>recipe.yaml</code> file. The following keys are added to <code>info/about.json</code> if present in the build recipe:</p> <ul> <li><code>home</code> (from about.homepage)</li> <li><code>dev_url</code> (from about.repository)</li> <li><code>doc_url</code> (from about.documentation)</li> <li><code>license_url</code></li> <li><code>license</code></li> <li><code>summary</code></li> <li><code>description</code></li> <li><code>license_family</code> (this field is not used anymore as we rely on SPDX license identifiers)</li> </ul>"},{"location":"package_spec/#inforecipe","title":"<code>info/recipe/&lt;...&gt;</code>","text":"<p>A directory containing the full contents of the build recipe. This folder also contains a rendered version of the recipe (<code>rendered_recipe.yaml</code>). This rendered version is used for the <code>rebuild</code> command. However, note that currently this format is still in flux and can change at any time.</p> <p>You can also use <code>--no-include-recipe</code> to disable the inclusion of the recipe in the package.</p>"},{"location":"rebuild/","title":"Rebuilding a package","text":"<p>The <code>rebuild</code> command allows you to rebuild a package from an existing package. The main use case is to examine if a package can be rebuilt in a reproducible manner. You can read more about reproducible builds here.</p>"},{"location":"rebuild/#usage","title":"Usage","text":"<pre><code>rattler-build rebuild ./mypkg-0.1.0-h60d57d3_0.tar.bz2\n</code></pre>"},{"location":"rebuild/#how-it-works","title":"How it works","text":"<p>The recipe is \"rendered\" and stored into the package. The way the recipe is rendered is subject to change. For the moment, the rendered recipe is stored as <code>info/recipe/rendered_recipe.yaml</code> file. It includes the exact package versions that were used at build time. When rebuilding, we use the package resolutions from the rendered recipe, and execute the same build script as the original package.</p> <p>We also take great care to sort files in a deterministic manner as well as erasing any time stamps. The <code>SOURCE_DATE_EPOCH</code> environment variable is set to the same timestamp as the original build for additional determinism (some build tools use this variable to set timestamps).</p>"},{"location":"rebuild/#how-to-check-the-reproducibility-of-a-package","title":"How to check the reproducibility of a package","text":"<p>There is an excellent tool called diffoscope that allows you to compare two packages and see the differences. You can install it with <code>pixi</code>:</p> <pre><code>pixi global install diffoscope\n</code></pre> <p>To compare two packages, you can use the following command:</p> <pre><code>rattler-build rebuild ./build0.tar.bz2\ndiffoscope ./build0.tar.bz2 ./mypkg-0.1.0-h60d57d3_0.tar.bz2\n</code></pre>"},{"location":"recipe_file/","title":"The recipe spec","text":"<p><code>rattler-build</code> implements a new recipe spec, different from the traditional \"meta.yaml\" used in <code>conda-build</code>. A recipe has to be stored as <code>recipe.yaml</code> file.</p>"},{"location":"recipe_file/#history","title":"History","text":"<p>A discussion was started on what a new recipe spec could or should look like. The fragments of this discussion can be found here: https://github.com/mamba-org/conda-specs/blob/master/proposed_specs/recipe.md The reason for a new spec are:</p> <ul> <li>Make it easier to parse (\"pure yaml\"). conda-build uses a mix of comments and   jinja to achieve a great deal of flexibility, but it's hard to parse the   recipe with a computer</li> <li>iron out some inconsistencies around multiple outputs (build vs. build/script   and more)</li> <li>remove any need for recursive parsing &amp; solving</li> <li>finally, the initial implementation in <code>boa</code> relied on conda-build.   <code>rattler-build</code> removes any dependency on Python or conda-build and   reimplements everything in Rust.</li> </ul>"},{"location":"recipe_file/#major-differences-with-conda-build","title":"Major differences with conda-build","text":"<ul> <li>recipe filename is <code>recipe.yaml</code>, not <code>meta.yaml</code></li> <li>outputs have less complicated behavior, keys are same as top-level recipe   (e.g. build/script, not just script), same for package/name, not just name)</li> <li>no implicit meta-packages in outputs</li> <li>no full Jinja2 support: no conditional or <code>{% set ...</code> support, only string   interpolation. Variables can be set in the toplevel \"context\" which is valid   YAML</li> <li>Jinja string interpolation needs to be preceded by a dollar sign at the   beginning of a string, e.g. <code>- ${{ version }}</code> in order for it to be valid   YAML</li> <li>Selectors use a YAML dictionary style (vs. comments in conda-build). Instead   of <code>- somepkg  #[osx]</code> we use    <pre><code>if: osx\nthen:\n  - somepkg\n</code></pre></li> <li>Skip instruction uses a list of skip conditions and not the selector syntax   from conda-build (e.g. <code>skip: [\"osx\", \"win and py37\"]</code>)</li> </ul>"},{"location":"recipe_file/#spec","title":"Spec","text":"<p>The recipe spec has the following parts:</p> <ul> <li> <code>context</code>: to set up variables that can later be used in Jinja string   interpolation</li> <li> <code>package</code>: defines name, version etc. of the top-level package</li> <li> <code>source</code>: points to the sources that need to be downloaded in order to   build the recipe</li> <li> <code>build</code>: defines how to build the recipe and what build number to use</li> <li> <code>requirements</code>: defines requirements of the top-level package</li> <li> <code>test</code>: defines tests for the top-level package</li> <li> <code>outputs</code>: a recipe can have multiple outputs. Each output can and should   have a <code>package</code>, <code>requirements</code> and <code>test</code> section</li> </ul>"},{"location":"recipe_file/#spec-reference","title":"Spec reference","text":"<p>The spec is also made available through a JSON Schema (which is used for validation). The schema (and pydantic source file) can be found in this repository: <code>recipe-format</code>.</p> To use with VSCode(yaml-plugin) and other IDEs: <p>Either, start the document with the following line: <pre><code># yaml-language-server: $schema=https://raw.githubusercontent.com/prefix-dev/recipe-format/main/schema.json\n</code></pre> Or, using <code>yaml.schemas</code>, <pre><code>yaml.schemas: {\n  \"https://raw.githubusercontent.com/prefix-dev/recipe-format/main/schema.json\": \"**/recipe.yaml\",\n}\n</code></pre> Read more.</p> <p>See more in the automatic linting chapter.</p>"},{"location":"recipe_file/#examples","title":"Examples","text":"recipe.yaml<pre><code># this sets up \"context variables\" (in this case name and version) that\n# can later be used in Jinja expressions\ncontext:\n  version: 1.1.0\n  name: imagesize\n\n# top level package information (name and version)\npackage:\n  name: ${{ name }}\n  version: ${{ version }}\n\n# location to get the source from\nsource:\n  url: https://pypi.io/packages/source/${{ name[0] }}/${{ name }}/${{ name }}-${{ version }}.tar.gz\n  sha256: f3832918bc3c66617f92e35f5d70729187676313caa60c187eb0f28b8fe5e3b5\n\n# build number (should be incremented if a new build is made, but version is not incrementing)\nbuild:\n  number: 1\n  script: python -m pip install --no-deps --ignore-installed .\n\n# the requirements at build and runtime\nrequirements:\n  host:\n    - python\n    - pip\n  run:\n    - python\n\n# tests to validate that the package works as expected\ntests:\n  - python:\n      imports:\n        - imagesize\n\n# information about the package\nabout:\n  homepage: https://github.com/shibukawa/imagesize_py\n  license: MIT\n  summary: 'Getting image size from png/jpeg/jpeg2000/gif file'\n  description: |\n    This module analyzes jpeg/jpeg2000/png/gif image header and\n    return image size.\n  repository: https://github.com/shibukawa/imagesize_py\n  documentation: https://pypi.python.org/pypi/imagesize\n\n# the below is conda-forge specific!\nextra:\n  recipe-maintainers:\n    - somemaintainer\n</code></pre>"},{"location":"recipe_file/#package-section","title":"Package section","text":"<p>Specifies package information.</p> <pre><code>package:\n  name: bsdiff4\n  version: \"2.1.4\"\n</code></pre> <ul> <li>name: The lower case name of the package. It may contain \"-\", but no   spaces.</li> <li>version: The version number of the package. Use the PEP-386 verlib   conventions. Cannot contain \"-\". YAML interprets version numbers such as 1.0   as floats, meaning that 0.10 will be the same as 0.1. To avoid this, put the   version number in quotes so that it is interpreted as a string.</li> </ul>"},{"location":"recipe_file/#source-section","title":"Source section","text":"<p>Specifies where the source code of the package is coming from. The source may come from a tarball file, git, hg, or svn. It may be a local path and it may contain patches.</p>"},{"location":"recipe_file/#source-from-tarball-or-zip-archive","title":"Source from tarball or zip archive","text":"<pre><code>source:\n  url: https://pypi.python.org/packages/source/b/bsdiff4/bsdiff4-1.1.4.tar.gz\n  md5: 29f6089290505fc1a852e176bd276c43\n  sha1: f0a2c9a30073449cfb7d171c57552f3109d93894\n  sha256: 5a022ff4c1d1de87232b1c70bde50afbb98212fd246be4a867d8737173cf1f8f\n</code></pre> <p>If an extracted archive contains only 1 folder at its top level, its contents will be moved 1 level up, so that the extracted package contents sit in the root of the work folder.</p>"},{"location":"recipe_file/#source-from-git","title":"Source from git","text":"<pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  # branch: master # note: defaults to fetching the repo's default branch\n</code></pre> <p>You can use <code>rev</code> to pin the commit version directly.</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  rev: \"50a1f7ed6c168eb0815d424cba2df62790f168f0\"\n</code></pre> <p>Or you can use the <code>tag</code>.</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  tag: \"1.1.4\"\n</code></pre> <p>The <code>git</code> can also be a relative path to the recipe directory.</p> <pre><code>source:\n  git: ../../bsdiff4/.git\n  tag: \"1.1.4\"\n</code></pre> <p>Futhermore if you want to fetch just the current \"HEAD\"(this may result in non-deterministic builds) then you can use <code>depth</code>,</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  depth: 1 # note: the behaviour defaults to -1\n</code></pre> <p>Note: <code>tag</code> or <code>rev</code> may not be available within commit depth range, hence we don't allow using <code>rev</code> or <code>tag</code> and <code>depth</code> of them together if not set to <code>-1</code>.</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  tag: \"1.1.4\"\n  depth: 1 # error: use of `depth` with `rev` is invalid, they are mutually exclusive\n</code></pre> <p>When you want to use git-lfs, you need to set <code>lfs: true</code>. This will also pull the lfs files from the repository.</p> <pre><code>source:\n  git: ../../bsdiff4/.git\n  tag: \"1.1.4\"\n  lfs: true # note: defaults to false\n</code></pre>"},{"location":"recipe_file/#source-from-a-local-path","title":"Source from a local path","text":"<p>If the path is relative, it is taken relative to the recipe directory. The source is copied to the work directory before building.</p> <pre><code>  source:\n    path: ../src\n    use_gitignore: false # note: defaults to true\n</code></pre> <p>By default, all files in the local path that are ignored by git are also ignored by rattler-build. You can disable this behavior by setting <code>use_gitignore</code> to <code>false</code>.</p>"},{"location":"recipe_file/#patches","title":"Patches","text":"<p>Patches may optionally be applied to the source.</p> <pre><code>  source:\n    #[source information here]\n    patches:\n      - my.patch # the patch file is expected to be found in the recipe\n</code></pre>"},{"location":"recipe_file/#destination-path","title":"Destination path","text":"<p>Within boa's work directory, you may specify a particular folder to place source into. <code>rattler-build</code> will always drop you into the same folder (build folder/work), but it's up to you whether you want your source extracted into that folder, or nested deeper. This feature is particularly useful when dealing with multiple sources, but can apply to recipes with single sources as well.</p> <pre><code>source:\n  #[source information here]\n  target_directory: my-destination/folder\n</code></pre>"},{"location":"recipe_file/#source-from-multiple-sources","title":"Source from multiple sources","text":"<p>Some software is most easily built by aggregating several pieces.</p> <p>The syntax is a list of source dictionaries. Each member of this list follows the same rules as the single source. All features for each member are supported.</p> <p>Example:</p> <pre><code>source:\n  - url: https://package1.com/a.tar.bz2\n    target_directory: stuff\n  - url: https://package1.com/b.tar.bz2\n    target_directory: stuff\n  - git: https://github.com/mamba-org/boa\n    target_directory: boa\n</code></pre> <p>Here, the two URL tarballs will go into one folder, and the git repo is checked out into its own space. Git will not clone into a non-empty folder.</p>"},{"location":"recipe_file/#build-section","title":"Build section","text":"<p>Specifies build information.</p> <p>Each field that expects a path can also handle a glob pattern. The matching is performed from the top of the build environment, so to match files inside your project you can use a pattern similar to the following one: <code>\"**/myproject/**/*.txt\"</code>. This pattern will match any .txt file found in your project. Quotation marks (<code>\"\"</code>) are required for patterns that start with a <code>*</code>.</p> <p>Recursive globbing using <code>**</code> is also supported.</p>"},{"location":"recipe_file/#build-number-and-string","title":"Build number and string","text":"<p>The build number should be incremented for new builds of the same version. The number defaults to <code>0</code>. The build string cannot contain \"-\". The string defaults to the default rattler-build build string plus the build number.</p> <pre><code>build:\n  number: 1\n  string: abc\n</code></pre> <p>A hash will appear when the package is affected by one or more variables from the conda_build_config.yaml file. The hash is made up from the \"used\" variables - if anything is used, you have a hash. If you don't use these variables then you won't have a hash. There are a few special cases that do not affect the hash, such as Python and R or anything that already had a place in the build string.</p> <p>The build hash will be added to the build string if these are true for any dependency:</p> <ul> <li>package is an explicit dependency in build, host, or run deps</li> <li>package has a matching entry in conda_build_config.yaml which is a pin to a     specific version, not a lower bound</li> <li>that package is not ignored by ignore_version</li> </ul> <p>OR</p> <ul> <li>package uses <code>{{ compiler() }}</code> jinja2 function</li> </ul>"},{"location":"recipe_file/#dynamic-linking","title":"Dynamic linking","text":"<p>This section contains settings for the shared libraries and executables.</p> <pre><code>build:\n  dynamic_linking:\n    rpath_allowlist: [\"/usr/lib/**\"]\n</code></pre>"},{"location":"recipe_file/#python-entry-points","title":"Python entry points","text":"<p>The following example creates a Python entry point named \"bsdiff4\" that calls <code>bsdiff4.cli.main_bsdiff4()</code>.</p> <pre><code>build:\n  python:\n    entry_points:\n      - bsdiff4 = bsdiff4.cli:main_bsdiff4\n      - bspatch4 = bsdiff4.cli:main_bspatch4\n</code></pre>"},{"location":"recipe_file/#script","title":"Script","text":"<p>By default, rattler-build uses a <code>build.sh</code> file on Unix (macOS and Linux) and a <code>build.bat</code> file on Linux, if they exist in the same folder as the <code>recipe.yaml</code> file. With the script parameter you can either supply a different filename or write out short build scripts. You may need to use selectors to use different scripts for different platforms.</p> <pre><code>build:\n  script:\n    python setup.py install --single-version-externally-managed --record=record.txt\n</code></pre>"},{"location":"recipe_file/#skipping-builds","title":"Skipping builds","text":"<p>List conditions under which boa should skip the build of this recipe. Particularly useful for defining recipes that are platform specific. By default, a build is never skipped.</p> <pre><code>build:\n  skip:\n    - win\n    ...\n</code></pre>"},{"location":"recipe_file/#architecture-independent-packages","title":"Architecture independent packages","text":"<p>Allows you to specify \"no architecture\" when building a package, thus making it compatible with all platforms and architectures. Noarch packages can be installed on any platform.</p> <p>Assigning the noarch key as <code>generic</code> tells conda to not try any manipulation of the contents.</p> <pre><code>build:\n  noarch: generic\n</code></pre> <p><code>noarch: generic</code> is most useful for packages such as static javascript assets and source archives. For pure Python packages that can run on any Python version, you can use the <code>noarch: python</code> value instead:</p> <pre><code>build:\n  noarch: python\n</code></pre> <p>Note</p> <p>At the time of this writing, <code>noarch</code> packages should not make use of preprocess-selectors: <code>noarch</code> packages are built with the directives which evaluate to <code>true</code> in the platform it is built on, which probably will result in incorrect/incomplete installation in other platforms.</p>"},{"location":"recipe_file/#requirements-section","title":"Requirements section","text":"<p>Specifies the build and runtime requirements. Dependencies of these requirements are included automatically.</p> <p>Versions for requirements must follow the conda/mamba match specification. See build-version-spec.</p>"},{"location":"recipe_file/#build","title":"Build","text":"<p>Tools required to build the package. These packages are run on the build system and include things such as revision control systems (Git, SVN) make tools (GNU make, Autotool, CMake) and compilers (real cross, pseudo-cross, or native when not cross-compiling), and any source pre-processors.</p> <p>Packages which provide \"sysroot\" files, like the <code>CDT</code> packages (see below) also belong in the build section.</p> <pre><code>requirements:\n  build:\n    - git\n    - cmake\n</code></pre>"},{"location":"recipe_file/#host","title":"Host","text":"<p>It represents packages that need to be specific to the target platform when the target platform is not necessarily the same as the native build platform. For example, in order for a recipe to be \"cross-capable\", shared libraries requirements must be listed in the host section, rather than the build section, so that the shared libraries that get linked are ones for the target platform, rather than the native build platform. You should also include the base interpreter for packages that need one. In other words, a Python package would list <code>python</code> here and an R package would list <code>mro-base</code> or <code>r-base</code>.</p> <pre><code>requirements:\n  build:\n    - ${{ compiler('c') }}\n    - if: linux\n      then:\n        - ${{ cdt('xorg-x11-proto-devel') }}\n  host:\n    - python\n</code></pre> <p>Note</p> <p>When both build and host sections are defined, the build section can be thought of as \"build tools\" - things that run on the native platform, but output results for the target platform. For example, a cross-compiler that runs on linux-64, but targets linux-armv7.</p> <p>The PREFIX environment variable points to the host prefix. With respect to activation during builds, both the host and build environments are activated. The build prefix is activated before the host prefix so that the host prefix has priority over the build prefix. Executables that don't exist in the host prefix should be found in the build prefix.</p> <p>The build and host prefixes are always separate when both are defined, or when <code>${{ compiler() }}</code> Jinja2 functions are used. The only time that build and host are merged is when the host section is absent, and no <code>${{ compiler() }}</code> Jinja2 functions are used in meta.yaml.</p>"},{"location":"recipe_file/#run","title":"Run","text":"<p>Packages required to run the package. These are the dependencies that are installed automatically whenever the package is installed. Package names should follow the package match specifications.</p> <pre><code>requirements:\n  run:\n    - python\n    - six &gt;=1.8.0\n</code></pre> <p>To build a recipe against different versions of NumPy and ensure that each version is part of the package dependencies, list <code>numpy</code> as a requirement in <code>recipe.yaml</code> and use a <code>conda_build_config.yaml</code> file with multiple NumPy versions.</p>"},{"location":"recipe_file/#run-constrained","title":"Run constrained","text":"<p>Packages that are optional at runtime but must obey the supplied additional constraint if they are installed.</p> <p>Package names should follow the package match specifications.</p> <pre><code>requirements:\n  run_constrained:\n    - optional-subpackage ==${{ version }}\n</code></pre> <p>For example, let's say we have an environment that has package \"a\" installed at version 1.0. If we install package \"b\" that has a run_constrained entry of \"a&gt;1.0\", then mamba would need to upgrade \"a\" in the environment in order to install \"b\".</p> <p>This is especially useful in the context of virtual packages, where the run_constrained dependency is not a package that mamba manages, but rather a virtual package that represents a system property that mamba can't change. For example, a package on linux may impose a run_constrained dependency on __glibc&gt;=2.12. This is the version bound consistent with CentOS 6. Software built against glibc 2.12 will be compatible with CentOS 6. This run_constrained dependency helps mamba tell the user that a given package can't be installed if their system glibc version is too old.</p>"},{"location":"recipe_file/#run-exports","title":"Run exports","text":"<p>Packages may have runtime requirements such as shared libraries (e.g. zlib), which are required for linking at build time, and for resolving the link at run time. Such packages use <code>run_exports</code> for defining the runtime requirements to let the dependent packages understand the runtime requirements of the package.</p> <p>Example from zlib:</p> <pre><code>  requirements:\n    run_exports:\n      - {{ pin_subpackage('libzlib', exact=True) }}\n</code></pre> <p>Run exports are weak by default. But you can also define strong run_exports.</p> <pre><code>  requirements:\n    run_exports:\n      strong:\n        - {{ pin_subpackage('libzlib', exact=True) }}\n</code></pre>"},{"location":"recipe_file/#ignore-run-exports","title":"Ignore run exports","text":"<p>There maybe cases where an upstream package has a problematic <code>run_exports</code> constraint, you can ignore it in your recipe by listing the upstream package name in the <code>ignore_run_exports</code> section in <code>requirements</code>.</p> <p>You can ignore them by package name, or by naming the runtime dependency directly.</p> <pre><code>  requirements:\n    ignore_run_exports:\n      from_package:\n        - zlib\n</code></pre> <p>Using, runtime depenedency name.</p> <pre><code>  requirements:\n    ignore_run_exports:\n      from_name:\n        - libzlib\n</code></pre> <p>Note</p> <p><code>ignore_run_exports</code> only applies to runtime dependencies coming from an upstream package.</p>"},{"location":"recipe_file/#tests-section","title":"Tests section","text":"<p>Rattler-build supports 4 different types of tests. The \"script\" test installs the package and runs a list of commands. The python test attempts to import a list of python modules and runs <code>pip check</code>. The downstream test runs the tests of a downstream package that reverse depends on the package being built.</p> <p>And lastly, the package content test checks if the built package contains the mentioned items.</p> <p>The tests section is a list of these items:</p> <pre><code>tests:\n  - script:\n      - echo \"hello world\"\n    requirements:\n      run:\n        - pytest\n    files:\n      source:\n        - test-data.txt\n\n  - python:\n      imports:\n        - bsdiff4\n      pip_check: true  # this is the default\n  - downstream: numpy\n</code></pre>"},{"location":"recipe_file/#script-test","title":"Script test","text":"<p>The script test has 3 top-level keys: <code>script</code>, <code>files</code> and <code>requirements</code>. Only the <code>script</code> key is required.</p>"},{"location":"recipe_file/#test-commands","title":"Test commands","text":"<p>Commands that are run as part of the test.</p> <pre><code>tests:\n  - script:\n      - echo \"hello world\"\n      - bsdiff4 -h\n      - bspatch4 -h\n</code></pre>"},{"location":"recipe_file/#extra-test-files","title":"Extra Test Files","text":"<p>Test files that are copied from the source work directory into the temporary test directory and are needed during testing (note that the source work directory is otherwise not available at all during testing).</p> <p>You can also include files that come from the <code>recipe</code> folder. They are copied into the test directory as well.</p> <p>At test execution time, the test directory is the current working directory.</p> <pre><code>tests:\n  - script:\n      - ls\n    files:\n      source:\n        - myfile.txt\n        - tests/\n        - some/directory/pattern*.sh\n      recipe:\n        - extra-file.txt\n</code></pre>"},{"location":"recipe_file/#test-requirements","title":"Test requirements","text":"<p>In addition to the runtime requirements, you can specify requirements needed during testing. The runtime requirements that you specified in the \"run\" section described above are automatically included during testing (because the built package is installed like regular).</p> <p>In the <code>build</code> section you can specify additional requirements that are only needed on the build system for cross-compilation (e.g. emulators or compilers).</p> <pre><code>tests:\n  - script:\n      - echo \"hello world\"\n    requirements:\n      build:\n        - myemulator\n      run:\n        - nose\n</code></pre>"},{"location":"recipe_file/#python-tests","title":"Python tests","text":"<p>For this test type you can list a set of Python modules that need to be importable. The test will fail if any of the modules cannot be imported.</p> <p>The test will also automatically run <code>pip check</code> to check for any broken dependencies. This can be disabled by setting <code>pip_check: false</code> in the YAML.</p> <pre><code>tests:\n  - python:\n      imports:\n        - bsdiff4\n        - bspatch4\n      pip_check: true  # can be left out because this is the default\n</code></pre> <p>Internally this will write a small Python script that imports the modules:</p> <pre><code>import bsdiff4\nimport bspatch4\n</code></pre>"},{"location":"recipe_file/#check-for-package-contents","title":"Check for package-contents","text":"<p>Checks if the built package contains the mentioned items. These checks are executed directly at the end of the build process to make sure that all expected files are present in the package.</p> <pre><code>tests:\n  - package-contents:\n      # checks for the existence of files inside $PREFIX or %PREFIX%\n      # or, checks that there is at least one file matching the specified `glob`\n      # pattern inside the prefix\n      files:\n        - etc/libmamba/test.txt\n        - etc/libmamba\n        - etc/libmamba/*.mamba.txt\n\n      # checks for the existence of `mamba/api/__init__.py` inside of the\n      # Python site-packages directory (note: also see Python import checks)\n      site_packages:\n        - mamba.api\n\n\n      # looks in $PREFIX/bin/mamba for unix and %PREFIX%\\Library\\bin\\mamba.exe on Windows\n      # note: also check the `commands` and execute something like `mamba --help` to make\n      # sure things work fine\n      bin:\n        - mamba\n\n      # searches for `$PREFIX/lib/libmamba.so` or `$PREFIX/lib/libmamba.dylib` on Linux or macOS,\n      # on Windows for %PREFIX%\\Library\\lib\\mamba.dll &amp; %PREFIX%\\Library\\bin\\mamba.bin\n      lib:\n        - mamba\n\n      # searches for `$PREFIX/include/libmamba/mamba.hpp` on unix, and\n      # on Windows for `%PREFIX%\\Library\\include\\mamba.hpp`\n      includes:\n        - libmamba/mamba.hpp\n</code></pre>"},{"location":"recipe_file/#downstream-tests","title":"Downstream tests","text":"<p>Warning</p> <p>Downstream tests are not yet implemented in <code>rattler-build</code>.</p> <p>A downstream test can mention a single package that has a dependency on the package being built. The test will install the package and run the tests of the downstream package with our current package as a dependency.</p> <p>Sometimes downstream packages do not resolve. In this case, the test is ignored.</p> <pre><code>tests:\n  - downstream: numpy\n</code></pre>"},{"location":"recipe_file/#outputs-section","title":"Outputs section","text":"<p>Explicitly specifies packaging steps. This section supports multiple outputs, as well as different package output types. The format is a list of mappings.</p> <p>When using multiple outputs, certain top-level keys are \"forbidden\": <code>package</code> and <code>requirements</code>. Instead of <code>package</code>, a top-level <code>recipe</code> key can be defined. The <code>recipe.name</code> is ignored but the <code>recipe.version</code> key is used as default version for each output. Other \"top-level\" keys are merged into each output (for example, the <code>about</code> section) to avoid repetition. Each output is a complete recipe, and can have its own <code>build</code>, <code>requirements</code>, and <code>test</code> sections.</p> <pre><code>recipe:\n  # the recipe name is ignored\n  name: some\n  version: 1.0\n\noutputs:\n  - package:\n      # version is taken from recipe.version (1.0)\n      name: some-subpackage\n\n  - package:\n      name: some-other-subpackage\n      version: 2.0\n</code></pre> <p>Each output acts like an independent recipe and can have their own <code>script</code>, <code>build_number</code>, and so on.</p> <pre><code>outputs:\n  - package:\n      name: subpackage-name\n    build:\n      script: install-subpackage.sh\n</code></pre> <p>Each output is built independently. You should take care of not packaging the same files twice.</p>"},{"location":"recipe_file/#subpackage-requirements","title":"Subpackage requirements","text":"<p>Like a top-level recipe, a subpackage may have zero or more dependencies listed as build, host or run requirements.</p> <p>The dependencies listed as subpackage build requirements are available only during the packaging phase of that subpackage.</p> <pre><code>outputs:\n  - package:\n      name: subpackage-name\n    requirements:\n      build:\n        - some-dep\n      run:\n        - some-dep\n</code></pre> <p>You can also use the <code>pin_subpackage</code> function to pin another output from the same recipe.</p> <pre><code>outputs:\n  - package:\n      name: libtest\n  - package:\n      name: test\n    requirements:\n      build:\n        - ${{ pin_subpackage('libtest', max_pin='x.x') }}\n</code></pre> <p>The outputs are topologically sorted by the dependency graph which is taking the <code>pin_subpackage</code> invocations into account. When using <code>pin_subpackage(name, exact=True)</code> a special behavior is used where the <code>name</code> package is injected as a \"variant\" and the variant matrix is expanded appropriately. For example, when you have the following situation, with a <code>variant_config.yaml</code> file that contains <code>openssl: [1, 3]</code>:</p> <pre><code>outputs:\n  - package:\n      name: libtest\n    requirements:\n      host:\n        - openssl\n  - package:\n      name: test\n    requirements:\n      build:\n        - ${{ pin_subpackage('libtest', exact=True) }}\n</code></pre> <p>Due to the variant config file, this will build two versions of <code>libtest</code>. We will also build two versions of <code>test</code>, one that depends on <code>libtest (openssl 1)</code> and one that depends on <code>libtest (openssl 3)</code>.</p>"},{"location":"recipe_file/#about-section","title":"About section","text":"<p>Specifies identifying information about the package. The information displays in the package server.</p> <pre><code>about:\n  homepage: https://example.com/bsdiff4\n  license: BSD\n  license_file: LICENSE\n  summary: binary diff and patch using the BSDIFF4-format\n  description: |\n    Long description of bsdiff4 ...\n  repository: https://github.com/ilanschnell/bsdiff4\n  documentation: https://docs.com\n</code></pre>"},{"location":"recipe_file/#license-file","title":"License file","text":"<p>Add a file containing the software license to the package metadata. Many licenses require the license statement to be distributed with the package. The filename is relative to the source or recipe directory. The value can be a single filename or a YAML list for multiple license files. Values can also point to directories with license information. Directory entries must end with a <code>/</code> suffix (this is to lessen unintentional inclusion of non-license files; all the directory's contents will be unconditionally and recursively added).</p> <pre><code>about:\n  license_file:\n    - LICENSE\n    - vendor-licenses/\n</code></pre>"},{"location":"recipe_file/#extra-section","title":"Extra section","text":"<p>A schema-free area for storing non-conda-specific metadata in standard YAML form.</p> Example: To store recipe maintainers information <pre><code>extra:\n  maintainers:\n   - name of maintainer\n</code></pre>"},{"location":"recipe_file/#templating-with-jinja","title":"Templating with Jinja","text":"<p>rattler-build supports limited Jinja templating in the <code>recipe.yaml</code> file.</p> <p>You can set up Jinja variables in the context yaml section:</p> <pre><code>context:\n  name: \"test\"\n  version: \"5.1.2\"\n  # later keys can reference previous keys\n  # and use jinja functions to compute new values\n  major_version: ${{ version.split('.')[0] }}\n</code></pre> <p>Later in your <code>recipe.yaml</code> you can use these values in string interpolation with Jinja. For example:</p> <pre><code>source:\n  url: https://github.com/mamba-org/${{ name }}/v${{ version }}.tar.gz\n</code></pre> <p>Jinja has built-in support for some common string manipulations.</p> <p>In rattler-build, complex Jinja is completely disallowed as we try to produce YAML that is valid at all times. So you should not use any <code>{% if ... %}</code> or similar Jinja constructs that produce invalid yaml. Furthermore, instead of plain double curly brackets Jinja statements need to be prefixed by <code>$</code>, e.g. <code>${{ ... }}</code>:</p> <pre><code>package:\n  name: {{ name }}   # WRONG: invalid yaml\n  name: ${{ name }} # correct\n</code></pre> <p>For more information, see the Jinja template documentation and the list of available environment variables <code>env-vars</code>.</p> <p>Jinja templates are evaluated during the build process.</p>"},{"location":"recipe_file/#additional-jinja2-functionality-in-rattler-build","title":"Additional Jinja2 functionality in rattler-build","text":"<p>Besides the default Jinja2 functionality, additional Jinja functions are available during the rattler-build process: <code>pin_compatible</code>, <code>pin_subpackage</code>, and <code>compiler</code>.</p> <p>The compiler function takes <code>c</code>, <code>cxx</code>, <code>fortran</code> and other values as argument and automatically selects the right (cross-)compiler for the target platform.</p> <pre><code>build:\n  - ${{ compiler('c') }}\n</code></pre> <p>The <code>pin_subpackage</code> function pins another package produced by the recipe with the supplied parameters.</p> <p>Similarly, the <code>pin_compatible</code> function will pin a package according to the specified rules.</p>"},{"location":"recipe_file/#pin-expressions","title":"Pin expressions","text":"<p><code>rattler-build</code> knows pin expressions. A pin expression can have a <code>min_pin</code>, <code>max_pin</code> and <code>exact</code> value. A <code>max_pin</code> and <code>min_pin</code> are specified with a string containing only <code>x</code> and <code>.</code>, e.g. <code>max_pin=\"x.x.x\"</code> would signify to pin the given package to <code>&lt;1.2.3</code> (if the package version is <code>1.2.2</code>, for example).</p> <p>A pin with <code>min_pin=\"x.x\",max_pin=\"x.x\"</code> for a package of version <code>1.2.2</code> would evaluate to <code>&gt;=1.2.2,&lt;1.2.3</code>.</p> <p>If <code>exact=true</code>, then the <code>hash</code> is included, and the package is pinned exactly, e.g. <code>==1.2.2 h1234</code>. This is a unique package variant that cannot exist more than once, and thus is \"exactly\" pinned.</p>"},{"location":"recipe_file/#pin-subpackage","title":"Pin subpackage","text":"<p>Pin subpackage refers to another package from the same recipe file. It is commonly used in the <code>build/run_exports</code> section to export a run export from the package, or with multiple outputs to refer to a previous build.</p> <p>It looks something like:</p> <pre><code>package:\n  name: mypkg\n  version: \"1.2.3\"\n\nrequirements:\n  run_exports:\n    # this will evaluate to `mypkg &lt;1.3`\n    - ${{ pin_subpackage(name, max_pin='x.x') }}\n</code></pre>"},{"location":"recipe_file/#pin-compatible","title":"Pin compatible","text":"<p>Pin compatible lets you pin a package based on the version retrieved from the variant file (if the pinning from the variant file needs customization).</p> <p>E.g. if the variant specifies a pin for <code>numpy: 1.11</code>, one can use <code>pin_compatible</code> to relax it:</p> <pre><code>requirements:\n  host:\n    # this will select nupy 1.11\n    - numpy\n  run:\n    # this will export `numpy &gt;=1.11,&lt;2`, instead of the stricter `1.11` pin\n    - ${{ pin_compatible('numpy', min_pin='x.x', max_pin='x') }}\n</code></pre>"},{"location":"recipe_file/#the-env-jinja-functions","title":"The env Jinja functions","text":"<p>You can access the current environment variables using the <code>env</code> object in Jinja.</p> <p>There are three functions:</p> <ul> <li><code>env.get(\"ENV_VAR\")</code> will insert the value of \"ENV_VAR\" into the recipe.</li> <li><code>env.get_default(\"ENV_VAR\", \"undefined\")</code> will insert the value of \"ENV_VAR\"   into the recipe or, if \"ENV_VAR\" is not defined, the specified default value   (in this case \"undefined\")</li> <li><code>env.exists(\"ENV_VAR\")</code> returns a boolean true of false if the env var is set   to any value</li> </ul> <p>This can be used for some light templating, e.g.</p> <pre><code>build:\n  string: ${{ env.get(\"GIT_BUILD_STRING\") }}_${{ PKG_HASH }}\n</code></pre>"},{"location":"recipe_file/#cmp-function","title":"<code>cmp</code> function","text":"<p>This function matches the first argument(package's MatchSpec) against the second argument(the version spec) and returns the resulting boolean.</p> <pre><code>cmp(python, '&gt;=3.4')\n</code></pre> <p>Example: cmp usage example</p>"},{"location":"recipe_file/#cdt-function","title":"<code>cdt</code> function","text":"<p>This function helps add Core Dependency Tree packages as dependencies by converting packages as required according to hard-coded logic.</p> <pre><code># on x86_64 system\ncdt('package-name') # outputs: package-name-cos6-x86_64\n# on aarch64 system\ncdt('package-name') # outputs: package-name-cos6-aarch64\n</code></pre> <p>Example: cdt usage example</p>"},{"location":"recipe_file/#preprocessing-selectors","title":"Preprocessing selectors","text":"<p>You can add selectors to any item, and the selector is evaluated in a preprocessing stage. If a selector evaluates to <code>true</code>, the item is flattened into the parent element. If a selector evaluates to <code>false</code>, the item is removed.</p> <p>Selectors can use <code>if ... then ... else</code> as follows:</p> <pre><code>source:\n  - if: not win\n    then:\n      - url: http://path/to/unix/source\n    else:\n      - url: http://path/to/windows/source\n\n# or the equivalent with two if conditions:\n\nsource:\n  - if: unix\n    then:\n      - url: http://path/to/unix/source\n  - if: win\n    then:\n      - url: http://path/to/windows/source\n</code></pre> <p>A selector is a valid Python statement that is executed. The following variables are defined. Unless otherwise stated, the variables are booleans.</p> <p>The use of the Python version selectors, py27, py34, etc. is discouraged in favor of the more general comparison operators. Additional selectors in this series will not be added to conda-build.</p> <p>Because the selector is any valid Python expression, complicated logic is possible:</p> <pre><code>- if: unix and not win\n  then: ...\n- if: (win or linux) and not py27\n  then: ...\n</code></pre> <p>Lists are automatically \"merged\" upwards, so it is possible to group multiple items under a single selector:</p> <pre><code>tests:\n  - script:\n    - if: unix\n      then:\n      - test -d ${PREFIX}/include/xtensor\n      - test -f ${PREFIX}/lib/cmake/xtensor/xtensorConfigVersion.cmake\n    - if: win\n      then:\n      - if not exist %LIBRARY_PREFIX%\\include\\xtensor\\xarray.hpp (exit 1)\n      - if not exist %LIBRARY_PREFIX%\\lib\\cmake\\xtensor\\xtensorConfigVersion.cmake (exit 1)\n\n# On unix this is rendered to:\ntests:\n  - script:\n    - test -d ${PREFIX}/include/xtensor\n    - test -f ${PREFIX}/lib/cmake/xtensor/xtensorConfigVersion.cmake\n</code></pre>"},{"location":"recipe_file/#experimental-features","title":"Experimental features","text":"<p>Warning</p> <p>These are experimental features of <code>rattler-build</code> and may change or go away completely.</p>"},{"location":"recipe_file/#jinja-functions","title":"Jinja functions","text":"<ul> <li><code>load_from_file</code></li> <li><code>git.*</code> functions</li> </ul>"},{"location":"selectors/","title":"Selectors in recipes","text":"<p>Recipe and variant configuration files can utilize selectors to conditionally add, remove, or modify dependencies, configuration options, or even skip recipe execution based on specific conditions.</p> <p>Selectors are implemented using a simple <code>if / then / else</code> map, which is a valid YAML dictionary. The condition is evaluated using <code>minijinja</code> and follows the same syntax as a Python expression.</p> <p>During rendering, several variables are set based on the platform and variant being built. For example, the unix variable is true for macOS and Linux, while win is true for Windows. Consider the following recipe executed on Linux:</p> <pre><code>requirements:\n  host:\n    - if: unix\n      then: unix-tool\n    - if: win\n      then: win-tool\n</code></pre> <p>This will be evaluated as:</p> <pre><code>requirements:\n  host:\n    - unix-tool\n</code></pre> <p>The line containing the Windows-specific configuration is removed. Multiple items can also be selected, such as:</p> <pre><code>host:\n  - if: linux\n    then:\n    - linux-tool-1\n    - linux-tool-2\n    - linux-tool-3\n</code></pre> <p>For Linux, this will result in:</p> <pre><code>host:\n  - linux-tool-1\n  - linux-tool-2\n  - linux-tool-3\n</code></pre> <p>Other examples often found in the wild:</p> <pre><code>if: build_platform != target_platform ... # true if cross-platform build\nif: osx and arm64 ... # true for apple silicon (osx-arm64)\nif: linux and (aarch64 or ppc64le)) ... # true for linux ppc64le or linux-aarch64\n</code></pre>"},{"location":"selectors/#available-variables","title":"Available variables","text":"<p>The following variables are available during the initial rendering and afterward:</p> Variable Description <code>target_platform</code> the configured target_platform for the build <code>build_platform</code> the build platform <code>linux</code> true if target_platform is Linux <code>osx</code> true if target_platform is OSX / macOS <code>win</code> true if target_platform is Windows <code>unix</code> true if target_platform is a Unix (macOS or Linux) <code>x86_64</code>, <code>x86</code>, <code>arm64</code>, ... The architecture (\"x86_64\" for 64 bit, \"x86\" for 32 bit, otherwise arm64, aarch64, ppc64le, ...) <p>After the initial phase, when the variant configuration is selected, the variant values are also available in selectors. For example, if the build uses <code>python: 3.8</code> as variant, we can use <code>if: python == \"3.8\"</code> to enable a dependency only when the Python version is 3.8.</p>"},{"location":"selectors/#the-cmp-function","title":"The <code>cmp</code> function","text":"<p>Inside selectors, one can use a special <code>cmp</code> function to test if the selected variant version has a matching version. For example, if we have again a <code>python: 3.8</code> variant, we could use the following tests:</p> <pre><code>- if: cmp(python, \"3.8\")    # true\n  then: mydep\n- if: cmp(python, \"&gt;=3.8\")  # true\n  then: mydep\n- if: cmp(python, \"&lt;3.8\")   # false\n  then: mydep\n</code></pre> <p>This function eliminates the need to implement any python-special conda-build selectors (such as <code>py3k</code>, <code>py38</code>, etc.) or the <code>py</code> and <code>npy</code> integers.</p> <p>Please note that during the initial phase of rendering we do not know the variant, and thus the <code>cmp</code> condition always evaluates to true.</p>"},{"location":"testing/","title":"Testing packages","text":"<p>When you are developing a package, you should write tests for it. The tests are automatically executed right after the package build has finished.</p> <p>The tests from the test section are actually packaged into your package and can also be executed straight from the existing package.</p> <p>The idea behind adding the tests into the package is that you can execute the tests independently from building the package. That is also why we are shipping a <code>test</code> subcommand that takes as input an existing package and executes the tests:</p> <pre><code>rattler-build test --package-file ./xtensor-0.24.6-h60d57d3_0.tar.bz2\n</code></pre> <p>Running the above command will extract the package and create a clean environment where the package and dependencies are installed. Then the tests are executed in this environment.</p> <p>If you inspect the package contents, you would find the test files under <code>info/test/*</code>.</p>"},{"location":"testing/#how-tests-are-translated","title":"How tests are translated","text":"<p>The test section allows you to specify the following things:</p> <pre><code>tests:\n  - script:\n      # commands to run to test the package. If any of the commands\n      # returns with an error code, the test is considered failed.\n      - echo \"Hello world\"\n      - pytest ./tests\n\n    # additional requirements at test time\n    requirements:\n      run:\n        - pytest\n\n    files:\n      # Extra files to be copied to the test directory from the \"work directory\"\n      source:\n        - tests/\n        - test.py\n        - *.sh\n      recipe:\n        - more_tests/*.py\n\n  # This test section tries to import the Python modules and errors if it can't\n  - python:\n      imports:\n        - mypkg\n        - mypkg.subpkg\n</code></pre> <p>When you are writing a test for your package, additional files are created and added to your package. These files are placed under the <code>info/tests/{index}/</code> folder per test.</p> <p>For a script test:</p> <ul> <li>All the files are copied straight into the test folder (under   <code>info/tests/{index}/</code>)</li> <li>The script is turned into a <code>run_test.sh</code> or <code>run_test.bat</code> file</li> <li>The extra requirements are stored as a JSON file called   <code>test_time_dependencies.json</code></li> </ul> <p>For a Python import test:</p> <ul> <li>A JSON file is created that is called <code>python_test.json</code> and stores the   imports to be tested and wether to execute <code>pip check</code> or not. This file is   placed under <code>info/tests/{index}/</code></li> </ul> <p>For a downstream test:</p> <ul> <li>A JSON file is created that is called <code>downstream_test.json</code> and stores the   downstream tests to be executed. This file is placed under   <code>info/tests/{index}/</code></li> </ul>"},{"location":"testing/#legacy-tests","title":"Legacy tests","text":"<p>Legacy tests (from conda-build) are still supported for execution. These tests are stored as files under the <code>info/test/</code> folder.</p> <p>The files are:</p> <ul> <li><code>run_test.sh</code> (Unix)</li> <li><code>run_test.bat</code> (Windows)</li> <li><code>run_test.py</code> (for the Python import tests)</li> <li><code>test_time_dependencies.json</code> (for additional dependencies at test time)</li> </ul> <p>Additionally, the <code>test</code> folder contains all the files specified in the test section as <code>source_files</code> and <code>files</code>. The tests are executed pointing to this directory as the current working directory.</p>"},{"location":"variants/","title":"Variant configuration","text":"<p><code>rattler-build</code> can automatically build multiple variants of a given package. For example, a Python package might need multiple variants per Python version (especially if it is a binary package such as <code>numpy</code>).</p> <p>For this use case, one can specify variant configuration files. A variant configuration file has 2 special entries and a list of packages with variants. For example:</p> variants.yaml<pre><code># special entry #1, the zip keys\nzip_keys:\n- [python, numpy]\n\n# special entry #2, the pin_run_as_build key\npin_run_as_build:\n  numpy:\n    max_pin: 'x.x'\n\n# entries per package version that users are interested in\npython:\n# Note that versions are _strings_ (not numbers)\n- \"3.8\"\n- \"3.9\"\n- \"3.10\"\n\nnumpy:\n- \"1.12\"\n- \"1.12\"\n- \"1.20\"\n</code></pre> <p>We can pass a variant configuration file to <code>rattler-build</code> using a command line like this:</p> <pre><code>rattler-build build --variant-config ./variants.yaml --recipe myrecipe.yaml\n</code></pre> <p>If we have a recipe, that has a <code>build</code>, <code>host</code> or <code>run</code> dependency on <code>python</code> we will build multiple variants of this package, one for each configured <code>python</code> version (\"3.8\", \"3.9\" and \"3.10\").</p> <p>For example:</p> <pre><code># ...\nrequirements:\n  host:\n  - python\n</code></pre> <p>will be rendered as (for the first variant)</p> <pre><code># ...\nrequirements:\n  host:\n- python 3.8*\n</code></pre> <p>Note that variants are only applied if the requirement doesn't specify any constraints. If the requirement would be <code>python &gt;3.8,&lt;3.10</code> the variant entry would be ignored.</p>"},{"location":"variants/#package-hash-from-variant","title":"Package hash from variant","text":"<p>You might have wondered what the role of the build string is. The build string is (if not explicitly set) computed from the variant configuration. It serves as a mechanism to discern different build configurations that produce a package with the same name and version.</p> <p>The hash is computed by dumping all the variant configuration values that are used by a given recipe into a JSON file, and then hashing that JSON file. For example, in our <code>python</code> example, we would get a variant configuration file that looks something like:</p> <pre><code>{\n    \"python\": \"3.8\"\n}\n</code></pre> <p>This JSON string is then hashed with the MD5 hash algorithm, and produces the hash. For certain packages (such as Python packages) special rules exists, and the <code>py&lt;Major.Minor&gt;</code> version is prepended to the hash, so that the final hash would look something like <code>py38h123123</code>.</p>"},{"location":"variants/#zip-keys","title":"Zip Keys","text":"<p>Zip keys modify how variants are combined. Usually, each variant key that has multiple entries is expanded to a build matrix, for example if we have:</p> <pre><code>python: [\"3.8\", \"3.9\"]\nnumpy: [\"1.12\", \"1.14\"]\n</code></pre> <p>We obtain 4 variants for a recipe that uses both <code>numpy</code> and <code>python</code>:</p> <pre><code>- python 3.8, numpy 1.12\n- python 3.8, numpy 1.14\n- python 3.9, numpy 1.12\n- python 3.9, numpy 1.14\n</code></pre> <p>However, if we use the <code>zip_keys</code> and specify</p> <pre><code>zip_keys: [\"python\", \"numpy\"]\npython: [\"3.8\", \"3.9\"]\nnumpy: [\"1.12\", \"1.14\"]\n</code></pre> <p>Then the versions are \"zipped up\" and we only get two variants. Note that both, <code>python</code> and <code>numpy</code> need to specify the exact same number of versions to make this work. The resulting variants with the zip applied are:</p> <pre><code>- python 3.8, numpy 1.12\n- python 3.9, numpy 1.14\n</code></pre>"},{"location":"variants/#pin-run-as-build","title":"Pin run as build","text":"<p>The <code>pin_run_as_build</code> key allows the user to inject additional pins. Usually, the <code>run_exports</code> mechanism is used to specify constraints for runtime dependencies from build time dependencies, but <code>pin_run_as_build</code> offers a mechanism to override that if the package does not contain a run exports file.</p> <p>For example:</p> <pre><code>pin_run_as_build:\n  libcurl:\n    min_pin: 'x'\n    max_pin: 'x'\n</code></pre> <p>If we now have a recipe that uses <code>libcurl</code> in the <code>host</code> and <code>run</code> dependencies like:</p> <pre><code>requirements:\n  host:\n  - libcurl\n  run:\n  - libcurl\n</code></pre> <p>During resolution, <code>libcurl</code> might be evaluated to <code>libcurl 8.0.1 h13284</code>. Our new runtime dependency then looks like:</p> <pre><code>requirements:\n  host:\n  - libcurl 8.0.1 h13284\n  run:\n  - libcurl &gt;=8,&lt;9\n</code></pre>"}]}