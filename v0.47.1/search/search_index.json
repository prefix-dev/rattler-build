{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#rattler-build-a-fast-conda-package-builder","title":"<code>rattler-build</code>: A Fast Conda Package Builder","text":"<p>The <code>rattler-build</code> tooling and library creates cross-platform relocatable binaries / packages from a simple recipe format. The recipe format is heavily inspired by <code>conda-build</code> and <code>boa</code>, and the output of a regular <code>rattler-build</code> run is a package that can be installed using <code>mamba</code>, <code>rattler</code> or <code>conda</code>.</p> <p><code>rattler-build</code> does not have any dependencies on <code>conda-build</code> or Python and works as a standalone binary.</p> <p></p>"},{"location":"#installation","title":"Installation","text":"<p>The recommended way of installing <code>rattler-build</code>, being a conda-package builder, is through a conda package manager. Next to <code>rattler-build</code> we are also building <code>pixi</code>.</p> <p>With <code>pixi</code> you can install <code>rattler-build</code> globally:</p> <pre><code>pixi global install rattler-build\n</code></pre> <p>Other options are:</p> CondaHomebrewArch LinuxBinary <pre><code>conda install rattler-build -c conda-forge\n\nmamba install rattler-build -c conda-forge\nmicromamba install rattler-build -c conda-forge\n\npixi global install rattler-build\npixi add rattler-build # To a pixi project\n</code></pre> <pre><code>brew install rattler-build\n</code></pre> <pre><code>pacman -S rattler-build\n</code></pre> <p><pre><code># Download the latest release from the GitHub releases page, for example the linux x86 version with curl:\ncurl -SL --progress-bar https://github.com/prefix-dev/rattler-build/releases/latest/download/rattler-build-x86_64-unknown-linux-musl\n</code></pre> You can grab version of <code>rattler-build</code> from the Github Releases.</p>"},{"location":"#completion","title":"Completion","text":"<p>When installing <code>rattler-build</code> you might want to enable shell completion. Afterwards, restart the shell or source the shell config file.</p>"},{"location":"#bash-default-on-most-linux-systems","title":"Bash (default on most Linux systems)","text":"<pre><code>echo 'eval \"$(rattler-build completion --shell bash)\"' &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"#zsh-default-on-macos","title":"Zsh (default on macOS)","text":"<pre><code>echo 'eval \"$(rattler-build completion --shell zsh)\"' &gt;&gt; ~/.zshrc\n</code></pre>"},{"location":"#powershell-pre-installed-on-all-windows-systems","title":"PowerShell (pre-installed on all Windows systems)","text":"<pre><code>Add-Content -Path $PROFILE -Value '(&amp; rattler-build completion --shell powershell) | Out-String | Invoke-Expression'\n</code></pre> <p>Failure because no profile file exists</p> <p>Make sure your profile file exists, otherwise create it with: <pre><code>New-Item -Path $PROFILE -ItemType File -Force\n</code></pre></p>"},{"location":"#fish","title":"Fish","text":"<pre><code>echo 'rattler-build completion --shell fish | source' &gt;&gt; ~/.config/fish/config.fish\n</code></pre>"},{"location":"#nushell","title":"Nushell","text":"<p>Add the following to the end of your Nushell env file (find it by running <code>$nu.env-path</code> in Nushell):</p> <pre><code>mkdir ~/.cache/rattler-build\nrattler-build completion --shell nushell | save -f ~/.cache/rattler-build/completions.nu\n</code></pre> <p>And add the following to the end of your Nushell configuration (find it by running <code>$nu.config-path</code>):</p> <pre><code>use ~/.cache/rattler-build/completions.nu *\n</code></pre>"},{"location":"#elvish","title":"Elvish","text":"<pre><code>echo 'eval (rattler-build completion --shell elvish | slurp)' &gt;&gt; ~/.elvish/rc.elv\n</code></pre>"},{"location":"#dependencies","title":"Dependencies","text":"<p>Currently <code>rattler-build</code> needs some dependencies on the host system which are executed as subprocess. We plan to reduce the number of external dependencies over time by writing what we need in Rust to make <code>rattler-build</code> fully self-contained.</p> <ul> <li><code>tar</code> to unpack tarballs downloaded from the internet in a variety of formats.   <code>.gz</code>, <code>.bz2</code> and <code>.xz</code> are widely used and one might have to install the   compression packages as well (e.g. <code>gzip</code>, <code>bzip2</code>, ...)</li> <li><code>patch</code> to patch source code after downloading</li> <li><code>install_name_tool</code> is necessary on macOS to rewrite the <code>rpath</code> of shared   libraries and executables to make it relative</li> <li><code>patchelf</code> is required on Linux to rewrite the <code>rpath</code> and <code>runpath</code> of shared   libraries and executables</li> <li><code>git</code> to checkout Git repositories (not implemented yet, but will require <code>git</code>   in the future)</li> <li><code>msvc</code> on Windows because we cannot ship the MSVC compiler on conda-forge   (needs to be installed on the host machine)</li> </ul> <p>On Windows, to obtain these dependencies from conda-forge, one can install <code>m2-patch</code>, <code>m2-bzip2</code>, <code>m2-gzip</code>, <code>m2-tar</code>.</p>"},{"location":"#github-action","title":"GitHub Action","text":"<p>There is a GitHub Action for <code>rattler-build</code>. It can be used to install <code>rattler-build</code> in CI/CD workflows and run a build command. Please check out the GitHub Action documentation for more information.</p>"},{"location":"#the-recipe-format","title":"The recipe format","text":"<p>Note You can find all examples below in the <code>examples</code> folder in the codebase and run them with <code>rattler-build</code>.</p> <p>A simple example recipe for the <code>xtensor</code> header-only C++ library:</p> <pre><code>context:\n  name: xtensor\n  version: 0.24.6\n\npackage:\n  name: ${{ name|lower }}\n  version: ${{ version }}\n\nsource:\n  url: https://github.com/xtensor-stack/xtensor/archive/${{ version }}.tar.gz\n  sha256: f87259b51aabafdd1183947747edfff4cff75d55375334f2e81cee6dc68ef655\n\nbuild:\n  number: 0\n  script:\n    - if: win\n      then: |\n        cmake -G \"NMake Makefiles\" -D BUILD_TESTS=OFF -D CMAKE_INSTALL_PREFIX=%LIBRARY_PREFIX% %SRC_DIR%\n        nmake\n        nmake install\n      else: |\n        cmake ${CMAKE_ARGS} -DBUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=$PREFIX $SRC_DIR -DCMAKE_INSTALL_LIBDIR=lib\n        make install\n\nrequirements:\n  build:\n    - ${{ compiler('cxx') }}\n    - cmake\n    - if: unix\n      then: make\n  host:\n    - xtl &gt;=0.7,&lt;0.8\n  run:\n    - xtl &gt;=0.7,&lt;0.8\n  run_constraints:\n    - xsimd &gt;=8.0.3,&lt;10\n\ntests:\n  - script:\n    - if: unix or emscripten\n      then:\n        - test -d ${PREFIX}/include/xtensor\n        - test -f ${PREFIX}/include/xtensor/xarray.hpp\n        - test -f ${PREFIX}/share/cmake/xtensor/xtensorConfig.cmake\n        - test -f ${PREFIX}/share/cmake/xtensor/xtensorConfigVersion.cmake\n    - if: win\n      then:\n        - if not exist %LIBRARY_PREFIX%\\include\\xtensor\\xarray.hpp (exit 1)\n        - if not exist %LIBRARY_PREFIX%\\share\\cmake\\xtensor\\xtensorConfig.cmake (exit 1)\n        - if not exist %LIBRARY_PREFIX%\\share\\cmake\\xtensor\\xtensorConfigVersion.cmake (exit 1)\n\nabout:\n  homepage: https://github.com/xtensor-stack/xtensor\n  license: BSD-3-Clause\n  license_file: LICENSE\n  summary: The C++ tensor algebra library\n  description: Multi dimensional arrays with broadcasting and lazy computing\n  documentation: https://xtensor.readthedocs.io\n  repository: https://github.com/xtensor-stack/xtensor\n\nextra:\n  recipe-maintainers:\n    - some-maintainer\n</code></pre> <p>A recipe for the <code>rich</code> Python package (using <code>noarch</code>):</p> <pre><code>context:\n  version: \"13.4.2\"\n\npackage:\n  name: \"rich\"\n  version: ${{ version }}\n\nsource:\n  - url: https://pypi.io/packages/source/r/rich/rich-${{ version }}.tar.gz\n    sha256: d653d6bccede5844304c605d5aac802c7cf9621efd700b46c7ec2b51ea914898\n\nbuild:\n  # Thanks to `noarch: python` this package works on all platforms\n  noarch: python\n  script:\n    - python -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - poetry-core &gt;=1.0.0\n    - python 3.10.*\n  run:\n    # sync with normalized deps from poetry-generated setup.py\n    - markdown-it-py &gt;=2.2.0\n    - pygments &gt;=2.13.0,&lt;3.0.0\n    - python 3.10.*\n    - typing_extensions &gt;=4.0.0,&lt;5.0.0\n\ntests:\n  - python:\n      imports:\n        - rich\n      pip_check: true\n\nabout:\n  homepage: https://github.com/Textualize/rich\n  license: MIT\n  license_file: LICENSE\n  summary: Render rich text, tables, progress bars, syntax highlighting, markdown and more to the terminal\n  description: |\n    Rich is a Python library for rich text and beautiful formatting in the terminal.\n\n    The Rich API makes it easy to add color and style to terminal output. Rich\n    can also render pretty tables, progress bars, markdown, syntax highlighted\n    source code, tracebacks, and more \u2014 out of the box.\n  documentation: https://rich.readthedocs.io\n  repository: https://github.com/Textualize/rich\n</code></pre> <p>A recipe for the <code>curl</code> library:</p> <pre><code>context:\n  version: \"8.0.1\"\n\npackage:\n  name: curl\n  version: ${{ version }}\n\nsource:\n  url: http://curl.haxx.se/download/curl-${{ version }}.tar.bz2\n  sha256: 9b6b1e96b748d04b968786b6bdf407aa5c75ab53a3d37c1c8c81cdb736555ccf\n\nbuild:\n  number: 0\n\nrequirements:\n  build:\n    - ${{ compiler('c') }}\n    - if: win\n      then:\n        - cmake\n        - ninja\n    - if: unix\n      then:\n        - make\n        - perl\n        - pkg-config\n        - libtool\n  host:\n    - if: linux\n      then:\n        - openssl\n\nabout:\n  homepage: http://curl.haxx.se/\n  license: MIT/X derivate (http://curl.haxx.se/docs/copyright.html)\n  license_file: COPYING\n  summary: tool and library for transferring data with URL syntax\n  description: |\n    Curl is an open source command line tool and library for transferring data\n    with URL syntax. It is used in command lines or scripts to transfer data.\n  documentation: https://curl.haxx.se/docs/\n  repository: https://github.com/curl/curl\n</code></pre> <p>For the <code>curl</code> library recipe, two additional script files (<code>build.sh</code> and <code>build.bat</code>) are needed.</p> <p><code>build.sh</code></p> <pre><code>#!/bin/bash\n\n# Get an updated config.sub and config.guess\ncp $BUILD_PREFIX/share/libtool/build-aux/config.* .\n\nif [[ $target_platform =~ linux.* ]]; then\n    USESSL=\"--with-openssl=${PREFIX}\"\nelse\n    USESSL=\"--with-secure-transport\"\nfi;\n\n./configure \\\n    --prefix=${PREFIX} \\\n    --host=${HOST} \\\n    ${USESSL} \\\n    --with-ca-bundle=${PREFIX}/ssl/cacert.pem \\\n    --disable-static --enable-shared\n\nmake -j${CPU_COUNT} ${VERBOSE_AT}\nmake install\n\n# Includes man pages and other miscellaneous.\nrm -rf \"${PREFIX}/share\"\n</code></pre> <p><code>build.bat</code></p> <pre><code>mkdir build\n\ncmake -GNinja ^\n      -DCMAKE_BUILD_TYPE=Release ^\n      -DBUILD_SHARED_LIBS=ON ^\n      -DCMAKE_INSTALL_PREFIX=%LIBRARY_PREFIX% ^\n      -DCMAKE_PREFIX_PATH=%LIBRARY_PREFIX% ^\n      -DCURL_USE_SCHANNEL=ON ^\n      -DCURL_USE_LIBSSH2=OFF ^\n      -DUSE_ZLIB=ON ^\n      -DENABLE_UNICODE=ON ^\n      %SRC_DIR%\n\nIF %ERRORLEVEL% NEQ 0 exit 1\n\nninja install --verbose\n</code></pre>"},{"location":"authentication_and_upload/","title":"Server authentication","text":""},{"location":"authentication_and_upload/#authenticating-with-a-server","title":"Authenticating with a server","text":"<p>You may want to use private channels for which you need to be authenticated. To do this ephemerally you can use the <code>RATTLER_AUTH_FILE</code> environment variable to point to a JSON file with the following structure:</p> <pre><code>{\n    \"*.prefix.dev\": {\n        \"BearerToken\": \"your_token\"\n    },\n    \"otherhost.com\": {\n        \"BasicHTTP\": {\n            \"username\": \"your_username\",\n            \"password\": \"your_password\"\n        }\n    },\n    \"anaconda.org\": {\n        \"CondaToken\": \"your_token\"\n    },\n    \"s3://my-bucket/my-channel\": {\n        \"S3Credentials\": {\n            \"access_key_id\": \"your_access_key_id\",\n            \"secret_access_key\": \"your_secret_access_key\",\n            \"session_token\": null\n        }\n    }\n}\n</code></pre> <p>The keys are the host names. You can use wildcard specifiers here (e.g. <code>*.prefix.dev</code> to match all subdomains of <code>prefix.dev</code>, such as <code>repo.prefix.dev</code>). This will allow you to also obtain packages from any private channels that you have access to.</p> <p>The following known authentication methods are supported:</p> <ul> <li><code>BearerToken</code>: prefix.dev</li> <li><code>CondaToken</code>: anaconda.org, quetz</li> <li><code>BasicHTTP</code>: artifactory</li> <li><code>S3Credentials</code>: S3 buckets</li> </ul>"},{"location":"authentication_and_upload/#uploading-packages","title":"Uploading packages","text":"<p>If you want to upload packages, then rattler-build comes with a built-in <code>upload</code> command. There are the following options:</p> <ul> <li><code>prefix.dev</code>: you can create public or private channels on the prefix.dev   hosted server</li> <li><code>anaconda.org</code>: you can upload packages to the free anaconda.org server</li> <li><code>quetz</code>: you can host your own quetz server and upload packages to it</li> <li><code>artifactory</code>: you can upload packages to a JFrog Artifactory server</li> <li><code>s3</code>: you can upload packages to an S3 bucket</li> </ul> <p>The command is:</p> <pre><code>rattler-build upload &lt;server&gt; &lt;package_files&gt;\n</code></pre> <p>Note: you can also use the <code>RATTLER_AUTH_FILE</code> environment variable to authenticate with the server.</p>"},{"location":"authentication_and_upload/#prefixdev","title":"prefix.dev","text":""},{"location":"authentication_and_upload/#trusted-publishing-via-oidc","title":"Trusted publishing via OIDC","text":"<p><code>rattler-build</code> supports authentication with https://prefix.dev through OIDC with GitHub Actions. An API key is no longer required, rattler-build can manage the complete authentication workflow for you. You only have to set up a specific repository and workflow under \"Trusted Publishers\" on prefix.dev.</p> <p></p> <p>Here you can find an example GitHub Actions workflow</p> .github/workflows/build.yml<pre><code>permissions:\n  contents: read\n  id-token: write\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build conda package\n        uses: prefix-dev/rattler-build-action@v0.2.19\n\n      - name: Upload all packages\n        shell: bash\n        run: |\n          shopt -s nullglob\n          EXIT_CODE=0\n          for pkg in $(find output -type f \\( -name \"*.conda\" -o -name \"*.tar.bz2\" \\) ); do\n            if ! rattler-build upload prefix -c my-channel \"${pkg}\"; then\n              EXIT_CODE=1\n            fi\n          done\n          exit $EXIT_CODE\n</code></pre>"},{"location":"authentication_and_upload/#token","title":"Token","text":"<p>To upload to prefix.dev, you need to have an account. You can then create a token in the settings of your account. The token is used to authenticate the upload.</p> <pre><code>export PREFIX_API_KEY=&lt;your_token&gt;\nrattler-build upload prefix -c &lt;channel&gt; &lt;package_files&gt;\n</code></pre> <p>You can also use the <code>--api-key=$PREFIX_API_KEY</code> option to pass the token directly to the command. Note that you need to have created the channel on the prefix.dev website before you can upload to it.</p>"},{"location":"authentication_and_upload/#quetz","title":"Quetz","text":"<p>You need to pass a token and API key to upload to a channel on your own Quetz server. The token is used to authenticate the upload.</p> <pre><code>export QUETZ_API_KEY=&lt;your_token&gt;\nrattler-build upload quetz -u &lt;url&gt; -c &lt;channel&gt; &lt;package_files&gt;\n</code></pre>"},{"location":"authentication_and_upload/#artifactory","title":"Artifactory","text":"<p>To upload to an Artifactory server, you need to pass a username and password. The username and password are used to authenticate the upload.</p> <pre><code>export ARTIFACTORY_USERNAME=&lt;your_username&gt;\nexport ARTIFACTORY_PASSWORD=&lt;your_password&gt;\nrattler-build upload artifactory -u &lt;url&gt; -c &lt;channel&gt; &lt;package_files&gt;\n</code></pre>"},{"location":"authentication_and_upload/#anacondaorg","title":"anaconda.org","text":"<p>To upload to anaconda.org, you need to specify the owner and API key. The API key is used to authenticate the upload.</p> <p>The owner is the owner of the distribution, for example, your user name or organization.</p> <p>One can also specify a label such as <code>dev</code> for release candidates using the <code>-c</code> flag. The default value is <code>main</code>.</p> <p>You can also add the <code>--force</code> argument to forcibly upload a new package (and overwrite any existing ones).</p> <pre><code>export ANACONDA_API_KEY=&lt;your_token&gt;\nrattler-build upload anaconda -o &lt;your_username&gt; -c &lt;label&gt; &lt;package_files&gt;\n</code></pre>"},{"location":"authentication_and_upload/#s3","title":"S3","text":"<p>To upload to an S3 bucket, you need to set access key ID, secret access key and (optionally) a session token. If not using <code>rattler-build auth login s3://my-bucket --s3-access-key-id &lt;access-key-id&gt; --s3-secret-access-key &lt;secret-access-key&gt; --s3-session-token &lt;session-token&gt;</code>, you can set the corresponding <code>AWS_*</code> environment variables (even if not using AWS S3). For instance, the following example uploads to a Cloudflare R2 S3 bucket:</p> <pre><code>export AWS_ACCESS_KEY_ID=&lt;your_access_key_id&gt;\nexport AWS_SECRET_ACCESS_KEY=&lt;your_secret_access_key&gt;\nrattler-build upload s3 \\\n  --channel s3://my-bucket/my-channel \\\n  --region auto \\\n  --endpoint-url https://xyz.r2.cloudflarestorage.com \\\n  --force-path-style\n</code></pre>"},{"location":"automatic_linting/","title":"Enabling Automatic Linting in VSCode","text":"<p>Our new recipe format adheres to a strict JSON schema, which you can access here.</p> <p>This schema is implemented using <code>pydantic</code> and can be rendered into a JSON schema file. The YAML language server extension in VSCode is capable of recognizing this schema, providing useful hints during the editing process.</p>"},{"location":"build_options/","title":"Advanced build options","text":"<p>There are some specialized build options to control various features:</p> <ul> <li>prefix replacement</li> <li>variant configuration</li> <li>encoded file type</li> </ul> <p>These are all found under the <code>build</code> key in the <code>recipe.yaml</code>.</p>"},{"location":"build_options/#include-only-certain-files-in-the-package","title":"Include only certain files in the package","text":"<p>Sometimes you may want to include only a subset of the files installed by the build process in your package. For this, the <code>files</code> key can be used. Only new files are considered for inclusion (ie. files that were not in the host environment beforehand).</p> recipe.yaml<pre><code>build:\n  # select files to be included in the package\n  # this can be used to remove files from the package, even if they are installed in the\n  # environment\n  files:\n    - list\n    - of\n    - globs\n</code></pre> <p>For example, to only include the header files in a package, you could use:</p> recipe.yaml<pre><code>build:\n  files:\n    - include/**/*.h\n</code></pre> <p>Glob patterns throughout the recipe file can also use a flexible <code>include</code> / <code>exclude</code> pair, such as:</p> recipe.yaml<pre><code>build:\n  files:\n    include:\n      - include/**/*.h\n    exclude:\n      - include/**/private.h\n</code></pre>"},{"location":"build_options/#glob-evaluation","title":"Glob evaluation","text":"<p>Glob patterns are used throughout the build options to specify files. The patterns are matched against the relative path of the file in the build directory. Patterns can contain <code>*</code> to match any number of characters, <code>?</code> to match a single character, and <code>**</code> to match any number of directories.</p> <p>For example:</p> <ul> <li><code>*.txt</code> matches all files ending in <code>.txt</code></li> <li><code>**/*.txt</code> matches all files ending in <code>.txt</code> in any directory</li> <li><code>**/test_*.txt</code> matches all files starting with <code>test_</code> and ending in <code>.txt</code>   in any directory</li> <li><code>foo/</code> matches all files under the <code>foo</code> directory</li> </ul> <p>The globs are always evaluated relative to the prefix directory. If you have no <code>include</code> globs, but an <code>exclude</code> glob, then all files are included except those that match the <code>exclude</code> glob. This is equivalent to <code>include: ['**']</code>.</p>"},{"location":"build_options/#always-include-and-always-copy-files","title":"Always include and always copy files","text":"<p>There are some options that control the inclusion of files in the final package.</p> <p>The <code>always_include_files</code> option can be used to include files even if they are already in the environment as part of some other host dependency. This is normally \"clobbering\" and should be used with caution (since packages should not have any overlapping files).</p> <p>The <code>always_copy_files</code> option can be used to copy files instead of linking them. This is useful for files that might be modified inside the environment (e.g. configuration files). Normally, files are linked from a central cache into the environment to save space \u2013 that means that files modified in one environment will be modified in all environments. This is not always desirable, and in that case you can use the <code>always_copy_files</code> option.</p> <p>How <code>always_copy_files</code> works</p> <p>The <code>always_copy_files</code> option works by setting the <code>no_link</code> option in the <code>info/paths.json</code> to <code>true</code> for the files in question. This means that the files are copied instead of linked when the package is installed.</p> recipe.yaml<pre><code>build:\n  # include files even if they are already in the environment\n  # as part of some other host dependency\n  always_include_files: list of globs\n\n  # do not soft- or hard-link these files, but always copy them was `no_link`\n  always_copy_files: list of globs\n</code></pre>"},{"location":"build_options/#merge-build-and-host-environments","title":"Merge build and host environments","text":"<p>In very rare cases you might want to merge the build and host environments to obtain the \"legacy\" behavior of conda-build.</p> recipe.yaml<pre><code>build:\n  # merge the build and host environments (used in many R packages on Windows)\n  merge_build_and_host_envs: bool (defaults to false)\n</code></pre>"},{"location":"build_options/#prefix-detection-replacement-options","title":"Prefix detection / replacement options","text":"<p>During installation time the \"install\"-prefix is injected into text and binary files. Sometimes this is not desired, and sometimes the user might want closer control over the automatic text/binary detection.</p> <p>The main difference between prefix replacement for text and binary files is that for binary files, the prefix string is padded with null bytes to match the length of the original prefix. The original prefix is the very long placeholder string that you might have seen in the build process.</p> <p>On Windows, binary prefix replacement is never performed.</p> recipe.yaml<pre><code>package:\n  name: mypackage\n  version: 1.0\n\nbuild:\n  # settings concerning the prefix detection in files\n  prefix_detection:\n    # force the file type of the given files to be TEXT or BINARY\n    # for prefix replacement\n    force_file_type:\n      # force TEXT file type (list of globs)\n      text: list of globs\n      # force binary file type (list of globs)\n      binary: list of globs\n\n    # ignore all or specific files for prefix replacement`\n    ignore: bool | [path] (defaults to false)\n\n    # whether to detect binary files with prefix or not\n    # defaults to true on Unix and (always) false on Windows\n    ignore_binary_files: bool\n</code></pre>"},{"location":"build_options/#variant-configuration","title":"Variant configuration","text":"<p>To control the variant precisely you can use the \"variant configuration\" options.</p> <p>A variant package has the same version number, but different \"hash\" and potentially different dependencies or build options. Variant keys are extracted from the <code>variants.yaml</code> file and usually any used Jinja variables or dependencies without version specifier are used as variant keys.</p> <p>Variant keys can also be forcibly set or ignored with the <code>use_keys</code> and <code>ignore_keys</code> options.</p> <p>In order to decide which of the variant packages to prefer and install by default, the <code>down_prioritize_variant</code> option can be used. The higher the value, the less preferred the variant is.</p> <p>More about variants can be found in the variant documentation.</p> <p>The following options are available in the <code>build</code> section to control the variant configuration:</p> recipe.yaml<pre><code>build:\n  # settings for the variant\n  variant:\n    # Keys to forcibly use for the variant computation\n    # even if they are not in the dependencies\n    use_keys: list of strings\n\n    # Keys to forcibly ignore for the variant computation\n    # even if they are in the dependencies\n    ignore_keys: list of strings\n\n    # used to prefer this variant less\n    down_prioritize_variant: integer (defaults to 0, higher is less preferred)\n</code></pre>"},{"location":"build_options/#dynamic-linking-configuration","title":"Dynamic linking configuration","text":"<p>After the package is built, rattler-build performs some \"post-processing\" on the binaries and libraries.</p> <p>This entails making the shared libraries relocatable and checking that all linked libraries are present in the run requirements. The following settings control this behavior.</p> <p>With the <code>rpath</code> option you can forcibly set the <code>rpath</code> of the shared libraries. The path is relative to the install prefix. Any <code>rpath</code> setting is ignored on Windows.</p> <p>The <code>rpath_allowlist</code> option can be used to allow the <code>rpath</code> to point to locations outside of the environment. This is useful if you want to link against libraries that are not part of the conda environment (e.g. proprietary software).</p> <p>If you want to stop <code>rattler-build</code> from relocating the binaries, you can set <code>binary_relocation</code> to <code>false</code>. If you want to only relocate some binaries, you can select the relevant ones with a glob pattern.</p> <p>To read more about <code>rpath</code>s and how rattler-build creates relocatable binary packages, see the internals docs.</p> <p>If you link against some libraries (possibly even outside of the prefix, in a system location), then you can use the <code>missing_dso_allowlist</code> to allow linking against these and suppress any warnings. This list is pre-populated with a list of known system libraries on the different operating systems.</p> <p>As part of the post-processing, <code>rattler-build</code> checks for overlinking and overdepending. \"Overlinking\" is when a binary links against a library that is not specified in the run requirements. This is usually a mistake because the library would not be present in the environment when the package is installed.</p> <p>Conversely, \"overdepending\" is when a library is part of the run requirements, but is not actually used by any of the binaries/libraries in the package.</p> <p>In addition to handling binary dependencies, <code>rattler-build</code> also ensures that packages containing hardcoded paths into the environment are relocatable when installed outside the of the build environment. To do this, <code>rattler-build</code> constructs a host environment with a 255 character name of the form <code>host_env_placehold[_placehold[_placehold[...]]]</code> (for details, see the internals docs). At install time, conda will find these paths and replace them in binaries with the path to the environment being installed into.</p> <p>Since this process may not be safe for all packages, and not all packages will require these modifications (if packages are already internally avoiding embedding invalid absolute paths, for example), then this process may be disabled using the <code>prefix_detection</code> options shown below.</p> recipe.yaml<pre><code>build:\n  # settings for shared libraries and executables\n  dynamic_linking:\n    # linux only, list of rpaths relative to the installation prefix\n    rpaths: list of paths (defaults to ['lib/'])\n\n    # Allow runpath / rpath to point to these locations\n    # outside of the environment\n    rpath_allowlist: list of globs\n\n    # whether to relocate binaries or not. If this is a list of paths, then\n    # only the listed paths are relocated\n    binary_relocation: bool (defaults to true) | list of globs\n\n    # Allow linking against libraries that are not in the run requirements\n    missing_dso_allowlist: list of globs\n\n    # what to do when detecting overdepending\n    overdepending_behavior: \"ignore\" or \"error\" # (defaults to \"ignore\")\n\n    # what to do when detecting overlinking\n    overlinking_behavior: \"ignore\" or \"error\" # (defaults to \"ignore\")\n\n  prefix_detection:\n    # A set of files to ignore prefix detection for altogether, see\n    ignore: list of globs\n\n    force_file_type:\n      # Force replacement of files as binary blobs regardless of their type\n      binary: list of globs\n      # Force replacement of files as text (strings) regardless of their type\n      text: list of globs\n</code></pre>"},{"location":"build_options/#python-options","title":"Python options","text":"<p>There are some additional options in the <code>python</code> section of the <code>build</code> key.</p> <p>The <code>entry_points</code> option can be used to specify entry points for the package.</p> <p>The <code>use_python_app_entrypoint</code> option can be used to specify if <code>python.app</code> which is useful for GUI applications on macOS.</p> <p>The <code>skip_pyc_compilation</code> option can be used to exclude certain files from being automatically compiled from <code>.py</code> to <code>.pyc</code>. Note that <code>noarch: python</code> packages never contain <code>.pyc</code> files. Some packages ship .py files that cannot be compiled, such as those that contain templates. Some packages also ship .py files that should not be compiled yet, because the Python interpreter that will be used is not known at build time. In these cases, conda-build can skip attempting to compile these files. The patterns used in this section do not need the ** to handle recursive paths.</p> <p>The <code>site_packages_path</code> is a specific option that is only used when build <code>python</code> itself. It will add metadata to the package record of the python package to tell the installer where the <code>site-packages</code> path is located. This is used to install noarch packages in the correct location.</p> recipe.yaml<pre><code>build:\n  python:\n    # entry points for the package\n    entry_points:\n      - bsdiff4 = bsdiff4.cli:main_bsdiff4\n      - bspatch4 = bsdiff4.cli:main_bspatch4\n\n    # use python.app entrypoint (macOS only)\n    use_python_app_entrypoint: false  # (defaults to false, only used on macOS)\n\n    # skip pyc compilation for certain files\n    skip_pyc_compilation:\n      - foo/*.py\n\n    # Option to specify whether a package is version independent (aka ABI3)\n    version_independent: true  # defaults to false\n</code></pre> <p>And an example of the <code>site_packages_path</code> option when building the python interpreter:</p> recipe.yaml<pre><code>package:\n  name: python\n  version: \"3.13.0\"\n\nbuild:\n  python:\n    # path to the site-packages folder\n    site_packages_path: \"lib/python3.13/site-packages\"\n</code></pre>"},{"location":"build_options/#python-package-version-independence","title":"Python Package Version Independence","text":"<p>Conda packages can be made version-independent in two different ways:</p>"},{"location":"build_options/#noarch-python","title":"<code>noarch: python</code>","text":"<p>Packages marked as <code>noarch: python</code> contain only pure Python code without compiled extensions. These packages work across all Python versions and platforms from a single build.</p>"},{"location":"build_options/#version_independent-true","title":"<code>version_independent: true</code>","text":"<p>Packages marked as version_independent support multiple Python versions while containing compiled extensions using Python's ABI3 compatibility. These require platform-specific builds (Windows, macOS, Linux) but remain compatible across different Python versions within each platform.</p>"},{"location":"build_options/#post-processing-of-the-package-contents-experimental","title":"Post processing of the package contents (experimental)","text":"<p>rattler-build allows you to post-process the package contents with <code>regex</code> replacements after the build has finished. This is only useful in very specific cases when you cannot easily identify new files and want to run post-processing only on new files.</p> <p>Note that this is an experimental feature and might be removed or changed in the future.</p> <p>The <code>post_process</code> key is a list of dictionaries with the following keys:</p> <ul> <li>files: list of globs to select the files from the package that you want to   modify</li> <li>regex: the regular expression to match in the file. Note that this uses Rust   regex syntax.</li> <li>replacement: the replacement string to use. Attention: note that Rust supports   expanding \"named captures\" with $name or ${name}. If you want to replace with   a env variable, you need to use <code>$${name}</code> to get <code>${name}</code> in the output.</li> </ul> recipe.yaml<pre><code>build:\n  post_process:\n    - files:\n        - *.txt\n      regex: \"foo\"\n      replacement: \"bar\"\n    - files:\n        - '*.pc'\n      regex: (?:-L|-I)?\"?([^;\\s]+/sysroot/)\n      replacement: '$${CONDA_BUILD_SYSROOT_S}'  # note this expands to `${CONDA_BUILD_SYSROOT_S}`\n</code></pre>"},{"location":"build_script/","title":"Scripts for building and testing packages","text":"<p>The <code>build.sh</code> file is the build script for Linux and macOS and <code>build.bat</code> is the build script for Windows. These scripts contain the logic that carries out your build steps. Anything that your build script copies into the <code>$PREFIX</code> or <code>%PREFIX%</code> folder will be included in your output package.</p> <p>For example, this <code>build.sh</code>:</p> build.sh<pre><code>mkdir -p $PREFIX/bin\ncp $RECIPE_DIR/my_script_with_recipe.sh $PREFIX/bin/super-cool-script.sh\n</code></pre> <p>There are many environment variables defined for you to use in build.sh and build.bat. Please see environment variables for more information.</p> <p><code>build.sh</code> and <code>build.bat</code> are optional. You can instead use the <code>build/script</code> key in your <code>recipe.yaml</code>, with each value being either a string command or a list of string commands. Any commands you put there must be able to run on every platform for which you build. For example, you can't use the <code>cp</code> command because <code>cmd.exe</code> won't understand it on Windows.</p> <p><code>build.sh</code> is run with <code>bash</code> and <code>build.bat</code> is run with <code>cmd.exe</code>.</p> recipe.yaml<pre><code>build:\n  script:\n    - if: unix\n      then:\n        - mkdir -p $PREFIX/bin\n        - cp $RECIPE_DIR/my_script_with_recipe.sh $PREFIX/bin/super-cool-script.sh\n    - if: win\n      then:\n        - mkdir %PREFIX%\\bin\n        - copy %RECIPE_DIR%\\my_script_with_recipe.bat %PREFIX%\\bin\\super-cool-script.bat\n</code></pre>"},{"location":"build_script/#environment-variables","title":"Environment variables","text":"<p>There are many environment variables that are automatically set during the build process.</p> <p>However, you can also set your own environment variables easily in the <code>script</code> section of your recipe:</p> recipe.yaml<pre><code>build:\n  script:\n    # Either use `content` or `file` to specify the script\n    # Note: this script only works on Unix :)\n    content: |\n      echo $FOO\n      echo $BAR\n      echo \"Secret value: $BAZ\"\n    env:\n      # hard coded value for `FOO`\n      FOO: \"foo\"\n      # Forward a value from the \"outer\" environment\n      # Without `default=...`, the build process will error if `BAR` is not set\n      BAR: ${{ env.get(\"BAR\", default=\"NOBAR\") }}\n    secrets:\n      # This value is a secret and will be masked in the logs and not stored in the rendered recipe\n      # The value needs to be available as an environment variable in the outer environment\n      - BAZ\n</code></pre>"},{"location":"build_script/#alternative-script-interpreters","title":"Alternative script interpreters","text":"<p>With <code>rattler-build</code> and the new recipe syntax you can select an <code>interpreter</code> for your script.</p> <p>So far, the following interpreters are supported:</p> <ul> <li><code>bash</code> (default on Unix)</li> <li><code>cmd.exe</code> (default on Windows)</li> <li><code>nushell</code></li> <li><code>python</code></li> <li><code>perl</code></li> <li><code>rscript</code> (for R scripts)</li> <li><code>ruby</code></li> <li><code>node</code> or <code>nodejs</code> (for NodeJS scripts)</li> </ul> <p><code>rattler-build</code> automatically detects the interpreter based on the file extension (<code>.sh</code>, <code>.bat</code>, <code>.nu</code>, <code>.py</code>, <code>.pl</code>, <code>.r</code>, <code>.rb</code>, <code>.js</code>) or you can specify it in the <code>interpreter</code> key in the <code>script</code> section of your recipe.</p> recipe.yaml<pre><code>build:\n  script: myscript.py  # automatically selects the Python interpreter\n\nrequirements:\n  build:\n    - python  # required to execute the `myscript.py` script\n</code></pre> <p>Note</p> <p>Using alternative interpreters is less battle-tested than using <code>bash</code> or <code>cmd.exe</code>. If you encounter any issues, please open an issue.</p>"},{"location":"build_script/#using-nushell","title":"Using <code>nushell</code>","text":"<p>In order to use <code>nushell</code> you can select the <code>interpreter: nu</code> or have a <code>build.nu</code> file in your recipe directory. Nushell works on Windows, macOS and Linux with the same syntax.</p> recipe.yaml<pre><code>build:\n  script:\n    interpreter: nu\n    content: |\n      echo \"Hello from nushell!\"\n\n# Note: it's required to have `nushell` in the `build` section of your recipe!\nrequirements:\n  build:\n    - nushell\n</code></pre>"},{"location":"build_script/#using-python","title":"Using <code>python</code>","text":"<p>In order to use <code>python</code> you can select the <code>interpreter: python</code> or have a <code>build.py</code> file in your recipe directory and <code>python</code> in the <code>requirements/build</code> section.</p> recipe.yaml<pre><code>build:\n  script:\n    interpreter: python\n    content: |\n      print(\"Hello from Python!\")\n\n# Note: it's required to have `python` in the `build` section of your recipe!\nrequirements:\n  build:\n    - python\n</code></pre>"},{"location":"build_script/#using-ruby","title":"Using <code>ruby</code>","text":"<p>In order to use <code>ruby</code> you can select the <code>interpreter: ruby</code> or have a <code>build.rb</code> file in your recipe directory and <code>ruby</code> in the <code>requirements/build</code> section.</p> recipe.yaml<pre><code>build:\n  script:\n    interpreter: ruby\n    content: |\n      puts \"Hello from Ruby!\"\n\n# Note: it's required to have `ruby` in the `build` section of your recipe!\nrequirements:\n  build:\n    - ruby\n</code></pre>"},{"location":"build_script/#using-nodejs","title":"Using <code>nodejs</code>","text":"<p>In order to use <code>nodejs</code> you can select the <code>interpreter: nodejs</code> (or <code>node</code>) or have a <code>build.js</code> file in your recipe directory and <code>nodejs</code> in the <code>requirements/build</code> section.</p> recipe.yaml<pre><code>build:\n  script:\n    interpreter: nodejs\n    content: |\n      console.log(\"Hello from NodeJS!\");\n\n# Note: it's required to have `nodejs` in the `build` section of your recipe!\nrequirements:\n  build:\n    - nodejs\n</code></pre>"},{"location":"build_script/#default-environment-variables-set-during-the-build-process","title":"Default environment variables set during the build process","text":"<p>During the build process, the following environment variables are set, on Windows with <code>build.bat</code> and on macOS and Linux with <code>build.sh</code>. By default, these are the only variables available to your build script. Unless otherwise noted, no variables are inherited from the shell environment in which you invoke <code>conda-build</code>. To override this behavior, see :ref:<code>inherited-env-vars</code>.</p> <code>ARCH</code> <p>Either <code>32</code> or <code>64</code>, to specify whether the build is 32-bit or 64-bit.   The value depends on the ARCH environment variable and defaults to the   architecture the interpreter running conda was compiled with.</p> <code>CMAKE_GENERATOR</code> <p>The CMake generator string for the current build   environment. On Linux systems, this is always <code>Unix Makefiles</code>. On Windows, it   is generated according to the Visual Studio version activated at build time, for   example, <code>Visual Studio 9 2008 Win64</code>.</p> <code>CONDA_BUILD=1</code> <p>Always set to indicate that the conda-build process is   running.</p> <code>CPU_COUNT</code> <p>Represents the number of CPUs on the system.</p> <code>SHLIB_EXT</code> <p>Denotes the shared library extension specific to the operating   system (e.g. <code>.so</code> for Linux, <code>.dylib</code> for macOS, and <code>.dll</code> for Windows).</p> <code>HTTP_PROXY</code>, <code>HTTPS_PROXY</code> <p>Inherited from the user's shell environment, specifying the HTTP and HTTPS   proxy settings.</p> <code>LANG</code> <p>Inherited from the user's shell environment, defining the system   language and locale settings.</p> <code>MAKEFLAGS</code> <p>Inherited from the user's shell environment. This can be used to   set additional arguments for the make command, such as -j2 to utilize 2 CPU   cores for building the recipe.</p> <code>PY_VER</code> <p>Specifies the Python version against which the build is occurring.   This can be modified with a <code>variants.yaml</code> file.</p> <code>PATH</code> <p>Inherited from the user's shell environment and augmented with the   activated host and build prefixes.</p> <code>PREFIX</code> <p>The build prefix to which the build script should install the   software.</p> <code>PKG_BUILDNUM</code> <p>Indicates the build number of the package currently being built.</p> <code>PKG_NAME</code> <p>The name of the package that is being built.</p> <code>PKG_VERSION</code> <p>The version of the package currently under construction.</p> <code>PKG_BUILD_STRING</code> <p>The complete build string of the package being built,   including the hash (e.g. py311h21422ab_0).</p> <code>PKG_HASH</code> <p>Represents the hash of the package being built, excluding the   leading 'h' (e.g. 21422ab). This is applicable from conda-build 3.0 onwards.</p> <code>PYTHON</code> <p>The path to the Python executable in the host prefix. Python is   installed in the host prefix only when it is listed as a host requirement.</p> <code>R</code> <p>The path to the R executable in the build prefix. R is installed in the   build prefix only when it is listed as a build requirement.</p> <code>RECIPE_DIR</code> <p>The directory where the recipe is located.</p> <code>SP_DIR</code> <p>The location of Python's site-packages, where Python libraries are installed.</p> <code>SRC_DIR</code> <p>The path to where the source code is unpacked or cloned. If the   source file is not a recognized archive format, this directory contains a copy   of the source file.</p> <code>STDLIB_DIR</code> <p>The location of Python's standard library.</p> <code>build_platform</code> <p>Represents the native subdirectory of the conda executable,   indicating the platform for which the build is occurring.</p> <p>Removed from <code>conda-build</code> are: - <code>NPY_VER</code> - <code>PY3K</code></p>"},{"location":"build_script/#windows","title":"Windows","text":"<p>Unix-style packages on Windows are built in a special <code>Library</code> directory under the build prefix. The environment variables listed in the following table are defined only on Windows.</p> Variable Description <code>LIBRARY_BIN</code> <code>&lt;build prefix&gt;\\Library\\bin</code>. <code>LIBRARY_INC</code> <code>&lt;build prefix&gt;\\Library\\include</code>. <code>LIBRARY_LIB</code> <code>&lt;build prefix&gt;\\Library\\lib</code>. <code>LIBRARY_PREFIX</code> <code>&lt;build prefix&gt;\\Library</code>. <code>SCRIPTS</code> <code>&lt;build prefix&gt;\\Scripts</code>. <p>Not yet supported in <code>rattler-build</code>:</p> <ul> <li><code>CYGWIN_PREFIX</code></li> <li><code>VS_MAJOR</code></li> <li><code>VS_VERSION</code></li> <li><code>VS_YEAR</code></li> </ul> <p>Additionally, the following variables are forwarded from the environment:</p> <ul> <li><code>ALLUSERSPROFILE</code></li> <li><code>APPDATA</code></li> <li><code>CommonProgramFiles</code></li> <li><code>CommonProgramFiles(x86)</code></li> <li><code>CommonProgramW6432</code></li> <li><code>COMPUTERNAME</code></li> <li><code>ComSpec</code></li> <li><code>HOMEDRIVE</code></li> <li><code>HOMEPATH</code></li> <li><code>LOCALAPPDATA</code></li> <li><code>LOGONSERVER</code></li> <li><code>NUMBER_OF_PROCESSORS</code></li> <li><code>PATHEXT</code></li> <li><code>ProgramData</code></li> <li><code>ProgramFiles</code></li> <li><code>ProgramFiles(x86)</code></li> <li><code>ProgramW6432</code></li> <li><code>PROMPT</code></li> <li><code>PSModulePath</code></li> <li><code>PUBLIC</code></li> <li><code>SystemDrive</code></li> <li><code>SystemRoot</code></li> <li><code>TEMP</code></li> <li><code>TMP</code></li> <li><code>USERDOMAIN</code></li> <li><code>USERNAME</code></li> <li><code>USERPROFILE</code></li> <li><code>windir</code></li> <li><code>PROCESSOR_ARCHITEW6432</code></li> <li><code>PROCESSOR_ARCHITECTURE</code></li> <li><code>PROCESSOR_IDENTIFIER</code></li> </ul>"},{"location":"build_script/#unix","title":"Unix","text":"<p>The environment variables listed in the following table are defined only on macOS and Linux.</p> Variable Description <code>HOME</code> Standard $HOME environment variable. <code>PKG_CONFIG_PATH</code> Path to <code>pkgconfig</code> directory, defaults to `$PREFIX/lib/pkgconfig <code>SSL_CERT_FILE</code> Path to <code>SSL_CERT_FILE</code> file. <code>CFLAGS</code> Empty, can be forwarded from env to set additional arguments to C compiler. <code>CXXFLAGS</code> Same as CFLAGS for C++ compiler. <code>LDFLAGS</code> Empty, additional flags to be passed to the linker when linking object files into an executable or shared object."},{"location":"build_script/#macos","title":"macOS","text":"<p>The environment variables listed in the following table are defined only on macOS.</p> Variable Description <code>MACOSX_DEPLOYMENT_TARGET</code> Same as the Anaconda Python macOS deployment target. Currently <code>10.9</code> for intel 32- and 64bit macOS, and 11.0 for arm64. <code>OSX_ARCH</code> <code>i386</code> or <code>x86_64</code> or <code>arm64</code>, depending on the target platform"},{"location":"build_script/#linux","title":"Linux","text":"<p>The environment variable listed in the following table is defined only on Linux.</p> Variable Description <code>LD_RUN_PATH</code> Defaults to <code>&lt;build prefix&gt;/lib</code>. <code>QEMU_LD_PREFIX</code> The prefix used by QEMU's user mode emulation for library paths. <code>QEMU_UNAME</code> Set qemu uname release string to 'uname'. <code>DEJAGNU</code> The path to the dejagnu testing framework used by the GCC test suite. <code>DISPLAY</code> The X11 display to use for graphical applications. <code>BUILD</code> Target triple (<code>{build_arch}-conda_{build_distro}-linux-gnu</code>) where build_distro is one of <code>cos6</code> or <code>cos7</code>, for Centos 6 or 7"},{"location":"compilers/","title":"Compilers and cross-compilation","text":"<p>To use a compiler in your project, it's best to use the <code>${{ compiler('lang') }}</code> template function. The compiler function works by taking a language, determining the configured compiler for that language, and adding some information about the target platform to the selected compiler. To configure a compiler for a specific language, the <code>variants.yaml</code> file can be used.</p> <p>For example, in a recipe that uses a C-compiler, you can use the following code:</p> <pre><code>requirements:\n  build:\n    - ${{ compiler('c') }}\n</code></pre> <p>To set the compiler that you want to use, create a variant config that looks like the following:</p> <pre><code>c_compiler:\n  - gcc\n\n# optionally you can specify a version\nc_compiler_version:\n  - 9.3.0\n</code></pre> <p>When the template function is evaluated, it will look something like: <code>gcc_linux-64 9.3.0</code>. You can define your own compilers. For example, for Rust you can use <code>${{ compiler('rust') }}</code> and <code>rust_compiler_{version}</code> in your variant config.</p>"},{"location":"compilers/#cross-compilation","title":"Cross-compilation","text":"<p>Cross-compilation is supported by <code>rattler-build</code> and the compiler template function is part of what makes it possible. When you want to cross-compile from <code>linux-64</code> to <code>linux-aarch64</code> (i.e. intel to ARM), you can pass <code>--target-platform linux-aarch64</code> to the <code>rattler-build</code> command. This will cause the compiler template function to select a compiler that is configured for <code>linux-aarch64</code>. The above example would resolve to <code>gcc_linux-aarch64 9.3.0</code>. Provided that the package is available for <code>linux-64</code> (your build platform), the compilation should succeed.</p> <p>The distinction between the <code>build</code> and <code>host</code> sections begins to make sense when thinking about cross-compilation. The <code>build</code> environment is resolved to packages that need to run at compilation time. For example, <code>cmake</code>, <code>gcc</code>, and <code>autotools</code> are all tools that need to be executed. Therefore, the <code>build</code> environment resolves to packages for the <code>linux-64</code> architecture (in our example). On the other hand, the <code>host</code> packages resolve to <code>linux-aarch64</code> - those are packages that we want to link against.</p> <pre><code># packages that need to run at build time (cmake, gcc, autotools, etc.)\n# in the platform that rattler-build is executed on (the build_platform)\nbuild:\n  - cmake\n  - ${{ compiler('c') }}\n# packages that we want to link against in the architecture we are\n# cross-compiling to the target_platform\nhost:\n  - libcurl\n  - openssl\n</code></pre>"},{"location":"config/","title":"Rattler-build configuration","text":"<p><code>rattler-build</code> can be configured by specifying <code>--config-file ~/.pixi/config.toml</code>. The config file is of the same format as pixi's global configuration file.</p>"},{"location":"config/#channels","title":"Channels","text":"<p>You can specify custom channels via the <code>default-channels</code> option.</p> config.toml<pre><code>default-channels = [\"conda-forge\", \"bioconda\"]\n</code></pre>"},{"location":"config/#package-format","title":"Package format","text":"<p>You can define the default package format to use for builds. It can be one of <code>tar-bz2</code> or <code>conda</code>. You can also add a compression level to the package format, e.g. <code>tar-bz2:&lt;number&gt;</code> (from 1 to 9) or <code>conda:&lt;number&gt;</code> (from -7 to 22).</p> config.toml<pre><code>[build]\npackage-format = \"conda:22\"\n</code></pre>"},{"location":"config/#mirror-configuration","title":"Mirror configuration","text":"<p>By specifying the <code>mirrors</code> section, you can instruct rattler-build to use mirrors when building. For more information, see pixi's documentation.</p> config.toml<pre><code>[mirrors]\n\"https://conda.anaconda.org/conda-forge\" = [\"https://prefix.dev/conda-forge\"]\n</code></pre>"},{"location":"config/#s3-configuration","title":"S3 configuration","text":"<p>You can configure your S3 buckets that are used during build by specifying <code>s3-options</code>. For more information, consult pixi's documentation.</p> config.toml<pre><code>[s3-options.my-bucket]\nendpoint-url = \"https://fsn1.your-objectstorage.com\"\nregion = \"US\"\nforce-path-style = false\n</code></pre>"},{"location":"converting_from_conda_build/","title":"Converting a recipe from conda-build","text":"<p>The recipe format of <code>rattler-build</code> differs in some aspects from <code>conda-build</code>. This document aims to help you convert a recipe from <code>conda-build</code> to <code>rattler-build</code>.</p>"},{"location":"converting_from_conda_build/#automatic-conversion","title":"Automatic conversion","text":"<p>To convert a recipe from <code>meta.yaml</code> to <code>recipe.yaml</code> you can use the automatic conversion utility.</p> <p>To install <code>conda-recipe-manager</code>, run</p> <pre><code>pixi global install conda-recipe-manager\n# or\nconda install -c conda-forge conda-recipe-manager\n</code></pre> <p>Then, run the conversion utility:</p> <pre><code>conda-recipe-manager convert my-recipe/meta.yaml\n</code></pre> <p>This will print the converted recipe to the console. You can save it to a file by redirecting the output:</p> <pre><code>conda-recipe-manager convert my-recipe/meta.yaml &gt; recipe.yaml\n</code></pre> <p>To learn more about the tool, or contribute, find the repository here.</p>"},{"location":"converting_from_conda_build/#converting-jinja-and-selectors","title":"Converting Jinja and selectors","text":"<p>To use <code>jinja</code> in the new recipes, you need to keep in mind two conversions. The <code>{% set version = \"1.2.3\" %}</code> syntax is replaced by the <code>context</code> section in the new recipe format.</p> <pre><code>{% set version = \"1.2.3\" %}\n</code></pre> <p>becomes</p> <pre><code>context:\n  version: \"1.2.3\"\n</code></pre> <p>To use the values or other Jinja expressions (e.g. from the variant config) you can use the <code>${{ version }}</code> syntax. Note the <code>$</code> sign before the curly braces - it makes Jinja fully compatible with the YAML format.</p> meta.yaml<pre><code># instead of\npackage:\n  version: \"{{ version }}\"\nsource:\n  url: https://example.com/foo-{{ version }}.tar.gz\n</code></pre> <p>becomes</p> recipe.yaml<pre><code>package:\n  version: ${{ version }}\nsource:\n  url: https://example.com/foo-${{ version }}.tar.gz\n</code></pre>"},{"location":"converting_from_conda_build/#converting-selectors","title":"Converting selectors","text":"<p><code>conda-build</code> has a line based \"selector\" system, to e.g. disable certain fields on Windows vs. Unix.</p> <p>In rattler-build we\u00a0use two different syntaxes: an <code>if/else/then</code> map or a inline jinja expression.</p> <p>A typical selector in <code>conda-build</code> looks something like this:</p> meta.yaml<pre><code>requirements:\n  host:\n    - pywin32  # [win]\n</code></pre> <p>To convert this to <code>rattler-build</code> syntax, you can use one of the following two syntaxes:</p> recipe.yaml<pre><code>requirements:\n  host:\n    - ${{ \"pywin32\" if win }}  # empty strings are automatically filtered\n    # or\n    - if: win\n      then:\n        - pywin32  # this list extends the outer list\n</code></pre>"},{"location":"converting_from_conda_build/#converting-the-recipe-script","title":"Converting the recipe script","text":"<p>We still support the <code>build.sh</code> script, but the <code>bld.bat</code> script was renamed to <code>build.bat</code> in order to be more consistent with the <code>build.sh</code> script.</p> <p>You can also choose a different name for your script:</p> <pre><code>build:\n  # note: if there is no extension, we will try to find .sh on unix and .bat on windows\n  script: my_build_script\n</code></pre> <p>There are also new ways of writing scripts, for example with <code>nushell</code> or <code>python</code></p> <p>Variant keys in build scripts</p> <p><code>conda-build</code> tries to analyze the build scripts for any usage of variant keys. We do not attempt that. If you want to use variant keys in your build script that are not used anywhere else you need to manually add them to your script environment, e.g.</p> recipe.yaml<pre><code>build:\n  script:\n    content: echo $MY_VARIANT\n    env:\n      MY_VARIANT: ${{ my_variant }}\n</code></pre>"},{"location":"converting_from_conda_build/#converting-the-recipe-structure","title":"Converting the recipe structure","text":"<p>There are a few differences in the recipe structure. However, the schema will tell you quite easily what is expected and you should see red squiggly lines in your editor (e.g. VSCode) if you make a mistake.</p> <p>Here are a few differences:</p> <ul> <li><code>build.run_exports</code> is now <code>requirements.run_exports</code></li> <li><code>requirements.run_constrained</code> is now <code>requirements.run_constraints</code></li> <li><code>build.ignore_run_exports</code> is now <code>requirements.ignore_run_exports.by_name</code></li> <li><code>build.ignore_run_exports_from</code> is now   <code>requirements.ignore_run_exports.from_package</code></li> <li>A <code>git</code> source now uses <code>git</code>, <code>tag</code>, ... and not <code>git_url</code> and <code>git_rev</code>, e.g.   <pre><code>git: https://github.com/foo/bar.git\ntag: 1.2.3\n</code></pre></li> </ul>"},{"location":"converting_from_conda_build/#converting-the-test-section","title":"Converting the test section","text":"<p>The <code>test</code> section is renamed to <code>tests</code> and is a list of independent tests. Each test runs in its own environment.</p> <p>Let's have a look at converting an existing test section:</p> meta.yaml<pre><code>test:\n  imports:\n    - mypackage\n  commands:\n    - mypackage --version\n</code></pre> <p>This would now be split into two tests:</p> recipe.yaml<pre><code>tests:\n  - script:\n      - mypackage --version\n  - python:\n      imports:\n        - mypackage\n      # by default we perform a `pip check` in the python test but\n      # it can be disabled by setting this to false\n      pip_check: false\n</code></pre> <p>The <code>script</code> tests also take a <code>requirements</code> section with <code>run</code> and <code>build</code> requirements. The <code>build</code> requirements can be used to install emulators and similar tools that need to run to execute tests in a cross-compilation environment.</p>"},{"location":"converting_from_conda_build/#automatic-feedstock-conversion","title":"Automatic feedstock conversion","text":"<p>Use the tool <code>feedrattler</code> by hadim to go directly from an existing conda-forge v0 recipe feedstock to the new v1 recipe used by rattler-build.</p> <p>You can install and use it directly by running <code>pixi exec</code>: <pre><code>pixi exec feedrattler my-awesome-feedstock\n</code></pre></p> <p>It uses the <code>conda-recipe-manager</code> for the generation of the recipe and <code>gh</code> or a <code>GITHUB_TOKEN</code> for creating the conversion PR in your name.</p> <p>Alternative installation: <pre><code># Globally install the tool\npixi global install feedrattler\n# or in a workspace\npixi add feedrattler\n# or using conda/mamba\nconda install -c conda-forge feedrattler\n</code></pre></p>"},{"location":"create_patch/","title":"Creating patches","text":"<p>When packaging software, you often need to make small source code changes \u2013 fixing a typo, applying a bug fix, or adapting build scripts. Instead of maintaining a fork of the upstream project, you can create patch files that are applied during the build process.</p> <p><code>rattler-build</code> provides a streamlined workflow for creating patches using the <code>debug</code> and <code>create-patch</code> commands.</p>"},{"location":"create_patch/#how-it-works","title":"How it works","text":"<p>The <code>debug</code> command sets up a build environment and downloads sources without running the actual build script. This gives you a clean workspace to make changes. The <code>create-patch</code> command then compares your modified files against the original sources and generates a unified diff patch.</p>"},{"location":"create_patch/#basic-workflow","title":"Basic workflow","text":"<pre><code># Set up debug environment (downloads sources, no build)\nrattler-build debug --recipe recipe.yaml\n\n# Edit files in the work directory\ncd output/bld/rattler-build_&lt;package&gt;_*/work\nvim some_file.c\n\n# Generate patch\nrattler-build create-patch --directory . --name fix-typo\n\n# Add to recipe\n</code></pre> recipe.yaml<pre><code>source:\n  - url: https://example.com/package.tar.gz\n    sha256: abc123...\n    patches:\n      - fix-typo.patch\n</code></pre>"},{"location":"create_patch/#command-options","title":"Command options","text":"<p>The <code>create-patch</code> command supports the following options:</p> <ul> <li><code>--directory &lt;DIR&gt;</code> - Work directory containing the modified sources (required)</li> <li><code>--name &lt;NAME&gt;</code> - Patch filename without .patch extension (default: \"changes\")</li> <li><code>--patch-dir &lt;DIR&gt;</code> - Directory to write the patch file (default: recipe directory)</li> <li><code>--exclude &lt;PATTERNS&gt;</code> - Files to exclude from the patch (comma-separated glob patterns)</li> <li><code>--dry-run</code> - Preview changes without creating a file</li> </ul>"},{"location":"create_patch/#examples","title":"Examples","text":"<p>Generate a patch with a custom name:</p> <pre><code>rattler-build create-patch --directory work/ --name fix-build-system\n</code></pre> <p>Preview changes before creating the patch:</p> <pre><code>rattler-build create-patch --directory work/ --dry-run\n</code></pre> <p>Create a patch in a dedicated patches folder:</p> <pre><code>rattler-build create-patch --directory work/ \\\n                           --name fix-compilation \\\n                           --patch-dir patches/\n</code></pre>"},{"location":"create_patch/#supported-source-types","title":"Supported source types","text":"<p>Currently, the <code>create-patch</code> command supports:</p> <ul> <li>URL sources - Creates patches for extracted archives (tar.gz, zip, etc.)</li> <li>Git sources - \u26a0\ufe0f Not yet implemented</li> <li>Path sources - \u26a0\ufe0f Not yet implemented</li> </ul>"},{"location":"experimental_features/","title":"Experimental features","text":"<p>Warning</p> <p>These are experimental features of <code>rattler-build</code> and may change or go away completely.</p> <p>Currently only the <code>build</code> and <code>rebuild</code> commands support the following experimental features.</p> <p>To enable them, use the <code>--experimental</code> flag with the command. Or, use the environment variable, <code>RATTLER_BUILD_EXPERIMENTAL=true</code>.</p>"},{"location":"experimental_features/#jinja-functions","title":"Jinja functions","text":""},{"location":"experimental_features/#load_from_filefile_path","title":"<code>load_from_file(&lt;file_path&gt;)</code>","text":"<p>The Jinja function <code>load_from_file</code> allows loading from files; specifically, it allows loading from <code>toml</code>, <code>json</code>, and <code>yaml</code> file types to an object to allow it to fetch things directly from the file. It loads all other files as strings.</p>"},{"location":"experimental_features/#usage","title":"Usage","text":"<p><code>load_from_file</code> is useful when there is a project description in a well-defined project file such as <code>Cargo.toml</code>, <code>package.json</code>, <code>pyproject.toml</code>, <code>package.yaml</code>, or <code>stack.yaml</code>. It enables the recipe to be preserved in as simple a state as possible, especially when there is no need to keep the changes in sync; some example use cases for this are with CI/CD infrastructure or when there is a well-defined output format.</p> <p>Below is an example loading a <code>Cargo.toml</code> inside of the <code>rattler-build</code> GitHub repository:</p> recipe.yaml<pre><code>context:\n  name: ${{ load_from_file(\"Cargo.toml\").package.name }}\n  version: ${{ load_from_file(\"Cargo.toml\").package.version }}\n  source_url: ${{ load_from_file(\"Cargo.toml\").package.homepage }}\n  rust_toolchain: ${{ load_from_file(\"rust-toolchains\") }}\n\npackage:\n  name: ${{ name }}\n  version: ${{ version }}\n\nsource:\n  git: ${{ source_url }}\n  tag: ${{ source_tag }}\n\nrequirements:\n  build:\n    - rust ==${{ rust_toolchain }}\n\nbuild:\n  script: cargo build --release -p ${{ name }}\n\ntest:\n  - script: cargo test -p ${{ name }}\n  - script: cargo test -p rust-test -- --test-threads=1\n\nabout:\n  home: ${{ source_url }}\n  repository: ${{ source_url }}\n  documentation: ${{ load_from_file(\"Cargo.toml\").package.documentation }}\n  summary: ${{ load_from_file(\"Cargo.toml\").package.description }}\n  license: ${{ load_from_file(\"Cargo.toml\").package.license }}\n</code></pre>"},{"location":"experimental_features/#git-functions","title":"<code>git</code> functions","text":"<p><code>git</code> functions are useful for getting the latest tag and commit hash. These can be used in the <code>context</code> section of the recipe, to fetch version information from a repository.</p> Examples <pre><code># latest tag in the repo\ngit.latest_tag(&lt;git_repo_url&gt;)\n\n# latest tag revision(aka, hash of tag commit) in the repo\ngit.latest_tag_rev(&lt;git_repo_url&gt;)\n\n# latest commit revision(aka, hash of head commit) in the repo\ngit.head_rev(&lt;git_repo_url&gt;)\n</code></pre>"},{"location":"experimental_features/#usage_1","title":"Usage","text":"<p>These can be useful for automating minor things inside of the recipe itself, such as if the current version is the latest version or if the current hash is the latest hash, etc.</p> recipe.yaml<pre><code>context:\n  git_repo_url: \"https://github.com/prefix-dev/rattler-build\"\n  latest_tag: ${{ git.latest_tag( git_repo_url ) }}\n\npackage:\n  name: \"rattler-build\"\n  version: ${{ latest_tag }}\n\nsource:\n  git: ${{ git_repo_url }}\n  tag: ${{ latest_tag }}\n</code></pre> <p>There is currently no guarantee of caching for repo fetches when using <code>git</code> functions. This may lead to some performance issues.</p>"},{"location":"highlevel/","title":"What is <code>rattler-build</code>?","text":"<p><code>rattler-build</code> is a tool to build and package software so that it can be installed on any operating system \u2013 with any compatible package manager such as <code>mamba</code>, <code>conda</code>, or <code>rattler</code>. We are also intending for <code>rattler-build</code> to be used as a library to drive builds of packages from any other recipe format in the future.</p>"},{"location":"highlevel/#how-does-rattler-build-work","title":"How does <code>rattler-build</code> work?","text":"<p>Building of packages consists of several steps. It all begins with a <code>recipe.yaml</code> file that specifies how the package is to be built and what the dependencies are. From the recipe file, <code>rattler-build</code> executes several steps:</p> <ol> <li> <p>Rendering: Parse the recipe file and evaluate conditionals, Jinja expressions, and variables, and variants.</p> </li> <li> <p>Fetch source: Retrieve specified source files, such as <code>.tar.gz</code> files, <code>git</code> repositories, local paths. Additionally, this step will apply patches that can be specified alongside the source file.</p> </li> <li> <p>Install build environments: Download and install dependencies into temporary \"host\" and \"build\" workspaces. Any dependencies that are needed at build time are installed in this step.</p> </li> <li> <p>Build source: Execute the build script to build/compile the source code and install it into the host environment.</p> </li> <li> <p>Prepare package files: Collect all files that are new in the \"host\" environment and apply some transformations if necessary; specifically, we edit the <code>rpath</code> on <code>Linux</code> and <code>macOS</code> to make binaries relocatable.</p> </li> <li> <p>Package: Bundle all the files in a package and write out any additional metadata into the <code>info/index.json</code>, <code>info/about.json</code>, and <code>info/paths.json</code> files. This also creates the test files that are bundled with the package.</p> </li> <li> <p>Test: Run any tests specified in the recipe. The package is considered done if it passes all the tests, otherwise its moved to <code>broken/</code> in the output directory.</p> </li> </ol> <p>After this process, a package is created. This package can be uploaded to somewhere like a custom prefix.dev private or public channel.</p>"},{"location":"highlevel/#how-to-run-rattler-build","title":"How to run <code>rattler-build</code>","text":"<p>Running <code>rattler-build</code> is straightforward. It can be done on the command line:</p> <pre><code>rattler-build build --recipe myrecipe/recipe.yaml\n</code></pre> <p>A custom channel that is not conda-forge (the default) can be specified like so:</p> <pre><code>rattler-build build -c robostack --recipe myrecipe/recipe.yaml\n</code></pre> <p>You can also use the <code>--recipe-dir</code> argument if you want to build all the packages in a directory:</p> <pre><code>rattler-build build --recipe-dir myrecipes/\n</code></pre>"},{"location":"highlevel/#overview-of-a-recipeyaml","title":"Overview of a <code>recipe.yaml</code>","text":"<p>A <code>recipe.yaml</code> file is separated into multiple sections and can conditionally include or exclude sections. Recipe files also support a limited amount of string interpolation with Jinja (specifically <code>minijinja</code> in our case).</p> <p>A simple example of a recipe file for the <code>zlib</code> package would look as follows:</p> recipe.yaml<pre><code># variables from the context section can be used in the rest of the recipe\n# in jinja expressions\ncontext:\n  version: 1.2.13\n\npackage:\n  name: zlib\n  version: ${{ version }}\n\nsource:\n  url: http://zlib.net/zlib-${{ version }}.tar.gz\n  sha256: b3a24de97a8fdbc835b9833169501030b8977031bcb54b3b3ac13740f846ab30\n\nbuild:\n  # build numbers can be set arbitrarily\n  number: 0\n  script:\n    # build script to install the package into the $PREFIX (host prefix)\n    - if: unix\n      then:\n      - ./configure --prefix=$PREFIX\n      - make -j$CPU_COUNT\n    - if: win\n      then:\n      - cmake -G \"Ninja\" -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=%LIBRARY_PREFIX%\n      - ninja install\n\nrequirements:\n  build:\n    # compiler is a special function.\n    - ${{ compiler(\"c\") }}\n    # The following two dependencies are only needed on Windows,\n    # and thus conditionally selected\n    - if: win\n      then:\n        - cmake\n        - ninja\n    - if: unix\n      then:\n        - make\n</code></pre> <p>The sections of a recipe are:</p> sections description <code>context</code> Defines variables that can be used in the Jinja context later in the recipe (e.g. name and version are commonly interpolated in strings) <code>package</code> This section defines the name and version of the package you are currently building and will be the name of the final output <code>source</code> Defines where the source code is going to be downloaded from and checksums <code>build</code> Settings for the build and the build script <code>requirements</code> Allows the definition of build, host, run and run-constrained dependencies"},{"location":"internals/","title":"What does <code>rattler-build</code> do to build a package?","text":"<p><code>rattler-build</code> creates conda packages which are relocatable packages. These packages are built up with some rules and conventions in mind.</p>"},{"location":"internals/#what-goes-into-a-package","title":"What goes into a package?","text":"<p>Generally speaking, any new files that are copied into the <code>$PREFIX</code> directory at build time are part of the new package. However, there is some filtering going on to exclude unwanted files, and <code>noarch: python</code> packages have special handling as well. The rules are as follows:</p>"},{"location":"internals/#filtering","title":"Filtering","text":""},{"location":"internals/#general-file-filtering","title":"General File Filtering","text":"<p>Certain files are filtered out to prevent them from being included in the package. These include:</p> <ul> <li>.pyo files: Optimized Python files are not included because they are   considered harmful.</li> <li>.la files: Libtool archive files that are not needed at runtime.</li> <li>.DS_Store files: macOS-specific files that are irrelevant to the package.</li> <li>.git files and directories: Version control files, including <code>.gitignore</code>   and the <code>.git</code> directory, which are not needed in the package.</li> <li>share/info/dir This file is ignored because it would be written from   multiple packages.</li> </ul>"},{"location":"internals/#special-handling-for-noarch-python-packages","title":"Special Handling for <code>noarch: python</code> Packages","text":"<p>For packages marked as <code>noarch: python</code>, special transformations are applied to ensure compatibility across different platforms:</p> <ul> <li>Stripping Python Library Prefix: The \"lib/pythonX.X\" prefix is removed,   retaining only the \"site-packages\" part of the path.</li> <li>Skipping <code>__pycache__</code> Directories and <code>.pyc</code> Files: These are excluded   and recreated during installation (they are specific to the Python version).</li> <li>Replacing <code>bin</code> and <code>Scripts</code> Directories:<ul> <li>On Unix systems, the <code>bin</code> directory is replaced with <code>python-scripts</code>.</li> <li>On Windows systems, the <code>Scripts</code> directory is replaced with   <code>python-scripts</code>.</li> </ul> </li> <li>Remove explicitly mentioned entrypoints: For <code>noarch: python</code> packages,   entry points registered in the package are also taken into account. Files in   the <code>bin</code> or <code>Scripts</code> directories that match entry points are excluded to   avoid duplications.</li> </ul>"},{"location":"internals/#symlink-handling","title":"Symlink Handling","text":"<p>Symlinks are carefully managed to ensure they are relative rather than absolute, which aids in making the package relocatable:</p> <ul> <li>Absolute symlinks pointing within the <code>$PREFIX</code> are converted to relative   symlinks.</li> <li>On Unix systems, this conversion is handled directly by creating new relative   symlinks.</li> <li>On Windows, a warning is issued since symlink creation requires administrator   privileges.</li> </ul>"},{"location":"internals/#making-packages-relocatable-with-rattler-build","title":"Making Packages Relocatable with <code>rattler-build</code>","text":"<p>Often, the most challenging aspect of building a package using <code>rattler-build</code> is making it relocatable. A relocatable package can be installed into any prefix, allowing it to be used outside the environment in which it was built. This is in contrast to a non-relocatable package, which can only be utilized within its original build environment.</p> <p><code>rattler-build</code> automatically performs the following actions to make packages relocatable:</p> <ol> <li>Binary object file conversion: Binary object files are converted to use    relative paths using <code>install_name_tool</code> on macOS and <code>patchelf</code> on Linux.    This uses <code>$ORIGIN</code> for elf files on Linux and <code>@loader_path</code> for Mach-O    files on macOS to make the <code>rpath</code> relative to the executable / shared    library.</li> <li>Text file prefix registration: Any text file without <code>NULL</code> bytes    containing the placeholder prefix have the registered prefix replaced with    the install prefix.</li> <li>Binary file prefix detection and registration: Binary files containing the build prefix can be automatically registered. The registered files will have their build prefix replaced with the install prefix at install time. This works by padding the install prefix with null terminators, such that the length of the binary file remains the same. The build prefix must be long enough to accommodate any reasonable installation prefix. On macOS and Linux, <code>rattler-build</code> pads the build prefix to 255 characters by appending <code>_placehold</code> to the end of the build directory name.</li> </ol>"},{"location":"multiple_output_cache/","title":"The cache for multiple outputs","text":"<p>Note</p> <p>The \"multi-output\" cache is a little bit different from a compilation cache. If you look for tips and tricks on how to use <code>sccache</code> or <code>ccache</code> with <code>rattler-build</code>, please refer to the tips and tricks section.</p> <p>Sometimes you build a package and want to split the contents into multiple sub-packages. For example, when building a C/C++ package, you might want to create multiple packages for the runtime requirements (library), and the development time requirements such as header files.</p> <p>The \"cache\" output makes this easy. It allows you to specify a single top-level cache that can produce arbitrary files, that can then be used in other packages.</p> <p>Let's take a look at an example:</p> recipe.yaml<pre><code>recipe:\n  name: mypackage\n  version: '0.1.0'\n\ncache:\n  source:\n    - url: https://example.com/library.tar.gz\n      sha256: 1234567890abcdef1234567890abcdef1234567890abcdef1234567890abcdef\n\n  requirements:\n    build:\n      - ${{ compiler('c') }}\n\n  build:\n    script:\n      - mkdir -p $PREFIX/lib\n      - mkdir -p $PREFIX/include\n      - echo \"This is the library\" &gt; lib/library.txt\n      - echo \"This is the header\" &gt; include/header.txt\n\noutputs:\n  - package:\n      name: mypackage-library\n    build:\n      files:\n        - lib/*\n\n  - package:\n      name: mypackage-headers\n    build:\n      files:\n        - include/*\n</code></pre> <p>Note</p> <p>Since this is an experimental feature, you need to pass the <code>--experimental</code> flag to enable parsing of the <code>cache</code> top-level section.</p> <p>In this example, we have a single package called <code>mypackage</code> that creates two outputs: <code>mypackage-library</code> and <code>mypackage-headers</code>. The cache output will run like a regular output, but after the build is finished, the files will be copied to a \"cache\" directory (in your output folder, under <code>output/build_cache</code>).</p> <p>The files in the cache folder are then copied into the <code>$PREFIX</code> of each output package. Since they are \"new\" files in the prefix, they will be included in the output package. The easiest way to select a subset of the files in the prefix is by using the <code>files</code> field in the output definition. You can use a list of globs to select only the files that you want.</p> <p>For something more complicated you can also use <code>include</code> and <code>exclude</code> fields in the <code>files</code> selector. Please refer to the the build options documentation.</p>"},{"location":"multiple_output_cache/#run-exports-from-the-cache","title":"Run exports from the cache","text":"<p>Since the cache output also has build- and host requirements we need to additionally take care of eventual \"run-exports\" from the cache output. Run exports from the cache-dependencies are handled very similar to the run exports from a given output. We append any run exports to the outputs.</p> <p>If the cache has an \"ignore run exports\" section, than we apply those filters at the cache level. If the output ignores any run exports, then we also ignore the run-exports if they would come from the cache.</p>"},{"location":"multiple_output_cache/#source-code-in-the-cache","title":"Source code in the cache","text":"<p>The cache output has its own <code>source</code> section. For every output, the (dirty) source is restored from the cache directory. Outputs can layer additional files on top of the cache source. However, if you already ran <code>cmake</code> in the cache output, you can continue from where the build left off. This is useful when you want to e.g. build additional components (such as Python bindings) on top of the already-built library.</p>"},{"location":"multiple_output_cache/#c-example-that-builds-python-bindings-on-top-of-a-library","title":"C++ Example that builds Python bindings on top of a library","text":"<p>You can find an example (with source code) here: Link.</p> variants.yaml<pre><code>python:\n  - \"3.12.*\"\n  - \"3.11.*\"\n</code></pre> <p>And the corresponding recipe:</p> recipe.yaml<pre><code>recipe:\n  name: calculator\n  version: 1.0.0\n\ncache:\n  source:\n    path: ../\n\n  requirements:\n    build:\n      - ${{ compiler('cxx') }}\n      - cmake\n      - ninja\n  build:\n    script:\n      # make sure that `alternative_name.md` is not present\n      - test ! -f ./alternative_name.md\n      - mkdir build\n      - cd build\n      - cmake $SRC_DIR -GNinja ${CMAKE_ARGS}\n      - ninja install\n\noutputs:\n  # this first output will include all files installed during the cache build\n  - package:\n      name: libcalculator\n\n    requirements:\n      run_exports:\n        - ${{ pin_subpackage('libcalculator') }}\n  # This output will build the Python bindings using CMake and then create new\n  # packages with the Python bindings\n  - package:\n      name: py-calculator\n    source:\n      - path: ../README.md\n        file_name: alternative_name.md\n\n    requirements:\n      build:\n        - ${{ compiler('cxx') }}\n        - cmake\n        - ninja\n      host:\n        - pybind11\n        - python\n        - libcalculator\n\n    build:\n      script:\n        # assert that the README.md file is present\n        - test -f ./alternative_name.md\n        - cd build\n        - cmake $SRC_DIR -GNinja ${CMAKE_ARGS} -DBUILD_PYTHON_BINDINGS=ON\n        - ninja install\n</code></pre>"},{"location":"package_spec/","title":"Package specification","text":"<p><code>rattler-build</code> produces \"conda\" packages. These packages work with the <code>mamba</code> and <code>conda</code> package managers, and they work cross-platform on Windows, Linux and macOS.</p> <p>By default, a conda package is a <code>tar.bz2</code> archive which contains:</p> <ul> <li>Metadata under the <code>info/</code> directory</li> <li>A collection of files that are installed directly into an install prefix</li> </ul> <p>The format is identical across platforms and operating systems. During the install process, all files are extracted into the install prefix, except the ones in <code>info/</code>. Installing a conda package into an environment is similar to executing the following commands:</p> <pre><code>cd &lt;environment prefix&gt;\ntar xjf mypkg-1.0.0-h2134.tar.bz2\n</code></pre> <p>Only files, including symbolic links, are part of a conda package. Directories are not included. Directories are created and removed as needed, but you cannot create an empty directory from the tar archive directly.</p> <p>There is also a newer archive type, suffixed with <code>.conda</code>. This archive type consists of an outer \"zip\" archive that is not compressed, and two inner archives that are compressed with <code>zstd</code>, which is very fast for decompression.</p> <p>The inner archives are split into <code>info</code> and <code>pkg</code> files, which makes it possible to extract only the <code>info</code> part of the archive (only the metadata), which is often smaller in size.</p>"},{"location":"package_spec/#package-filename","title":"Package filename","text":"<p>A conda package conforms to the following filename:</p> <pre><code>&lt;name&gt;-&lt;version&gt;-&lt;hash&gt;.tar.bz2 OR &lt;name&gt;-&lt;version&gt;-&lt;hash&gt;.conda\n</code></pre>"},{"location":"package_spec/#special-files-in-packages","title":"Special files in packages","text":"<p>There are some special files in a package:</p> <ul> <li>activation and deactivation scripts that are executed when the environment is   activated or deactivated</li> <li>post-link and pre-unlink scripts that are executed when the package is   installed or uninstalled</li> </ul> <p>You can read more about these files in the activation scripts and other special files section.</p>"},{"location":"package_spec/#package-metadata","title":"Package metadata","text":"<p>The <code>info/</code> directory contains all metadata about a package. Files in this location are not installed under the install prefix. Although you are free to add any file to this directory, conda only inspects the content of the files discussed below:</p>"},{"location":"package_spec/#infoindexjson","title":"<code>info/index.json</code>","text":"<p>This file contains basic information about the package, such as name, version, build string, and dependencies. The content of this file is stored in <code>repodata.json</code>, which is the repository index file, hence the name <code>index.json</code>. The JSON object is a dictionary containing the keys shown below.</p> <code>name: string</code> <p>The lowercase name of the package. May contain lowercase characters, underscores, and dashes.</p> <code>version: string</code> <p>The package version. May not contain \"<code>-</code>\". Acknowledges PEP 440.</p> <code>build: string</code> <p>The build string. May not contain \"<code>-</code>\". Differentiates builds of packages with   otherwise identical names and versions, such as:</p> <ul> <li>A build with other dependencies, such as Python 3.4 instead of Python 2.7.</li> <li>A bug fix in the build process.</li> <li>Some different optional dependencies, such as MKL versus ATLAS linkage.     Nothing in conda actually inspects the build string. Strings such as     <code>np18py34_1</code> are designed only for human readability and conda never parses     them.</li> </ul> <code>build_number: integer</code> <p>A non-negative integer representing the build number of the package. Unlike   the build string, the <code>build_number</code> is inspected by conda. Conda uses it to   sort packages that have otherwise identical names and versions to determine   the latest one. This is important because new builds that contain bug fixes   for the way a package is built may be added to a repository.</p> <code>depends: list of match specs</code> <p>A list of dependency specifications, where each element is a string. These come from the <code>run</code> section of the recipe or any run exports of dependencies.</p> <code>constrains: list of match specs</code> <p>A list of optional dependency constraints. The packages listed under <code>constrains</code> are not installed by default, but if they are installed they have   to respect the constraints.</p> <code>subdir: string</code> <p>The subdir (like <code>linux-64</code>) of this package.</p> <code>arch: string</code> <p>Optional. The architecture the package is built for. EXAMPLE: <code>x86_64</code>. This key is generally not used (duplicate information from <code>sudir</code>).</p> <code>platform: string</code> <p>Optional. The OS that the package is built for, e.g. <code>osx</code>. This key is generally not used (duplicate information from <code>sudir</code>).</p>"},{"location":"package_spec/#infopathsjson","title":"<code>info/paths.json</code>","text":"<p>The <code>paths.json</code> file lists all files that are installed into the environment.</p> <p>It consists of a list of path entries, each with the following keys:</p> <code>_path: string</code> <p>The relative path of the file</p> <code>path_type: optional, string</code> <p>The type of linking, can be <code>hardlink</code>, <code>softlink</code>, or <code>directory</code>. Default is   <code>hardlink</code>.</p> <code>file_mode: - optional, string</code> <p>The file mode can be <code>binary</code> or <code>text</code>. This is only relevant for prefix   replacement.</p> <code>prefix_placeholder: optional, string</code> <p>The prefix placeholder string that is encoded in the text or binary file, which   is replaced at installation time. Note that this prefix placeholder uses   <code>/</code> even on Windows.</p> <code>no_link: bool, optional</code> <p>Determines whether this file should be linked or not when installing the package   (linking the file from the cache into the environment). Defaults to <code>false</code>.</p> <code>sha256: string</code> <p>The <code>SHA256</code> hash of the file. For symbolic links it contains the <code>SHA256</code> hash of   the file pointed to.</p> <code>size_in_bytes: number</code> <p>The size, in bytes, of the file. For symbolic links, it contains the file size   of the file pointed to.</p> <p>Due to the way the binary replacement works, the placeholder prefix must be longer than the install prefix.</p>"},{"location":"package_spec/#infolicense","title":"<code>info/license/&lt;...&gt;</code>","text":"<p>All licenses mentioned in the recipe are copied to this folder.</p>"},{"location":"package_spec/#infoaboutjson","title":"<code>info/about.json</code>","text":"<p>Optional file. Contains the entries of the \"about\" section of the recipe of the <code>recipe.yaml</code> file. The following keys are added to <code>info/about.json</code> if present in the build recipe:</p> <p>Renamed fields</p> <p>The new recipe spec renamed a few fields (from conda-build's original implementation). This means that some fields in the <code>about.json</code> file still have the old names (for backwards compatibility), while you would generally use different names in the recipe.</p> <code>home: url (from about.homepage)</code> <p>The URL of the homepage of the package.</p> <code>dev_url: url (from about.repository)</code> <p>The URL of the development repository of the package.</p> <code>doc_url: url (from about.documentation)</code> <p>The URL of the documentation of the package.</p> <code>license: string (from about.license)</code> <p>The SPDX license identifier of the package.</p> <code>summary: string</code> <p>A short summary of the package.</p> <code>description: string</code> <p>A longer description of the package.</p> <code>license_family: string</code> <p>(this field is not used anymore as we rely on SPDX license identifiers)</p>"},{"location":"package_spec/#inforecipe","title":"<code>info/recipe/&lt;...&gt;</code>","text":"<p>A directory containing the full contents of the build recipe. This folder also contains a rendered version of the recipe (<code>rendered_recipe.yaml</code>). This rendered version is used for the <code>rebuild</code> command. However, note that currently this format is still in flux and can change at any time.</p> <p>You can also use <code>--no-include-recipe</code> to disable the inclusion of the recipe in the package.</p>"},{"location":"rebuild/","title":"Rebuilding a package","text":"<p>The <code>rebuild</code> command allows you to rebuild a package from an existing package. The main use case is to examine if a package can be rebuilt in a reproducible manner. You can read more about reproducible builds here.</p>"},{"location":"rebuild/#usage","title":"Usage","text":"<pre><code>rattler-build rebuild --package-file ./mypkg-0.1.0-h60d57d3_0.tar.bz2\n</code></pre>"},{"location":"rebuild/#how-it-works","title":"How it works","text":"<p>The recipe is \"rendered\" and stored into the package. The way the recipe is rendered is subject to change. For the moment, the rendered recipe is stored as <code>info/recipe/rendered_recipe.yaml</code>. It includes the exact package versions that were used at build time. When rebuilding, we use the package resolutions from the rendered recipe, and execute the same build script as the original package.</p> <p>We also take great care to sort files in a deterministic manner as well as erasing any time stamps. The <code>SOURCE_DATE_EPOCH</code> environment variable is set to the same timestamp as the original build for additional determinism (some build tools use this variable to set timestamps).</p>"},{"location":"rebuild/#how-to-check-the-reproducibility-of-a-package","title":"How to check the reproducibility of a package","text":"<p>There is an excellent tool called <code>diffoscope</code> that allows you to compare two packages and see the differences. You can install it with <code>pixi</code>:</p> <pre><code>pixi global install diffoscope\n</code></pre> <p>To compare two packages, you can use the following command:</p> <pre><code>rattler-build rebuild ./build0.tar.bz2\ndiffoscope ./build0.tar.bz2 ./mypkg-0.1.0-h60d57d3_0.tar.bz2\n</code></pre>"},{"location":"recipe_generation/","title":"Generating recipes for different ecosystems","text":"<p>Rattler-build has some builtin functionality to generate recipes for different (existing) ecosystems.</p> <p>Currently we support the following ecosystems:</p> <ul> <li><code>pypi</code> (Python) - generates a recipe for a Python package</li> <li><code>cran</code> (R) - generates a recipe for an R package</li> </ul> <p>To generate a recipe for a Python package, you can use the following command:</p> <pre><code>rattler-build generate-recipe pypi jinja2\n</code></pre> <p>This will generate a recipe for the <code>jinja2</code> package from PyPI and print it to the console. To turn it into a recipe, you can either pipe the stdout to a file or use the <code>-w</code> flag. The <code>-w</code> flag will create a new folder with the recipe in it.</p> <p>The generated recipe for <code>jinja2</code> will look something like:</p> recipe.yaml<pre><code>package:\n  name: jinja2\n  version: 3.1.4\n\nsource:\n- url: https://files.pythonhosted.org/packages/ed/55/39036716d19cab0747a5020fc7e907f362fbf48c984b14e62127f7e68e5d/jinja2-3.1.4.tar.gz\n  sha256: 4a3aee7acbbe7303aede8e9648d13b8bf88a429282aa6122a993f0ac800cb369\n\nbuild:\n  script: python -m pip install .\n\nrequirements:\n  host:\n  - flit_core &lt;4\n  - python &gt;=3.7\n  - pip\n  run:\n  - python &gt;=3.7\n  - markupsafe &gt;=2.0\n  # - babel &gt;=2.7  # extra == 'i18n'\n\ntests: []\n\nabout:\n  summary: A very fast and expressive template engine.\n  documentation: https://jinja.palletsprojects.com/\n</code></pre>"},{"location":"recipe_generation/#generating-recipes-for-r-packages","title":"Generating recipes for R packages","text":"<p>To generate a recipe for an R package, you can use the following command:</p> <pre><code>rattler-build generate-recipe cran dplyr\n</code></pre> <p>The <code>R</code> recipe generation supports some additional flags:</p> <ul> <li><code>-u/--universe</code> select an R universe to use (e.g. <code>bioconductor</code>)</li> <li><code>-t/--tree</code> generate multiple recipes, for every dependency as well</li> </ul> <p>R packages will be prefixed with <code>r-</code> to avoid name conflicts with Python packages. The generated recipe for <code>dplyr</code> will look something like:</p> recipe.yaml<pre><code>package:\n  name: r-dplyr\n  version: 1.1.4\n\nsource:\n- url: https://cran.r-project.org/src/contrib/dplyr_1.1.4.tar.gz\n  md5: e3066ea859b26e0d3b992c476ea3af2e\n\nbuild:\n  script: R CMD INSTALL --build .\n  python: {}\n\nrequirements:\n  host:\n  - r-base &gt;=3.5.0\n  run:\n  - r-cli &gt;=3.4.0\n  - r-generics\n  - r-glue &gt;=1.3.2\n  - r-lifecycle &gt;=1.0.3\n  - r-magrittr &gt;=1.5\n  - r-methods\n  - r-pillar &gt;=1.9.0\n  - r-r6\n  - r-rlang &gt;=1.1.0\n  - r-tibble &gt;=3.2.0\n  - r-tidyselect &gt;=1.2.0\n  - r-utils\n  - r-vctrs &gt;=0.6.4\n  # -  r-bench  # suggested\n  # -  r-broom  # suggested\n  # -  r-callr  # suggested\n  # -  r-covr  # suggested\n  # -  r-dbi  # suggested\n  # -  r-dbplyr &gt;=2.2.1  # suggested\n  # -  r-ggplot2  # suggested\n  # -  r-knitr  # suggested\n  # -  r-lahman  # suggested\n  # -  r-lobstr  # suggested\n  # -  r-microbenchmark  # suggested\n  # -  r-nycflights13  # suggested\n  # -  r-purrr  # suggested\n  # -  r-rmarkdown  # suggested\n  # -  r-rmysql  # suggested\n  # -  r-rpostgresql  # suggested\n  # -  r-rsqlite  # suggested\n  # -  r-stringi &gt;=1.7.6  # suggested\n  # -  r-testthat &gt;=3.1.5  # suggested\n  # -  r-tidyr &gt;=1.3.0  # suggested\n  # -  r-withr  # suggested\n\nabout:\n  homepage: https://dplyr.tidyverse.org, https://github.com/tidyverse/dplyr\n  summary: A Grammar of Data Manipulation\n  description: |-\n    A fast, consistent tool for working with data frame like\n    objects, both in memory and out of memory.\n  license: MIT\n  license_file: LICENSE\n  repository: https://github.com/cran/dplyr\n</code></pre> <p>Tip</p> <p>You can use the generated recipes to build your own \"forge\" with <code>rattler-build</code>. Read more about it in the Building your own forge section.</p>"},{"location":"sandbox/","title":"Experimental sandbox","text":"<p>Warning</p> <p>The sandbox feature is experimental and may not work as expected. The options might change in future releases.</p> <p>Since the 0.34.0 release, <code>rattler-build</code> has a new experimental feature called <code>sandbox</code>. With the sandbox feature enabled (via <code>--sandbox</code>), the build process has much more restricted access to system resources on macOS and Linux. As the sandbox feature is experimental it is disabled by default.</p> <p>In particular, with the default configuration, the build process can read the entire filesystem, but it cannot write outside of the build directories. The build process also cannot access the network. In the future, we plan to enable the sandbox per default and restrict it further.</p> <p>On macOS this is achieved by using the <code>sandbox-exec</code> command, which is part of the macOS system. On Linux the sandbox is created using Linux namespaces.</p> <p>To control the sandbox behavior, you can supply additional arguments to the CLI:</p>"},{"location":"sandbox/#example","title":"Example","text":"<pre><code># run the build and sandbox the build process\nrattler-build build --recipe ./example/recipe.yaml --sandbox\n\n# to add more permissions to the sandbox\nrattler-build build --recipe ./example/recipe.yaml --sandbox \\\n    --allow-read /some/path --allow-read /foo/bar --allow-network\n</code></pre>"},{"location":"sandbox/#options","title":"Options","text":"<ul> <li><code>--allow-network</code>: Allow network access (by default network access is disabled)</li> <li><code>--allow-read-write /some/path</code>: Allow read and write access to the specified path (and all its subdirectories)</li> <li><code>--allow-read /some/path</code>: Allow read access to the specified path (and all its subdirectories)</li> <li><code>--allow-read-execute /some/path</code>: Allow read and execute access to the specified path (and all its subdirectories)</li> <li><code>--overwrite-default-sandbox-config</code>: Ignore the default sandbox configuration and use only the supplied arguments</li> </ul>"},{"location":"sandbox/#default-sandbox-configuration","title":"Default sandbox configuration","text":""},{"location":"sandbox/#macos","title":"macOS","text":"<p>On macOS, by default, the sandbox configuration is as follows:</p> <ul> <li>Read access to the entire filesystem (<code>/</code>)</li> <li>Read and execute access to <code>/bin</code>, <code>/usr/bin</code></li> <li>Write access to the build directories and <code>/tmp</code>, <code>/var/tmp</code>, and <code>$TMPDIR</code> (if defined)</li> </ul>"},{"location":"sandbox/#linux","title":"Linux","text":"<p>On Linux, by default, the sandbox configuration is as follows:</p> <ul> <li>Read access to the entire filesystem (<code>/</code>)</li> <li>Read and execute access to <code>/bin</code>, <code>/usr/bin</code>, <code>/lib</code>, <code>/usr/lib</code>, <code>/lib64</code>, <code>/usr/lib64</code></li> <li>Write access to the build directories and <code>/tmp</code>, <code>/var/tmp</code>, and <code>$TMPDIR</code> (if defined)</li> </ul>"},{"location":"sandbox/#windows","title":"Windows","text":"<p>Sandboxing the build process is not yet supported on Windows, and thus all passed sandbox flags are entirely ignored.</p>"},{"location":"selectors/","title":"Selectors in recipes","text":"<p>Recipe and variant configuration files can utilize selectors to conditionally add, remove, or modify dependencies, configuration options, or even skip recipe execution based on specific conditions.</p> <p>Selectors are implemented using an <code>if / then / else</code> map, which is a valid YAML dictionary. The condition is evaluated using <code>minijinja</code> and follows the same syntax as a Python expression.</p> <p>During rendering, several variables are set based on the platform and variant being built. For example, the <code>unix</code> variable is true for macOS and Linux, while <code>win</code> is true for Windows. Consider the following recipe executed on Linux:</p> <pre><code>requirements:\n  host:\n    - if: unix\n      then: unix-tool\n    - if: win\n      then: win-tool\n</code></pre> <p>This will be evaluated as:</p> <pre><code>requirements:\n  host:\n    - unix-tool\n</code></pre> <p>The line containing the Windows-specific configuration is removed. Multiple items can also be selected, such as:</p> <pre><code>host:\n  - if: linux\n    then:\n      - linux-tool-1\n      - linux-tool-2\n      - linux-tool-3\n</code></pre> <p>For Linux, this will result in:</p> <pre><code>host:\n  - linux-tool-1\n  - linux-tool-2\n  - linux-tool-3\n</code></pre> <p>Other examples often found in the wild:</p> <pre><code>if: build_platform != target_platform ... # true if cross-platform build\nif: osx and arm64 ... # true for apple silicon (osx-arm64)\nif: linux and (aarch64 or ppc64le)) ... # true for linux ppc64le or linux-aarch64\n</code></pre>"},{"location":"selectors/#available-variables","title":"Available variables","text":"<p>The following variables are available during rendering of the recipe:</p> Variable Description <code>target_platform</code> the configured <code>target_platform</code> for the build <code>build_platform</code> the configured <code>build_platform</code> for the build <code>linux</code> \"true\" if <code>target_platform</code> is Linux <code>osx</code> \"true\" if <code>target_platform</code> is OSX / macOS <code>win</code> \"true\" if <code>target_platform</code> is Windows <code>unix</code> \"true\" if <code>target_platform</code> is a Unix (macOS or Linux) <code>x86</code>, <code>x86_64</code> x86 32/64-bit Architecture <code>aarch64</code>, <code>arm64</code> 64-bit Arm (these are the same but are both supported for legacy) <code>armV6l</code>, <code>armV7l</code> 32-bit Arm <code>ppc64</code>, <code>s390x</code>, Big endian <code>ppc64le</code> Little endian <code>riscv32</code>, <code>riscv64</code> The RISC-V Architecture <code>wasm32</code> The WebAssembly Architecture"},{"location":"selectors/#variant-selectors","title":"Variant selectors","text":"<p>To select based on variant configuration you can use the names in the selectors as well. For example, if the build uses <code>python: 3.8</code> as a variant, we can use <code>if: python == \"3.8\"</code> to enable a dependency for only when the Python version is 3.8.</p> <p>String comparison</p> <p>The comparison is a string comparison done by <code>minijinja</code>, so it is important to use the correct string representation of the variant. Use the <code>match</code> function to compare versions.</p> variants.yaml<pre><code>python:\n  - 3.8\n  - 3.9\n</code></pre> recipe.yaml<pre><code>requirements:\n  host:\n    - if: python == \"3.8\" # (1)!\n      then: mydep\n      else: otherdep\n</code></pre> <ol> <li>This will only add <code>mydep</code> when the Python version is 3.8. This comparison is a string comparison, so it is important    to    use the correct string representation of the variant.</li> </ol>"},{"location":"selectors/#the-match-function","title":"The <code>match</code> function","text":"<p>!!!  note \"Rename from <code>cmp</code> to <code>match</code>\"     The <code>cmp</code> function has been renamed to <code>match</code> to better reflect its purpose.</p> <p>Inside selectors, one can use a special <code>match</code> function to test if the selected variant version has a matching version. For example, having the following variants file, we could use the these tests:</p> variants.yaml<pre><code>python:\n  - 3.8\n  - 3.9\n</code></pre> recipe.yaml<pre><code>- if: match(python, \"3.8\")    # true, false\n  then: mydep\n- if: match(python, \"&gt;=3.8\")  # true, true\n  then: mydep\n- if: match(python, \"&lt;3.8\")   # false, false (1)\n  then: mydep\n</code></pre> <ol> <li><code>else:</code> would also have worked here.</li> </ol> <p>This function eliminates the need to implement any Python-specific <code>conda-build</code> selectors (such as <code>py3k</code>, <code>py38</code>, etc.) or the <code>py</code> and <code>npy</code> integers.</p> <p>Please note that during the initial phase of rendering we do not know the variant, and thus the <code>match</code> condition always evaluates to <code>true</code>.</p>"},{"location":"selectors/#selector-evaluation","title":"Selector evaluation","text":"<p>Except for the rattler-build specific selectors, the selectors are evaluated using the <code>minijinja</code> engine. This means that the selectors are evaluated by <code>minijinja</code> thus Python like expressions. Some notable options are:</p> <pre><code>- if: python == \"3.8\" # equal\n- if: python != \"3.8\" # not equal\n- if: python and linux # true if python variant is set and the target_platform is linux\n- if: python and not linux # true if python variant is set and the target_platform is not linux\n- if: python and (linux or osx) # true if python variant is set and the target_platform is linux or osx\n</code></pre>"},{"location":"selectors/#alternatives-for-scalar-fields","title":"Alternatives for scalar fields","text":"<p>Some fields accept scalars rather than lists, and selectors cannot be used. Alternatives include:</p> <pre><code>string: ${{ \"foobar\" if USE_OPENMP else \"bla\" }}\n</code></pre> <pre><code>string: |\n  {% if USE_OPENMP %}\n     blablabla\n  {% else %}\n     blabla\n  {% endif %}\n</code></pre>"},{"location":"special_files/","title":"Activation scripts and other special files","text":"<p>A <code>conda</code> package can contain \"special\" files in the prefix. These files are scripts that are executed during activation, installation, or uninstallation process.</p> <p>If possible, they should be avoided since they execute arbitrary code at installation time and slow down the installation and activation process.</p>"},{"location":"special_files/#activation-scripts","title":"Activation scripts","text":"<p>The activation scripts are executed when the environment containing the package is activated (e.g. when doing <code>micromamba activate myenv</code> or <code>pixi run ...</code>).</p> <p>The scripts are located in special folders:</p> <ul> <li><code>etc/conda/activate.d/{script.sh/bat}</code> - scripts in this folder are executed before the environment is activated</li> <li><code>etc/conda/deactivate.d/{script.sh/bat}</code> - scripts in this folder are executed when the environment is deactivated</li> </ul> <p>The scripts are executed in lexicographical order, so you can prefix them with numbers to control the order of execution.</p> <p>To add a script to the package, just make sure that you install the file in this folder. For example, on Linux:</p> <pre><code>mkdir -p $PREFIX/etc/conda/activate.d\ncp activate-mypkg.sh $PREFIX/etc/conda/activate.d/10-activate-mypkg.sh\n\nmkdir -p $PREFIX/etc/conda/deactivate.d\ncp deactivate-mypkg.sh $PREFIX/etc/conda/deactivate.d/10-deactivate-mypkg.sh\n</code></pre>"},{"location":"special_files/#post-link-and-pre-unlink-scripts","title":"Post-link and pre-unlink scripts","text":"<p>The <code>post-link</code> and <code>pre-unlink</code> scripts are executed when the package is installed or uninstalled. They are both heavily discouraged but implemented for compatibility with conda in <code>rattler-build</code> since version 0.17.</p> <p>For a <code>post-link</code> script to be executed when a package is installed, the built package needs to have a <code>.&lt;package_name&gt;-post-link.{sh/bat}</code> in its <code>bin/</code> folder. The same is applicable for <code>pre-unlink</code> scripts, just with the name <code>.&lt;package_name&gt;-pre-unlink.{sh/bat}</code> (note the leading period). For example, for a package <code>mypkg</code>, you would need to have a <code>.mypkg-post-link.sh</code> in its <code>bin/</code> folder.</p> <p>To make sure the scripts are included in the correct location, use your recipe's build script or <code>build/script</code> key. For example, assuming you have a <code>post-link.sh</code> script in your source, alongside the recipe in the recipe's folder, the following configuration will copy it correctly:</p> <pre><code>build:\n  ...\n  script:\n    - ...\n    - mkdir -p $PREFIX/bin\n    - cp $RECIPE_DIR/post-link.sh $PREFIX/bin/.mypkg-post-link.sh\n    - chmod +x $PREFIX/bin/.mypkg-post-link.sh\n</code></pre> <p>The <code>$PREFIX</code> and <code>$RECIPE_DIR</code> environment variables will be set during the build process to help you specify the correct paths.</p>"},{"location":"system_integration/","title":"System integration for packages","text":"<p>When you are building packages, you might want to integrate with the system to install shortcuts, desktop icons, etc.</p> <p>In the Conda ecosystem, this is the job of \"menuinst\" - originally a Python project, that we ported to our underlying <code>rattler</code> library. To install a menuitem, you need to place a specially crafted JSON file in the right location in the package / conda environment.</p> recipe.yaml<pre><code>build:\n  script:\n    # ... build the package\n    # Install the menu item\n    - mkdir -p $PREFIX/Menu\n    - cp $RECIPE_DIR/menu/menu.json $PREFIX/Menu/pixi-editor.json\n    - cp $RECIPE_DIR/icons/pixi-icon.* $PREFIX/Menu/\n</code></pre> <p>To learn more about installing menu items, please take a look at the <code>menuinst</code> documentation.</p>"},{"location":"system_integration/#installing-shell-completion-scripts","title":"Installing shell completion scripts","text":"<p>Shell completion scripts are scripts that are sourced by the shell to provide tab-completion for commands. They are automatically picked up by <code>pixi</code> and other tools when they appear in the right location in your package.</p> <p>These locations are:</p> <ul> <li><code>bash</code>: <code>$PREFIX/share/bash-completion/completions/</code></li> <li><code>zsh</code>: <code>$PREFIX/share/zsh/site-functions/</code></li> <li><code>fish</code>: <code>$PREFIX/share/fish/vendor_completions.d/</code></li> </ul> <p>Following is an example of how to ship shell completions for <code>ripgrep</code> in a package:</p> recipe.yaml<pre><code>package:\n  name: ripgrep\n  version: \"1.24.3\"\n\n# ... other fields omitted for brevity\n\nbuild:\n  number: 1\n  noarch: generic\n  script:\n    # Build and install ripgrep ...\n    # Then generate the completions\n    # ZSH completions\n    - mkdir -p $PREFIX/share/zsh/site-functions\n    - rg --generate complete-zsh &gt; $PREFIX/share/zsh/site-functions/_rg\n    # Bash completions\n    - mkdir -p $PREFIX/share/bash-completion/completions\n    - rg --generate complete-bash &gt; $PREFIX/share/bash-completion/completions/rg\n    # Fish completions\n    - mkdir -p $PREFIX/share/fish/vendor_completions.d\n    - rg --generate complete-fish &gt; $PREFIX/share/fish/vendor_completions.d/rg.fish\n\n# ... continue recipe\n</code></pre> <p>Note that tools like <code>pixi global install</code> will expect completion script name to match the binary name. The pattern is as follows:</p> <ul> <li><code>bash</code>: <code>&lt;binary-name&gt;</code></li> <li><code>zsh</code>: <code>_&lt;binary-name&gt;</code></li> <li><code>fish</code>: <code>&lt;binary-name&gt;.fish</code></li> </ul>"},{"location":"testing/","title":"Testing packages","text":"<p>When you are developing a package, you should write tests for it. The tests are automatically executed as soon as the package build and all it's run dependencies are ready.</p>"},{"location":"testing/#writing-tests","title":"Writing tests","text":"<p>You can add one or more tests to your package in the <code>tests</code> section of the recipe (or output). Each test is run independently, in a separate environment.</p> <p>One notable difference are the <code>package_contents</code> tests that are executed right after the package is prepared and do not create a new environment (as we only analyze the contents of the package).</p> recipe.yaml<pre><code>tests:\n  # commands to run to test the package. If any of the commands\n  # returns with an error code, the test is considered failed.\n  - script:\n      - echo \"Hello world\"\n      - exit 1  # this will fail the test\n\n  # run a script from the recipe folder\n  - script: sometest.py\n\n  # run a Python script with the Python interpreter\n  - script:\n      interpreter: python\n      content: |\n        import mypkg\n        assert mypkg.__version__ == \"0.1.0\"\n\n  # execute `pytest` with the tests from the `tests` folder\n  - script:\n      - pytest ./tests\n    # additional requirements at test time\n    requirements:\n      run:\n        - pytest\n        - python 3.9.*  # require an older python version\n    # extra files to be copied to the test folder from the recipe or source directory\n    files:\n      recipe:\n        - tests/\n\n  # python specific tests\n  - python:\n      # this test section tries to import the python modules and errors if it can't\n      imports:\n        - mypkg\n      pip_check: true\n      python_version: [3.9.*, 3.10.*]  # run against multiple older python versions\n\n  - r:\n      libraries:\n        - dplyr\n\n  - perl:\n      modules:\n        - JSON\n\n  # test the contents of the package.\n  - package_contents:\n      files:\n        - share/package/*.txt\n        - lib/python*/site-packages/mypackage/*.py\n\n  # test with strict mode: fails if there are any files not matched by the globs\n  - package_contents:\n      strict: true\n      files:\n        - share/package/*.txt\n        - bin/myapp\n      lib:\n        - mylib\n</code></pre>"},{"location":"testing/#testing-package-contents","title":"Testing package contents","text":"<p>The <code>package_contents</code> test is a special test that is executed right after the package is prepared. It does not create a new environment, but instead checks the paths that will be part of the final package. It can be very useful as a \"sanity check\" to ensure that the package contains the expected files.</p> <p>It has multiple sub-keys that help when building cross-platform packages:</p> <ul> <li><code>files</code>: Specifies glob patterns for files that should exist in the package. You can provide a simple list of globs that should match at least one file in the package. If any pattern doesn't match at least one file, the test fails.</li> </ul> <p>Note: For more advanced use cases, you can also use the expanded form with <code>exists</code> and <code>not_exists</code> fields: <pre><code>files:\n  exists:\n    - share/package/*.txt\n    - lib/python*/site-packages/mypackage/*.py\n  not_exists:\n    - lib/python*/site-packages/mypackage/deprecated_module.py\n</code></pre> - <code>lib</code>: matches libraries in the package (<code>.so</code>, <code>.dll</code>, <code>.dylib</code> files). The test fails if any of the libraries are not found. It's enough to specify the library name without any extension (e.g. <code>foo</code> will match <code>libfoo.so</code>, <code>libfoo.dylib</code>, and <code>foo.dll</code>). - <code>include</code>: matches files under the <code>include</code> directory in the package. You can specify the file name like <code>foo.h</code>. - <code>bin</code>: matches files under the <code>bin</code> directory in the package. You can specify executable names like <code>foo</code> which will match <code>foo.exe</code> on Windows and <code>foo</code> on Linux and macOS. - <code>site_packages</code>: matches files under the <code>site-packages</code> directory in the package. You can specify the import path like <code>foobar.api</code> which will match <code>foobar/api.py</code> and <code>foobar/api/__init__.py</code>. - <code>strict</code>: when set to <code>true</code>, enables strict mode. In strict mode, the test will fail if there are any files in the package that don't match any of the specified globs. (default: <code>false</code>).</p>"},{"location":"testing/#testing-existing-packages","title":"Testing existing packages","text":"<p>The tests from the test section are actually added into your package and can also be executed straight from the existing package.</p> <p>The idea behind adding the tests into the package is that you can execute the tests independently from building the package. That is also why we are shipping a <code>test</code> subcommand that takes as input an existing package and executes the tests:</p> <pre><code>rattler-build test --package-file ./xtensor-0.24.6-h60d57d3_0.tar.bz2\n</code></pre> <p>Running the above command will extract the package and create a clean environment where the package and dependencies are installed. Then the tests are executed in this newly-created environment.</p> <p>If you inspect the package contents, you would find the test files under <code>info/test/*</code>.</p>"},{"location":"testing/#how-tests-are-translated","title":"How tests are translated","text":"<p>The <code>tests</code> section allows you to define test configurations for your package. Tests are serialized to <code>info/tests/tests.yaml</code> in the created package and read from there during test execution.</p> <p>When adding extra files to your tests:</p> <ol> <li>During package creation<ul> <li>Files are copied to <code>$PREFIX/etc/conda/test-files/{pkg_name}/{idx}</code></li> <li><code>{idx}</code> is a sequential number assigned to each test</li> <li>Files can come from both <code>source</code> (work directory) and <code>recipe</code> locations</li> </ul> </li> <li>During test execution<ul> <li>Files are copied from <code>$PREFIX/etc/conda/test-files/{pkg_name}/{idx}</code> to a temporary directory</li> <li>Tests run within this temporary directory</li> <li>Use relative paths to access these files in your test commands</li> </ul> </li> </ol> <p>This approach ensures test files are properly packaged and available during test execution.</p>"},{"location":"testing/#legacy-tests","title":"Legacy tests","text":"<p>Legacy tests (from <code>conda-build</code>) are still supported for execution. These tests are stored as files under the <code>info/test/</code> folder.</p> <p>The files are:</p> <ul> <li><code>run_test.sh</code> (Unix)</li> <li><code>run_test.bat</code> (Windows)</li> <li><code>run_test.py</code> (for the Python import tests)</li> <li><code>test_time_dependencies.json</code> (for additional dependencies at test time)</li> </ul> <p>Additionally, the <code>info/test/</code> folder contains all the files specified in the test section as <code>source_files</code> and <code>files</code>. The tests are executed pointing to this directory as the current working directory.</p>"},{"location":"tips_and_tricks/","title":"Tips and tricks for rattler-build","text":"<p>This section contains some tips and tricks for using <code>rattler-build</code>.</p>"},{"location":"tips_and_tricks/#using-sccache-or-ccache-with-rattler-build","title":"Using sccache or ccache with <code>rattler-build</code>","text":"<p>When debugging a recipe it can help a lot to use <code>sccache</code> or <code>ccache</code>. You can install both tools e.g. with <code>pixi global install sccache</code>.</p> <p>To use them with a CMake project, you can use the following variables:</p> <pre><code>export CMAKE_C_COMPILER_LAUNCHER=sccache\nexport CMAKE_CXX_COMPILER_LAUNCHER=sccache\n\n# or more generally\n\nexport C=\"sccache $C\"\nexport CXX=\"sccache $CXX\"\n</code></pre> <p>However, both <code>ccache</code> and <code>sccache</code> are sensitive to changes in the build location. Since <code>rattler-build</code>, by default, always creates a new build directory with the timestamp, you need to use the <code>--no-build-id</code> flag. This will disable the time stamp in the build directory and allow <code>ccache</code> and <code>sccache</code> to cache the build.</p> <pre><code>rattler-build build --no-build-id --recipe ./path/to/recipe.yaml\n</code></pre>"},{"location":"tips_and_tricks/#building-your-own-forge","title":"Building your own \"forge\"","text":"<p>You might want to publish your own software packages to a channel you control. These might be packages that are not available in the main conda-forge channel, or proprietary packages, or packages that you have modified in some way.</p> <p>Doing so is pretty straightforward with <code>rattler-build</code> and a CI provider of your choice. We have a number of example repositories for \"custom\" forges:</p> <ul> <li>rust-forge: This repository builds a   number of Rust packages for Windows, macOS and Linux on top of Github Actions.</li> <li>r-forge: The same idea, but for <code>R</code>   packages</li> </ul>"},{"location":"tips_and_tricks/#directory-structure","title":"Directory structure","text":"<p>To create your own forge, you should create a number of sub-directories where each sub-directory should contain at most one recipe. With the <code>--recipe-dir</code> flag of rattler-build, the program will go and collect all recipes it finds in the given directory or sub-directories.</p> <p>We can combine this with the <code>--skip-existing=all</code> flag which will skip all packages that are already built locally or in the channel (if you upload them). Using <code>all</code> will also look at the <code>repodata.json</code> file in the channel to see if the package is already there. Packages are skipped based on their complete name, including the version and build string.</p> <p>To note: the build string changes if the variant configuration changes! So if you update a package in the variant configuration, the packages that need rebuilding should be rebuilt.</p> <p>Note</p> <p>You can generate recipes for different ecosystems with the <code>rattler-build generate-recipe</code> command. Read more about it in the Generating recipes section.</p>"},{"location":"tips_and_tricks/#ci-setup","title":"CI setup","text":"<p>As an example, the following is the CI setup for <code>rust-forge</code>. The workflow uses <code>rattler-build</code> to build and upload packages to a custom channel on https://prefix.dev \u2013 but you can also use <code>rattler-build</code> to upload to your own <code>quetz</code> instance, or a channel on <code>anaconda.org</code>.</p> Example CI setup for <code>rust-forge</code> <p>The following is an example of a Github Actions workflow for <code>rust-forge</code>:</p> .github/workflows/forge.yml<pre><code>name: Build all packages\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build:\n    strategy:\n      matrix:\n        include:\n          - { target: linux-64, os: ubuntu-20.04 }\n          - { target: win-64, os: windows-latest }\n          # force older macos-13 to get x86_64 runners\n          - { target: osx-64, os: macos-13 }\n          - { target: osx-arm64, os: macos-14 }\n      fail-fast: false\n\n    runs-on: ${{ matrix.os }}\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: 2\n      - uses: prefix-dev/setup-pixi@v0.5.1\n        with:\n          pixi-version: v0.24.2\n          cache: true\n\n      - name: Run code in changed subdirectories\n        shell: bash\n        env:\n          TARGET_PLATFORM: ${{ matrix.target }}\n\n        run: |\n          pixi run rattler-build build --recipe-dir . \\\n            --skip-existing=all --target-platform=$TARGET_PLATFORM \\\n            -c conda-forge -c https://prefix.dev/rust-forge\n\n      - name: Upload all packages\n        shell: bash\n        # do not upload on PR\n        if: github.event_name == 'push'\n        env:\n          PREFIX_API_KEY: ${{ secrets.PREFIX_API_KEY }}\n        run: |\n          # ignore errors because we want to ignore duplicate packages\n          for file in output/**/*.conda; do\n            pixi run rattler-build upload prefix -c rust-forge \"$file\" || true\n          done\n</code></pre>"},{"location":"tui/","title":"Terminal User Interface","text":"<p><code>rattler-build</code> offers a terminal user interface for building multiple packages and viewing the logs.</p> <p></p> <p>To launch the TUI, run the <code>build</code> command with the <code>--tui</code> flag as shown below:</p> <pre><code>$ rattler-build build -r recipe.yaml --tui\n</code></pre> <p>Note</p> <p><code>rattler-build-tui</code> is gated behind the <code>tui</code> feature flag to avoid extra dependencies. Build the project with <code>--features tui</code> arguments to enable the TUI functionality.</p>"},{"location":"tui/#key-bindings","title":"Key Bindings","text":"Key Action \u23ce Build a Build all j/k Next/previous package up/down/left/right Scroll logs e Edit recipe (via <code>$EDITOR</code>) c, : Open command prompt (available commands: <code>edit</code>) q, ctrl-c, esc, Quit"},{"location":"variants/","title":"Variant configuration","text":"<p><code>rattler-build</code> can automatically build multiple variants of a given package. For example, a Python package might need multiple variants per Python version (especially if it is a binary package such as <code>numpy</code>).</p> <p>For this use case, one can specify variant configuration files. A variant configuration file has 2 special entries and a list of packages with variants. For example:</p> variants.yaml<pre><code># special entry #1, the zip keys\nzip_keys:\n- [python, numpy]\n\n# special entry #2, the pin_run_as_build key\npin_run_as_build:\n  numpy:\n    max_pin: 'x.x'\n\n# entries per package version that users are interested in\npython:\n# Note that versions are _strings_ (not numbers)\n- \"3.8\"\n- \"3.9\"\n- \"3.10\"\n\nnumpy:\n- \"1.12\"\n- \"1.12\"\n- \"1.20\"\n</code></pre> <p>If we have a recipe, that has a <code>build</code>, <code>host</code> or <code>run</code> dependency on <code>python</code> we will build multiple variants of this package, one for each configured <code>python</code> version (\"3.8\", \"3.9\" and \"3.10\").</p> <p>For example:</p> <pre><code># ...\nrequirements:\n  host:\n  - python\n</code></pre> <p>... will be rendered as (for the first variant):</p> <pre><code># ...\nrequirements:\n  host:\n- python 3.8*\n</code></pre> <p>Note that variants are only applied if the requirement doesn't specify any constraints. If the requirement would be <code>python &gt;3.8,&lt;3.10</code> then the variant entry would be ignored.</p>"},{"location":"variants/#automatic-discovery","title":"Automatic Discovery","text":"<p><code>rattler-build</code> automatically discovers and includes variant configurations from either:</p> <ul> <li><code>variants.yaml</code> file located next to the recipe</li> <li><code>conda_build_config.yaml</code> file located next to the recipe</li> </ul> <p>To disable automatic discovery, use the <code>--ignore-recipe-variants</code> flag. If you pass variant configuration files explicitly using <code>--variant-config / -m &lt;file&gt;</code>, the passed variants are loaded with higher priority.</p>"},{"location":"variants/#custom-configuration-files","title":"Custom Configuration Files","text":"<p>To specify variant configurations from other locations or include multiple files, use the <code>--variant-config</code> or <code>-m</code> option:</p> <pre><code>rattler-build build --variant-config ~/user_variants.yaml --variant-config /opt/rattler-build/global_variants.yaml --recipe myrecipe.yaml\n</code></pre>"},{"location":"variants/#merging-of-multiple-variant-configuration-files","title":"Merging of multiple variant configuration files","text":"<p>When multiple variant configuration files are merged, the following rules apply:</p> <ul> <li>A key from a higher priority file will completely override a key from a lower priority file.</li> <li>Zip key lengths must still match.</li> </ul>"},{"location":"variants/#conda-build-compatibility","title":"<code>conda-build</code> Compatibility","text":"<p>Since version 0.35.0, rattler-build supports conda_build_config.yaml files, parsing a subset of conda-build's configuration syntax. The filename must match exactly to be recognized as a conda-build config file.</p>"},{"location":"variants/#overriding-the-variant-configuration-from-the-command-line","title":"Overriding the variant configuration from the command line","text":"<p>You can override the chosen variant configuration by passing in the variant you want from the CLI:</p> <pre><code>rattler-build build --recipe ./my-recipe --variant python=3.12 --variant numpy=\"2.*\"\n</code></pre> <p>To build against multiple Python versions you can separate the variant strings by <code>,</code>, eg. <code>--variant python=3.12,3.13</code>.</p> <p>This will follow the same logic as using multiple variant files: the CLI will overwrite any variant keys set by files that were loaded.</p>"},{"location":"variants/#package-hash-from-variant","title":"Package hash from variant","text":"<p>You might have wondered what the role of the build string is. The build string is (if not explicitly set) computed from the variant configuration. It serves as a mechanism to discern different build configurations that produce a package with the same name and version.</p> <p>The hash is computed by dumping all of the variant configuration values that are used by a given recipe into a JSON file, and then hashing that JSON file.</p> <p>For example, in our <code>python</code> example, we would get a variant configuration file that looks something like:</p> <pre><code>{\n    \"python\": \"3.8\"\n}\n</code></pre> <p>This JSON string is then hashed with the MD5 hash algorithm, and produces the hash. For certain packages (such as Python packages) special rules exists, and the <code>py&lt;Major.Minor&gt;</code> version is prepended to the hash, so that the final hash would look something like <code>py38h123123</code>.</p>"},{"location":"variants/#zip-keys","title":"Zip keys","text":"<p>Zip keys modify how variants are combined. Usually, each variant key that has multiple entries is expanded to a build matrix. For example, if we have:</p> <pre><code>python: [\"3.8\", \"3.9\"]\nnumpy: [\"1.12\", \"1.14\"]\n</code></pre> <p>...then we obtain 4 variants for a recipe that uses both <code>numpy</code> and <code>python</code>:</p> <pre><code>- python 3.8, numpy 1.12\n- python 3.8, numpy 1.14\n- python 3.9, numpy 1.12\n- python 3.9, numpy 1.14\n</code></pre> <p>However, if we use the <code>zip_keys</code> and specify:</p> <pre><code>zip_keys: [[\"python\", \"numpy\"]]\npython: [\"3.8\", \"3.9\"]\nnumpy: [\"1.12\", \"1.14\"]\n</code></pre> <p>...then the versions are \"zipped up\" and we only get 2 variants. Note that both <code>python</code> and <code>numpy</code> need to specify the exact same number of versions to make this work.</p> <p>The resulting variants with the zip applied are:</p> <pre><code>- python 3.8, numpy 1.12\n- python 3.9, numpy 1.14\n</code></pre>"},{"location":"variants/#pin-run-as-build","title":"Pin run as build","text":"<p>The <code>pin_run_as_build</code> key allows the user to inject additional pins. Usually, the <code>run_exports</code> mechanism is used to specify constraints for runtime dependencies from build time dependencies, but <code>pin_run_as_build</code> offers a mechanism to override that if the package does not contain a run exports file.</p> <p>For example:</p> <pre><code>pin_run_as_build:\n  libcurl:\n    min_pin: 'x'\n    max_pin: 'x'\n</code></pre> <p>If we now have a recipe that uses <code>libcurl</code> in the <code>host</code> and <code>run</code> dependencies like:</p> <pre><code>requirements:\n  host:\n  - libcurl\n  run:\n  - libcurl\n</code></pre> <p>During resolution, <code>libcurl</code> might be evaluated to <code>libcurl 8.0.1 h13284</code>. Our new runtime dependency then looks like:</p> <pre><code>requirements:\n  host:\n  - libcurl 8.0.1 h13284\n  run:\n  - libcurl &gt;=8,&lt;9\n</code></pre>"},{"location":"variants/#channel-sources","title":"Channel sources","text":"<p>You can specify the channels when building by adjusting <code>channel_sources</code> in your variant file:</p> <pre><code>channel_sources: conda-forge/label/rust_dev,conda-forge\n</code></pre>"},{"location":"variants/#prioritizing-variants","title":"Prioritizing variants","text":"<p>You might produce multiple variants for a package, but want to define a priority for a given variant. The variant with the highest priority would be the default package that is selected by the resolver.</p> <p>There are two mechanisms to make this possible: <code>mutex</code> packages and the <code>down_prioritize_variant</code> option in the recipe.</p>"},{"location":"variants/#the-down_prioritize_variant-option","title":"The <code>down_prioritize_variant</code> option","text":"<p>Note</p> <p>It is not always necessary to use the <code>down_prioritize_variant</code> option - only if the solver has no other way to prefer a given variant. For example, if you have a package that has multiple variants for different Python versions, the solver will automatically prefer the variant with the highest Python version.</p> <p>The <code>down_prioritize_variant</code> option allows you to specify a variant that should be down-prioritized. For example:</p> recipe.yaml<pre><code>build:\n  variant:\n    use_keys:\n      # use cuda from the variant config, e.g. to build multiple CUDA variants\n      - cuda\n    # this will down-prioritize the cuda variant versus other variants of the package\n    down_prioritize_variant: ${{ 1 if cuda else 0 }}\n</code></pre>"},{"location":"variants/#mutex-packages","title":"Mutex packages","text":"<p>Another way to make sure the right variants are selected are \"mutex\" packages. A mutex package is a package that is mutually exclusive. We use the fact that only one package of a given name can be installed at a time (the solver has to choose).</p> <p>A mutex package might be useful to make sure that all packages that depend on BLAS are compiled against the same BLAS implementation. The mutex package will serve the purpose that \"<code>openblas</code>\" and \"<code>mkl</code>\" can never be installed at the same time.</p> <p>We could define a BLAS mutex package like this:</p> variant_config.yaml<pre><code>blas_variant:\n  - \"openblas\"\n  - \"mkl\"\n</code></pre> <p>And then the <code>recipe.yaml</code> for the <code>mutex</code> package could look like this:</p> recipe.yaml<pre><code>package:\n  name: blas_mutex\n  version: 1.0\n\nbuild:\n  string: ${{ blas_variant }}${{ hash }}_${{ build_number }}\n  variant:\n    # make sure that `openblas` is preferred over `mkl`\n    down_prioritize_variant: ${{ 1 if blas_variant == \"mkl\" else 0 }}\n</code></pre> <p>This will create two package: <code>blas_mutex-1.0-openblas</code> and <code>blas_mutex-1.0-mkl</code>. Only one of these packages can be installed at a time because they share the same name. The solver will then only select one of these two packages.</p> <p>The <code>blas</code> package in turn should have a <code>run_export</code> for the <code>blas_mutex</code> package, so that any package that links against <code>blas</code> also has a dependency on the correct <code>blas_mutex</code> package:</p> recipe.yaml<pre><code>package:\n  name: openblas\n  version: 1.0\n\nrequirements:\n  # any package depending on openblas should also depend on the correct blas_mutex package\n  run_export:\n    # Add a run export on _any_ version of the blas_mutex package whose build string starts with \"openblas\"\n    - blas_mutex * openblas*\n</code></pre> <p>Then the recipe of a package that wants to build two variants, one for <code>openblas</code> and one for <code>mkl</code> could look like this:</p> recipe.yaml<pre><code>package:\n  name: fastnumerics\n  version: 1.0\n\nrequirements:\n  host:\n    # build against both openblas and mkl\n    - ${{ blas_variant }}\n  run:\n    # implicitly adds the correct blas_mutex package through run exports\n    # - blas_mutex * ${{ blas_variant }}*\n</code></pre>"},{"location":"reference/cli/","title":"Command-Line Help for <code>rattler-build</code>","text":"<p>This document contains the help content for the <code>rattler-build</code> command-line program.</p>"},{"location":"reference/cli/#rattler-build","title":"<code>rattler-build</code>","text":"<p>Usage: <code>rattler-build [OPTIONS] [COMMAND]</code></p>"},{"location":"reference/cli/#subcommands","title":"Subcommands:","text":"<ul> <li><code>build</code> \u2014 Build a package from a recipe</li> <li><code>test</code> \u2014 Run a test for a single package</li> <li><code>rebuild</code> \u2014 Rebuild a package from a package file instead of a recipe</li> <li><code>upload</code> \u2014 Upload a package</li> <li><code>completion</code> \u2014 Generate shell completion script</li> <li><code>generate-recipe</code> \u2014 Generate a recipe from PyPI, CRAN, CPAN, or LuaRocks</li> <li><code>auth</code> \u2014 Handle authentication to external channels</li> <li><code>debug</code> \u2014 Debug a recipe by setting up the environment without running the build script</li> <li><code>create-patch</code> \u2014 Create a patch for a directory</li> </ul>"},{"location":"reference/cli/#options","title":"Options:","text":"<ul> <li> <p><code>-v</code>, <code>--verbose</code></p> <p>Increase logging verbosity</p> </li> <li> <p><code>-q</code>, <code>--quiet</code></p> <p>Decrease logging verbosity</p> </li> <li> <p><code>--log-style &lt;LOG_STYLE&gt;</code></p> <p>Logging style</p> <ul> <li>Default value: <code>fancy</code></li> <li>Possible values:<ul> <li><code>fancy</code>:     Use fancy logging output</li> <li><code>json</code>:     Use JSON logging output</li> <li><code>plain</code>:     Use plain logging output</li> </ul> </li> </ul> </li> <li> <p><code>--wrap-log-lines &lt;WRAP_LOG_LINES&gt;</code></p> <p>Wrap log lines at the terminal width. This is automatically disabled on CI (by detecting the <code>CI</code> environment variable)</p> <ul> <li>Possible values: <code>true</code>, <code>false</code></li> </ul> </li> <li> <p><code>--config-file &lt;CONFIG_FILE&gt;</code></p> <p>The rattler-build configuration file to use</p> </li> <li> <p><code>--color &lt;COLOR&gt;</code></p> <p>Enable or disable colored output from rattler-build. Also honors the <code>CLICOLOR</code> and <code>CLICOLOR_FORCE</code> environment variable</p> <ul> <li>Default value: <code>auto</code></li> <li>Possible values:<ul> <li><code>always</code>:     Always use colors</li> <li><code>never</code>:     Never use colors</li> <li><code>auto</code>:     Use colors when the output is a terminal</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/cli/#build","title":"<code>build</code>","text":"<p>Build a package from a recipe</p> <p>Usage: <code>rattler-build build [OPTIONS]</code></p>"},{"location":"reference/cli/#options_1","title":"Options:","text":"<ul> <li> <p><code>-r</code>, <code>--recipe &lt;RECIPES&gt;</code></p> <p>The recipe file or directory containing <code>recipe.yaml</code>. Defaults to the current directory</p> <ul> <li>Default value: <code>.</code></li> </ul> </li> <li> <p><code>--recipe-dir &lt;RECIPE_DIR&gt;</code></p> <p>The directory that contains recipes</p> </li> <li> <p><code>--up-to &lt;UP_TO&gt;</code></p> <p>Build recipes up to the specified package</p> </li> <li> <p><code>--build-platform &lt;BUILD_PLATFORM&gt;</code></p> <p>The build platform to use for the build (e.g. for building with emulation, or rendering)</p> </li> <li> <p><code>--target-platform &lt;TARGET_PLATFORM&gt;</code></p> <p>The target platform for the build</p> </li> <li> <p><code>--host-platform &lt;HOST_PLATFORM&gt;</code></p> <p>The host platform for the build. If set, it will be used to determine also the target_platform (as long as it is not noarch)</p> </li> <li> <p><code>-c</code>, <code>--channel &lt;CHANNELS&gt;</code></p> <p>Add a channel to search for dependencies in</p> </li> <li> <p><code>-m</code>, <code>--variant-config &lt;VARIANT_CONFIG&gt;</code></p> <p>Variant configuration files for the build</p> </li> <li> <p><code>--variant &lt;VARIANT_OVERRIDES&gt;</code></p> <p>Override specific variant values (e.g. --variant python=3.12 or --variant python=3.12,3.11). Multiple values separated by commas will create multiple build variants</p> </li> <li> <p><code>--ignore-recipe-variants</code></p> <p>Do not read the <code>variants.yaml</code> file next to a recipe</p> </li> <li> <p><code>--render-only</code></p> <p>Render the recipe files without executing the build</p> </li> <li> <p><code>--with-solve</code></p> <p>Render the recipe files with solving dependencies</p> </li> <li> <p><code>--keep-build</code></p> <p>Keep intermediate build artifacts after the build</p> </li> <li> <p><code>--no-build-id</code></p> <p>Don't use build id(timestamp) when creating build directory name</p> </li> <li> <p><code>--compression-threads &lt;COMPRESSION_THREADS&gt;</code></p> <p>The number of threads to use for compression (only relevant when also using <code>--package-format conda</code>)</p> </li> <li> <p><code>--io-concurrency-limit &lt;IO_CONCURRENCY_LIMIT&gt;</code></p> <p>The maximum number of concurrent I/O operations to use when installing packages This can be controlled by the <code>RATTLER_IO_CONCURRENCY_LIMIT</code> environment variable Defaults to 8 times the number of CPUs</p> </li> <li> <p><code>--experimental</code></p> <p>Enable experimental features</p> </li> <li> <p><code>--allow-insecure-host &lt;ALLOW_INSECURE_HOST&gt;</code></p> <p>List of hosts for which SSL certificate verification should be skipped</p> </li> <li> <p><code>--channel-priority &lt;CHANNEL_PRIORITY&gt;</code></p> <p>Channel priority to use when solving</p> </li> <li> <p><code>--extra-meta &lt;EXTRA_META&gt;</code></p> <p>Extra metadata to include in about.json</p> </li> <li> <p><code>--continue-on-failure</code></p> <p>Continue building even if (one) of the packages fails to build. This is useful when building many packages with <code>--recipe-dir</code>.`</p> </li> </ul>"},{"location":"reference/cli/#modifying-result","title":"Modifying result","text":"<ul> <li> <p><code>--package-format &lt;PACKAGE_FORMAT&gt;</code></p> <p>The package format to use for the build. Can be one of <code>tar-bz2</code> or <code>conda</code>. You can also add a compression level to the package format, e.g. <code>tar-bz2:&lt;number&gt;</code> (from 1 to 9) or <code>conda:&lt;number&gt;</code> (from -7 to 22).</p> </li> <li> <p><code>--no-include-recipe</code></p> <p>Don't store the recipe in the final package</p> </li> <li> <p><code>--test &lt;TEST&gt;</code></p> <p>The strategy to use for running tests</p> <ul> <li>Possible values:<ul> <li><code>skip</code>:     Skip the tests</li> <li><code>native</code>:     Run the tests only if the build platform is the same as the host platform. Otherwise, skip the tests. If the target platform is noarch, the tests are always executed</li> <li><code>native-and-emulated</code>:     Always run the tests</li> </ul> </li> </ul> </li> <li> <p><code>--color-build-log</code></p> <p>Don't force colors in the output of the build script</p> </li> <li> <p><code>--output-dir &lt;OUTPUT_DIR&gt;</code></p> <p>Output directory for build artifacts.</p> </li> <li> <p><code>--skip-existing &lt;SKIP_EXISTING&gt;</code></p> <p>Whether to skip packages that already exist in any channel If set to <code>none</code>, do not skip any packages, default when not specified. If set to <code>local</code>, only skip packages that already exist locally, default when using <code>--skip-existing. If set to</code>all`, skip packages that already exist in any channel</p> <ul> <li>Possible values:<ul> <li><code>none</code>:     Do not skip any packages</li> <li><code>local</code>:     Skip packages that already exist locally</li> <li><code>all</code>:     Skip packages that already exist in any channel</li> </ul> </li> </ul> </li> <li> <p><code>--noarch-build-platform &lt;NOARCH_BUILD_PLATFORM&gt;</code></p> <p>Define a \"noarch platform\" for which the noarch packages will be built for. The noarch builds will be skipped on the other platforms</p> </li> <li> <p><code>--debug</code></p> <p>Enable debug output in build scripts</p> </li> <li> <p><code>--error-prefix-in-binary</code></p> <p>Error if the host prefix is detected in any binary files</p> </li> <li> <p><code>--allow-symlinks-on-windows</code></p> <p>Allow symlinks in packages on Windows (defaults to false - symlinks are forbidden on Windows)</p> </li> <li> <p><code>--exclude-newer &lt;EXCLUDE_NEWER&gt;</code></p> <p>Exclude packages newer than this date from the solver, in RFC3339 format (e.g. 2024-03-15T12:00:00Z)</p> </li> </ul>"},{"location":"reference/cli/#sandbox-arguments","title":"Sandbox arguments","text":"<ul> <li> <p><code>--sandbox</code></p> <p>Enable the sandbox</p> </li> <li> <p><code>--allow-network</code></p> <p>Allow network access during build (default: false if sandbox is enabled)</p> </li> <li> <p><code>--allow-read &lt;ALLOW_READ&gt;</code></p> <p>Allow read access to the specified paths</p> </li> <li> <p><code>--allow-read-execute &lt;ALLOW_READ_EXECUTE&gt;</code></p> <p>Allow read and execute access to the specified paths</p> </li> <li> <p><code>--allow-read-write &lt;ALLOW_READ_WRITE&gt;</code></p> <p>Allow read and write access to the specified paths</p> </li> <li> <p><code>--overwrite-default-sandbox-config</code></p> <p>Overwrite the default sandbox configuration</p> </li> </ul>"},{"location":"reference/cli/#test","title":"<code>test</code>","text":"<p>Run a test for a single package</p> <p>This creates a temporary directory, copies the package file into it, and then runs the indexing. It then creates a test environment that installs the package and any extra dependencies specified in the package test dependencies file.</p> <p>With the activated test environment, the packaged test files are run:</p> <ul> <li><code>info/test/run_test.sh</code> or <code>info/test/run_test.bat</code> on Windows * <code>info/test/run_test.py</code></li> </ul> <p>These test files are written at \"package creation time\" and are part of the package.</p> <p>Usage: <code>rattler-build test [OPTIONS] --package-file &lt;PACKAGE_FILE&gt;</code></p>"},{"location":"reference/cli/#options_2","title":"Options:","text":"<ul> <li> <p><code>-c</code>, <code>--channel &lt;CHANNELS&gt;</code></p> <p>Channels to use when testing</p> </li> <li> <p><code>-p</code>, <code>--package-file &lt;PACKAGE_FILE&gt;</code></p> <p>The package file to test</p> </li> <li> <p><code>--compression-threads &lt;COMPRESSION_THREADS&gt;</code></p> <p>The number of threads to use for compression</p> </li> <li> <p><code>--test-index &lt;TEST_INDEX&gt;</code></p> <p>The index of the test to run. This is used to run a specific test from the package</p> </li> <li> <p><code>--debug</code></p> <p>Build test environment and output debug information for manual debugging</p> </li> <li> <p><code>--experimental</code></p> <p>Enable experimental features</p> </li> <li> <p><code>--allow-insecure-host &lt;ALLOW_INSECURE_HOST&gt;</code></p> <p>List of hosts for which SSL certificate verification should be skipped</p> </li> <li> <p><code>--channel-priority &lt;CHANNEL_PRIORITY&gt;</code></p> <p>Channel priority to use when solving</p> </li> </ul>"},{"location":"reference/cli/#modifying-result_1","title":"Modifying result","text":"<ul> <li> <p><code>--output-dir &lt;OUTPUT_DIR&gt;</code></p> <p>Output directory for build artifacts.</p> </li> </ul>"},{"location":"reference/cli/#rebuild","title":"<code>rebuild</code>","text":"<p>Rebuild a package from a package file instead of a recipe</p> <p>Usage: <code>rattler-build rebuild [OPTIONS] --package-file &lt;PACKAGE_FILE&gt;</code></p>"},{"location":"reference/cli/#options_3","title":"Options:","text":"<ul> <li> <p><code>-p</code>, <code>--package-file &lt;PACKAGE_FILE&gt;</code></p> <p>The package file to rebuild (can be a local path or URL)</p> </li> <li> <p><code>--compression-threads &lt;COMPRESSION_THREADS&gt;</code></p> <p>The number of threads to use for compression</p> </li> <li> <p><code>--io-concurrency-limit &lt;IO_CONCURRENCY_LIMIT&gt;</code></p> <p>The number of threads to use for I/O operations when installing packages</p> </li> <li> <p><code>--experimental</code></p> <p>Enable experimental features</p> </li> <li> <p><code>--allow-insecure-host &lt;ALLOW_INSECURE_HOST&gt;</code></p> <p>List of hosts for which SSL certificate verification should be skipped</p> </li> <li> <p><code>--channel-priority &lt;CHANNEL_PRIORITY&gt;</code></p> <p>Channel priority to use when solving</p> </li> </ul>"},{"location":"reference/cli/#modifying-result_2","title":"Modifying result","text":"<ul> <li> <p><code>--test &lt;TEST&gt;</code></p> <p>The strategy to use for running tests</p> <ul> <li>Possible values:<ul> <li><code>skip</code>:     Skip the tests</li> <li><code>native</code>:     Run the tests only if the build platform is the same as the host platform. Otherwise, skip the tests. If the target platform is noarch, the tests are always executed</li> <li><code>native-and-emulated</code>:     Always run the tests</li> </ul> </li> </ul> </li> <li> <p><code>--output-dir &lt;OUTPUT_DIR&gt;</code></p> <p>Output directory for build artifacts.</p> </li> </ul>"},{"location":"reference/cli/#upload","title":"<code>upload</code>","text":"<p>Upload a package</p> <p>Usage: <code>rattler-build upload [OPTIONS] [PACKAGE_FILES]... &lt;COMMAND&gt;</code></p>"},{"location":"reference/cli/#subcommands_1","title":"Subcommands:","text":"<ul> <li><code>quetz</code> \u2014 Upload to a Quetz server. Authentication is used from the keychain / auth-file</li> <li><code>artifactory</code> \u2014 Options for uploading to a Artifactory channel. Authentication is used from the keychain / auth-file</li> <li><code>prefix</code> \u2014 Options for uploading to a prefix.dev server. Authentication is used from the keychain / auth-file</li> <li><code>anaconda</code> \u2014 Options for uploading to a Anaconda.org server</li> <li><code>s3</code> \u2014 Options for uploading to S3</li> </ul>"},{"location":"reference/cli/#arguments","title":"Arguments:","text":"<ul> <li> <p><code>&lt;PACKAGE_FILES&gt;</code></p> <p>The package file to upload</p> </li> </ul>"},{"location":"reference/cli/#options_4","title":"Options:","text":"<ul> <li> <p><code>--experimental</code></p> <p>Enable experimental features</p> </li> <li> <p><code>--allow-insecure-host &lt;ALLOW_INSECURE_HOST&gt;</code></p> <p>List of hosts for which SSL certificate verification should be skipped</p> </li> <li> <p><code>--channel-priority &lt;CHANNEL_PRIORITY&gt;</code></p> <p>Channel priority to use when solving</p> </li> </ul>"},{"location":"reference/cli/#modifying-result_3","title":"Modifying result","text":"<ul> <li> <p><code>--output-dir &lt;OUTPUT_DIR&gt;</code></p> <p>Output directory for build artifacts.</p> </li> </ul>"},{"location":"reference/cli/#quetz","title":"<code>quetz</code>","text":"<p>Upload to a Quetz server. Authentication is used from the keychain / auth-file</p> <p>Usage: <code>rattler-build upload quetz [OPTIONS] --url &lt;URL&gt; --channel &lt;CHANNELS&gt;</code></p>"},{"location":"reference/cli/#options_5","title":"Options:","text":"<ul> <li> <p><code>-u</code>, <code>--url &lt;URL&gt;</code></p> <p>The URL to your Quetz server</p> </li> <li> <p><code>-c</code>, <code>--channel &lt;CHANNELS&gt;</code></p> <p>The URL to your channel</p> </li> <li> <p><code>-a</code>, <code>--api-key &lt;API_KEY&gt;</code></p> <p>The Quetz API key, if none is provided, the token is read from the keychain / auth-file</p> </li> </ul>"},{"location":"reference/cli/#artifactory","title":"<code>artifactory</code>","text":"<p>Options for uploading to a Artifactory channel. Authentication is used from the keychain / auth-file</p> <p>Usage: <code>rattler-build upload artifactory [OPTIONS] --url &lt;URL&gt; --channel &lt;CHANNELS&gt;</code></p>"},{"location":"reference/cli/#options_6","title":"Options:","text":"<ul> <li> <p><code>-u</code>, <code>--url &lt;URL&gt;</code></p> <p>The URL to your Artifactory server</p> </li> <li> <p><code>-c</code>, <code>--channel &lt;CHANNELS&gt;</code></p> <p>The URL to your channel</p> </li> <li> <p><code>-t</code>, <code>--token &lt;TOKEN&gt;</code></p> <p>Your Artifactory token</p> </li> </ul>"},{"location":"reference/cli/#prefix","title":"<code>prefix</code>","text":"<p>Options for uploading to a prefix.dev server. Authentication is used from the keychain / auth-file</p> <p>Usage: <code>rattler-build upload prefix [OPTIONS] --channel &lt;CHANNEL&gt;</code></p>"},{"location":"reference/cli/#options_7","title":"Options:","text":"<ul> <li> <p><code>-u</code>, <code>--url &lt;URL&gt;</code></p> <p>The URL to the prefix.dev server (only necessary for self-hosted instances)</p> <ul> <li>Default value: <code>https://prefix.dev</code></li> </ul> </li> <li> <p><code>-c</code>, <code>--channel &lt;CHANNEL&gt;</code></p> <p>The channel to upload the package to</p> </li> <li> <p><code>-a</code>, <code>--api-key &lt;API_KEY&gt;</code></p> <p>The prefix.dev API key, if none is provided, the token is read from the keychain / auth-file</p> </li> <li> <p><code>--attestation &lt;ATTESTATION&gt;</code></p> <p>Upload one or more attestation files alongside the package Note: if you add an attestation, you can only upload a single package</p> </li> <li> <p><code>-s</code>, <code>--skip-existing</code></p> <p>Skip upload if package is existed</p> </li> </ul>"},{"location":"reference/cli/#anaconda","title":"<code>anaconda</code>","text":"<p>Options for uploading to a Anaconda.org server</p> <p>Usage: <code>rattler-build upload anaconda [OPTIONS] --owner &lt;OWNER&gt;</code></p>"},{"location":"reference/cli/#options_8","title":"Options:","text":"<ul> <li> <p><code>-o</code>, <code>--owner &lt;OWNER&gt;</code></p> <p>The owner of the distribution (e.g. conda-forge or your username)</p> </li> <li> <p><code>-c</code>, <code>--channel &lt;CHANNELS&gt;</code></p> <p>The channel / label to upload the package to (e.g. main / rc)</p> </li> <li> <p><code>-a</code>, <code>--api-key &lt;API_KEY&gt;</code></p> <p>The Anaconda API key, if none is provided, the token is read from the keychain / auth-file</p> </li> <li> <p><code>-u</code>, <code>--url &lt;URL&gt;</code></p> <p>The URL to the Anaconda server</p> </li> <li> <p><code>-f</code>, <code>--force</code></p> <p>Replace files on conflict</p> </li> </ul>"},{"location":"reference/cli/#s3","title":"<code>s3</code>","text":"<p>Options for uploading to S3</p> <p>Usage: <code>rattler-build upload s3 [OPTIONS] --channel &lt;CHANNEL&gt;</code></p>"},{"location":"reference/cli/#options_9","title":"Options:","text":"<ul> <li> <p><code>-c</code>, <code>--channel &lt;CHANNEL&gt;</code></p> <p>The channel URL in the S3 bucket to upload the package to, e.g., <code>s3://my-bucket/my-channel</code></p> </li> <li> <p><code>--endpoint-url &lt;ENDPOINT_URL&gt;</code></p> <p>The endpoint URL of the S3 backend</p> <ul> <li>Default value: <code>https://s3.amazonaws.com</code></li> </ul> </li> <li> <p><code>--region &lt;REGION&gt;</code></p> <p>The region of the S3 backend</p> <ul> <li>Default value: <code>eu-central-1</code></li> </ul> </li> <li> <p><code>--force-path-style</code></p> <p>Whether to use path-style S3 URLs</p> </li> <li> <p><code>--access-key-id &lt;ACCESS_KEY_ID&gt;</code></p> <p>The access key ID for the S3 bucket</p> </li> <li> <p><code>--secret-access-key &lt;SECRET_ACCESS_KEY&gt;</code></p> <p>The secret access key for the S3 bucket</p> </li> <li> <p><code>--session-token &lt;SESSION_TOKEN&gt;</code></p> <p>The session token for the S3 bucket</p> </li> </ul>"},{"location":"reference/cli/#completion","title":"<code>completion</code>","text":"<p>Generate shell completion script</p> <p>Usage: <code>rattler-build completion --shell &lt;SHELL&gt;</code></p>"},{"location":"reference/cli/#options_10","title":"Options:","text":"<ul> <li> <p><code>-s</code>, <code>--shell &lt;SHELL&gt;</code></p> <p>Specifies the shell for which the completions should be generated</p> <ul> <li>Possible values:<ul> <li><code>bash</code>:     Bourne Again SHell (bash)</li> <li><code>elvish</code>:     Elvish shell</li> <li><code>fish</code>:     Friendly Interactive SHell (fish)</li> <li><code>nushell</code>:     Nushell</li> <li><code>powershell</code>:     PowerShell</li> <li><code>zsh</code>:     Z SHell (zsh)</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/cli/#generate-recipe","title":"<code>generate-recipe</code>","text":"<p>Generate a recipe from PyPI, CRAN, CPAN, or LuaRocks</p> <p>Usage: <code>rattler-build generate-recipe &lt;COMMAND&gt;</code></p>"},{"location":"reference/cli/#subcommands_2","title":"Subcommands:","text":"<ul> <li><code>pypi</code> \u2014 Generate a recipe for a Python package from PyPI</li> <li><code>cran</code> \u2014 Generate a recipe for an R package from CRAN</li> <li><code>cpan</code> \u2014 Generate a recipe for a Perl package from CPAN</li> <li><code>luarocks</code> \u2014 Generate a recipe for a Lua package from LuaRocks</li> </ul>"},{"location":"reference/cli/#pypi","title":"<code>pypi</code>","text":"<p>Generate a recipe for a Python package from PyPI</p> <p>Usage: <code>rattler-build generate-recipe pypi [OPTIONS] &lt;PACKAGE&gt;</code></p>"},{"location":"reference/cli/#arguments_1","title":"Arguments:","text":"<ul> <li> <p><code>&lt;PACKAGE&gt;</code></p> <p>Name of the package to generate</p> </li> </ul>"},{"location":"reference/cli/#options_11","title":"Options:","text":"<ul> <li> <p><code>--version &lt;VERSION&gt;</code></p> <p>Select a version of the package to generate (defaults to latest)</p> </li> <li> <p><code>-w</code>, <code>--write</code></p> <p>Whether to write the recipe to a folder</p> </li> <li> <p><code>-u</code>, <code>--use-mapping</code></p> <p>Whether to use the conda-forge PyPI name mapping</p> </li> <li> <p><code>-t</code>, <code>--tree</code></p> <p>Whether to generate recipes for all dependencies</p> </li> </ul>"},{"location":"reference/cli/#cran","title":"<code>cran</code>","text":"<p>Generate a recipe for an R package from CRAN</p> <p>Usage: <code>rattler-build generate-recipe cran [OPTIONS] &lt;PACKAGE&gt;</code></p>"},{"location":"reference/cli/#arguments_2","title":"Arguments:","text":"<ul> <li> <p><code>&lt;PACKAGE&gt;</code></p> <p>Name of the package to generate</p> </li> </ul>"},{"location":"reference/cli/#options_12","title":"Options:","text":"<ul> <li> <p><code>-u</code>, <code>--universe &lt;UNIVERSE&gt;</code></p> <p>The R Universe to fetch the package from (defaults to <code>cran</code>)</p> </li> <li> <p><code>-t</code>, <code>--tree</code></p> <p>Whether to create recipes for the whole dependency tree or not</p> </li> <li> <p><code>-w</code>, <code>--write</code></p> <p>Whether to write the recipe to a folder</p> </li> </ul>"},{"location":"reference/cli/#cpan","title":"<code>cpan</code>","text":"<p>Generate a recipe for a Perl package from CPAN</p> <p>Usage: <code>rattler-build generate-recipe cpan [OPTIONS] &lt;PACKAGE&gt;</code></p>"},{"location":"reference/cli/#arguments_3","title":"Arguments:","text":"<ul> <li> <p><code>&lt;PACKAGE&gt;</code></p> <p>Name of the package to generate</p> </li> </ul>"},{"location":"reference/cli/#options_13","title":"Options:","text":"<ul> <li> <p><code>--version &lt;VERSION&gt;</code></p> <p>Select a version of the package to generate (defaults to latest)</p> </li> <li> <p><code>-w</code>, <code>--write</code></p> <p>Whether to write the recipe to a folder</p> </li> <li> <p><code>-t</code>, <code>--tree</code></p> <p>Whether to generate recipes for all dependencies</p> </li> </ul>"},{"location":"reference/cli/#luarocks","title":"<code>luarocks</code>","text":"<p>Generate a recipe for a Lua package from LuaRocks</p> <p>Usage: <code>rattler-build generate-recipe luarocks [OPTIONS] &lt;ROCK&gt;</code></p>"},{"location":"reference/cli/#arguments_4","title":"Arguments:","text":"<ul> <li> <p><code>&lt;ROCK&gt;</code></p> <p>Luarocks package to generate recipe for. Can be specified as: - module (fetches latest version) - module/version - author/module/version - Direct rockspec URL</p> </li> </ul>"},{"location":"reference/cli/#options_14","title":"Options:","text":"<ul> <li> <p><code>-w</code>, <code>--write-to &lt;WRITE_TO&gt;</code></p> <p>Where to write the recipe to</p> <ul> <li>Default value: <code>.</code></li> </ul> </li> </ul>"},{"location":"reference/cli/#auth","title":"<code>auth</code>","text":"<p>Handle authentication to external channels</p> <p>Usage: <code>rattler-build auth &lt;COMMAND&gt;</code></p>"},{"location":"reference/cli/#subcommands_3","title":"Subcommands:","text":"<ul> <li><code>login</code> \u2014 Store authentication information for a given host</li> <li><code>logout</code> \u2014 Remove authentication information for a given host</li> </ul>"},{"location":"reference/cli/#login","title":"<code>login</code>","text":"<p>Store authentication information for a given host</p> <p>Usage: <code>rattler-build auth login [OPTIONS] &lt;HOST&gt;</code></p>"},{"location":"reference/cli/#arguments_5","title":"Arguments:","text":"<ul> <li> <p><code>&lt;HOST&gt;</code></p> <p>The host to authenticate with (e.g. prefix.dev)</p> </li> </ul>"},{"location":"reference/cli/#options_15","title":"Options:","text":"<ul> <li> <p><code>--token &lt;TOKEN&gt;</code></p> <p>The token to use (for authentication with prefix.dev)</p> </li> <li> <p><code>--username &lt;USERNAME&gt;</code></p> <p>The username to use (for basic HTTP authentication)</p> </li> <li> <p><code>--password &lt;PASSWORD&gt;</code></p> <p>The password to use (for basic HTTP authentication)</p> </li> <li> <p><code>--conda-token &lt;CONDA_TOKEN&gt;</code></p> <p>The token to use on anaconda.org / quetz authentication</p> </li> <li> <p><code>--s3-access-key-id &lt;S3_ACCESS_KEY_ID&gt;</code></p> <p>The S3 access key ID</p> </li> <li> <p><code>--s3-secret-access-key &lt;S3_SECRET_ACCESS_KEY&gt;</code></p> <p>The S3 secret access key</p> </li> <li> <p><code>--s3-session-token &lt;S3_SESSION_TOKEN&gt;</code></p> <p>The S3 session token</p> </li> </ul>"},{"location":"reference/cli/#logout","title":"<code>logout</code>","text":"<p>Remove authentication information for a given host</p> <p>Usage: <code>rattler-build auth logout &lt;HOST&gt;</code></p>"},{"location":"reference/cli/#arguments_6","title":"Arguments:","text":"<ul> <li> <p><code>&lt;HOST&gt;</code></p> <p>The host to remove authentication for</p> </li> </ul>"},{"location":"reference/cli/#debug","title":"<code>debug</code>","text":"<p>Debug a recipe by setting up the environment without running the build script</p> <p>Usage: <code>rattler-build debug [OPTIONS] --recipe &lt;RECIPE&gt;</code></p>"},{"location":"reference/cli/#options_16","title":"Options:","text":"<ul> <li> <p><code>-r</code>, <code>--recipe &lt;RECIPE&gt;</code></p> <p>Recipe file to debug</p> </li> <li> <p><code>-o</code>, <code>--output &lt;OUTPUT&gt;</code></p> <p>Output directory for build artifacts</p> </li> <li> <p><code>--target-platform &lt;TARGET_PLATFORM&gt;</code></p> <p>The target platform to build for</p> </li> <li> <p><code>--host-platform &lt;HOST_PLATFORM&gt;</code></p> <p>The host platform to build for (defaults to target_platform)</p> </li> <li> <p><code>--build-platform &lt;BUILD_PLATFORM&gt;</code></p> <p>The build platform to build for (defaults to current platform)</p> </li> <li> <p><code>-c</code>, <code>--channel &lt;CHANNELS&gt;</code></p> <p>Channels to use when building</p> </li> <li> <p><code>--experimental</code></p> <p>Enable experimental features</p> </li> <li> <p><code>--allow-insecure-host &lt;ALLOW_INSECURE_HOST&gt;</code></p> <p>List of hosts for which SSL certificate verification should be skipped</p> </li> <li> <p><code>--channel-priority &lt;CHANNEL_PRIORITY&gt;</code></p> <p>Channel priority to use when solving</p> </li> <li> <p><code>--output-name &lt;OUTPUT_NAME&gt;</code></p> <p>Name of the specific output to debug</p> </li> </ul>"},{"location":"reference/cli/#modifying-result_4","title":"Modifying result","text":"<ul> <li> <p><code>--output-dir &lt;OUTPUT_DIR&gt;</code></p> <p>Output directory for build artifacts.</p> </li> </ul>"},{"location":"reference/cli/#create-patch","title":"<code>create-patch</code>","text":"<p>Create a patch for a directory</p> <p>Usage: <code>rattler-build create-patch [OPTIONS] --directory &lt;DIRECTORY&gt;</code></p>"},{"location":"reference/cli/#options_17","title":"Options:","text":"<ul> <li> <p><code>-d</code>, <code>--directory &lt;DIRECTORY&gt;</code></p> <p>Directory where we want to create the patch</p> </li> <li> <p><code>--name &lt;NAME&gt;</code></p> <p>The name for the patch file to create</p> <ul> <li>Default value: <code>changes</code></li> </ul> </li> <li> <p><code>--overwrite</code></p> <p>Whether to overwrite the patch file if it already exists</p> </li> <li> <p><code>--patch-dir &lt;DIR&gt;</code></p> <p>Optional directory where the patch file should be written. Defaults to the recipe directory determined from <code>.source_info.json</code> if not provided</p> </li> <li> <p><code>--exclude &lt;EXCLUDE&gt;</code></p> <p>Comma-separated list of file names (or glob patterns) that should be excluded from the diff</p> </li> <li> <p><code>--dry-run</code></p> <p>Perform a dry-run: analyse changes and log the diff, but don't write the patch file</p> </li> </ul> <p>     This document was generated automatically by     <code>clap-markdown</code>. </p>"},{"location":"reference/jinja/","title":"Jinja","text":"<p><code>rattler-build</code> comes with a couple of useful Jinja functions and filters that can be used in the recipe.</p>"},{"location":"reference/jinja/#functions","title":"Functions","text":""},{"location":"reference/jinja/#the-compiler-function","title":"The compiler function","text":"<p>The compiler function can be used to put together a compiler that works for the current platform and the compilation \"<code>target_platform</code>\". The syntax looks like: <code>${{ compiler('c') }}</code> where <code>'c'</code> signifies the programming language that is used.</p> <p>This function evaluates to <code>&lt;compiler&gt;_&lt;target_platform&gt; &lt;compiler_version&gt;</code>. For example, when compiling on <code>linux</code> and to <code>linux-64</code>, this function evaluates to <code>gcc_linux-64</code>.</p> <p>The values can be influenced by the <code>variant_configuration</code>. The <code>&lt;lang&gt;_compiler</code> and <code>&lt;lang&gt;_compiler_version</code> variables are the keys with influence. See below for an example:</p>"},{"location":"reference/jinja/#usage-in-a-recipe","title":"Usage in a recipe","text":"recipe.yaml<pre><code>requirements:\n  build:\n    - ${{ compiler('c') }}\n</code></pre> <p>With a corresponding variant_configuration:</p> variant_configuration.yaml<pre><code>c_compiler:\n- clang\nc_compiler_version:\n- 9.0\n</code></pre> <p>The variables shown above would select the <code>clang</code> compiler in version <code>9.0</code>. Note that the final output will still contain the <code>target_platform</code>, so that the full compiler will read <code>clang_linux-64 9.0</code> when compiling with <code>--target-platform linux-64</code>.</p> <p><code>rattler-build</code> defines some default compilers for the following languages (inherited from <code>conda-build</code>):</p> <ul> <li><code>c</code>: <code>gcc</code> on Linux, <code>clang</code> on <code>osx</code> and <code>vs2017</code> on Windows</li> <li><code>cxx</code>: <code>gxx</code> on Linux, <code>clangxx</code> on <code>osx</code> and <code>vs2017</code> on Windows</li> <li><code>fortran</code>: <code>gfortran</code> on Linux, <code>gfortran</code> on <code>osx</code> and <code>vs2017</code> on Windows</li> <li><code>rust</code>: <code>rust</code></li> </ul>"},{"location":"reference/jinja/#the-stdlib-function","title":"The <code>stdlib</code> function","text":"<p>The <code>stdlib</code> function closely mirrors the compiler function. It can be used to put together a standard library that works for the current platform and the compilation \"<code>target_platform</code>\".</p> <p>Usage: <code>${{ stdlib('c') }}</code></p> <p>Results in <code>&lt;stdlib&gt;_&lt;target_platform&gt; &lt;stdlib_version&gt;</code>. And uses the variant variables <code>&lt;lang&gt;_stdlib</code> and <code>&lt;lang&gt;_stdlib_version</code> to influence the output.</p>"},{"location":"reference/jinja/#usage-in-a-recipe_1","title":"Usage in a recipe:","text":"recipe.yaml<pre><code>requirements:\n  build:\n    # these are usually paired!\n    - ${{ compiler('c') }}\n    - ${{ stdlib('c') }}\n</code></pre> <p>With a corresponding variant_configuration:</p> variant_configuration.yaml<pre><code># these are the values `conda-forge` uses in their pinning file\n# found at https://github.com/conda-forge/conda-forge-pinning-feedstock/blob/main/recipe/conda_build_config.yaml\nc_stdlib:\n- sysroot\nc_stdlib_version:\n- 2.17\n</code></pre>"},{"location":"reference/jinja/#the-pin-functions","title":"The <code>pin</code> functions","text":"<p>A pin is created based on the version input (from a subpackage or a package resolution).</p> <p>The pin functions take the following three arguments:</p> <ul> <li><code>lower_bound</code> (default: <code>\"x.x.x.x.x.x\"</code>): The lower bound pin expression to be   used. When set to <code>None</code>, no lower bound is set.</li> <li><code>upper_bound</code> (default: <code>\"x\"</code>): The maximum pin to be used. When set to   <code>None</code>, no upper bound is set.</li> </ul> <p>The lower bound and upper bound can either be a \"pin expression\" (only <code>x</code> and <code>.</code> are allowed) or a hard-coded version string.</p> <p>A \"pin expression\" is applied to the version input to create the lower and upper bounds. For example, if the version is <code>3.10.5</code> with a  <code>lower_bound=\"x.x\", upper_bound=\"x.x.x\"</code>, the lower bound will be <code>3.10</code> and the upper bound will be <code>3.10.6.0a0</code>. A pin expression for the <code>upper_bound</code> will increment the last selected segment of the version by <code>1</code>, and append <code>.0a0</code> to the end to prevent any alpha versions from being selected.</p> <p>If the last segment of the version contains a letter (e.g. <code>9e</code> or <code>1.1.1j</code>), then incrementing the version will set that letter to <code>a</code>, e.g. <code>9e</code> will become <code>10a</code>, and <code>1.1.1j</code> will become <code>1.1.2a</code>. In this case, also no <code>0a0</code> is appended to the end.</p> <p>Sometimes you want to strongly connect your outputs. This can be achieved with the following input:</p> <ul> <li><code>exact=True</code> (default: <code>False</code>): This will pin the version exactly to the   version of the output, incl. the build string.</li> </ul> <p>To override the lower or upper bound with a hard-coded value, you can use the following input:</p> <ul> <li><code>lower_bound</code> (default: <code>None</code>): This will override the lower bound with the   given value.</li> <li><code>upper_bound</code> (default: <code>None</code>): This will override the upper bound with the   given value.</li> </ul> <p>Both <code>lower_bound</code> and <code>upper_bound</code> expect a valid version string (e.g. <code>1.2.3</code>).</p> <p>To add an build-string matching expression, you can use the <code>build</code> argument:</p> <ul> <li><code>build</code> (default: <code>None</code>): This will add a build string matching expression to   the pin. The build string matching expression is a string that is used to   match the build string with the match spec. For example, if the build string is   <code>py38_0</code>, the build string matching expression could be <code>py38*</code> or to match   exactly <code>py38_0</code>. The <code>build</code> and <code>exact</code> options are mutually exclusive.</li> </ul>"},{"location":"reference/jinja/#the-pin_subpackage-function","title":"The <code>pin_subpackage</code> function","text":"<ul> <li><code>${{ pin_subpackage(\"mypkg\", lower_bound=\"x.x\", upper_bound=\"x.x\") }}</code> creates a pin   to another output in the recipe. With an input of <code>3.1.5</code>, this would create a   pin of <code>mypkg &gt;=3.1,&lt;3.2.0a0</code>.</li> <li><code>${{ pin_subpackage(\"other_output\", exact=True) }}</code> creates a pin to another   output in the recipe with an exact version.</li> <li><code>${{ pin_subpackage(\"other_output\", lower_bound=\"1.2.3\", upper_bound=\"1.2.4\")   }}</code> creates a pin to another output in the recipe with a lower bound of   <code>1.2.3</code> and an upper bound of <code>1.2.4</code>. This is equivalent to writing   <code>other_output &gt;=1.2.3,&lt;1.2.4</code>.</li> <li><code>${{ pin_subpackage(\"foo\", build=\"py38*\") }}</code> creates a matchspec like <code>foo &gt;=3.1,&lt;3.2.0a0 py38*</code>.</li> </ul>"},{"location":"reference/jinja/#the-pin_compatible-function","title":"The <code>pin_compatible</code> function","text":"<p>The pin compatible function works exactly as the <code>pin_subpackage</code> function, but it pins the package in the run requirements based on the resolved package of the <code>host</code> or <code>build</code> section.</p> <ul> <li><code>pin_compatible</code> pins a package in the run requirements based on the resolved   package of the <code>host</code> or <code>build</code> section.</li> </ul>"},{"location":"reference/jinja/#the-cdt-function","title":"The <code>cdt</code> function","text":"<ul> <li><code>${{ cdt(\"mypkg\") }}</code> creates a cross-dependency to another output in the   recipe.</li> </ul> <p>This function helps add Core Dependency Tree packages as dependencies by converting packages as required according to hard-coded logic. See below for an example of how this function can be used:</p> <pre><code># on x86_64 system\ncdt('package-name') # outputs: package-name-cos6-x86_64\n# on aarch64 system\ncdt('package-name') # outputs: package-name-cos6-aarch64\n</code></pre>"},{"location":"reference/jinja/#the-hash-variable","title":"The <code>hash</code> variable","text":"<ul> <li><code>${{ hash }}</code> is the variant hash and is useful in the build string   computation.</li> </ul>"},{"location":"reference/jinja/#the-version_to_buildstring-function","title":"The <code>version_to_buildstring</code> function","text":"<ul> <li><code>${{ python | version_to_buildstring }}</code> converts a version from the variant   to a build string (it removes the <code>.</code> character and takes only the first two   elements of the version).</li> </ul>"},{"location":"reference/jinja/#the-env-object","title":"The <code>env</code> object","text":"<p>You can use the <code>env</code> object to retrieve environment variables and forward them to your build script. <code>${{ env.get(\"MY_ENV_VAR\") }}</code> will return the value of the environment variable <code>MY_ENV_VAR</code> or throw an error if it is not set.</p> <p>To supply a default value when the environment variable is not set, you can use <code>${{ env.get(\"MY_ENV_VAR\", default=\"default_value\") }}</code>. In this case, if <code>MY_ENV_VAR</code> is not set, the value <code>default_value</code> will be returned (and no error is thrown).</p> <p>You can also check for the existence of an environment variable:</p> <ul> <li><code>${{ env.exists(\"MY_ENV_VAR\") }}</code> will return <code>true</code> if the environment   variable <code>MY_ENV_VAR</code> is set and <code>false</code> otherwise.</li> </ul>"},{"location":"reference/jinja/#tests","title":"Tests","text":"<p>You can write tests using minijinja to check whether objects have certain properties. The syntax for a filter is <code>{{ variable is test_name }}</code>.</p> <ul> <li><code>undefined</code>: Check whether a variable is undefined.</li> <li><code>defined</code>: Check whether a variable is defined.</li> <li><code>none</code>: Check whether a variable is none.</li> <li><code>safe</code>: Check whether a variable is safe.</li> <li><code>escaped</code>: Check whether a variable is escaped. Same as <code>is safe</code>.</li> <li><code>odd</code>: Check whether a number is odd.</li> <li><code>even</code>: Check whether a number is even.</li> <li><code>number</code>: Check whether a variable is a number.</li> <li><code>integer</code>: Check whether a variable is an integer.</li> <li><code>int</code>: Check whether a variable is an integer. Same as <code>is integer</code>.</li> <li><code>float</code>: Check whether a variable is a float.</li> <li><code>string</code>: Check whether a variable is a string.</li> <li><code>sequence</code>: Check whether a variable is a sequence.</li> <li><code>boolean</code>: Check whether a variable is a boolean.</li> <li><code>startingwith</code>: Check whether a variable is starting with another string: <code>{{ python is startingwith('3.12') }}</code></li> <li><code>endingwith</code>: Check whether a variable is starting with another string: <code>{{ python is endingwith('.*') }}</code></li> </ul>"},{"location":"reference/jinja/#filters","title":"Filters","text":"<p>A feature of <code>jinja</code> is called \"filters\". Filters are functions that can be applied to variables in a template expression.</p> <p>The syntax for a filter is <code>{{ variable | filter_name }}</code>. A filter can also take arguments, such as <code>... | replace('foo', 'bar')</code>.</p> <p>The following Jinja filters are available, taken from the upstream <code>minijinja</code> library:</p> <ul> <li><code>replace</code>: replace a string with another string (e.g. <code>\"{{ 'foo' | replace('oo', 'aa') }}\"</code> will return <code>\"faa\"</code>)</li> <li><code>lower</code>: convert a string to lowercase (e.g. <code>\"{{ 'FOO' | lower }}\"</code> will return <code>\"foo\"</code>)</li> <li><code>upper</code>: convert a string to uppercase (e.g. <code>\"{{ 'foo' | upper }}\"</code> will return <code>\"FOO\"</code>) - <code>int</code>: convert a string to an integer (e.g. <code>\"{{ '42' | int }}\"</code> will return <code>42</code>)</li> <li><code>abs</code>: return the absolute value of a number (e.g. <code>\"{{ -42 | abs }}\"</code> will return <code>42</code>)</li> <li><code>bool</code>: convert a value to a boolean (e.g. <code>\"{{ 'foo' | bool }}\"</code> will return <code>true</code>)</li> <li><code>default</code>: return a default value if the value is falsy (e.g. <code>\"{{ '' | default('foo') }}\"</code> will return <code>\"foo\"</code>)</li> <li><code>first</code>: return the first element of a list (e.g. <code>\"{{ [1, 2, 3] | first }}\"</code> will return <code>1</code>) - <code>last</code>: return the last element of a list (e.g. <code>\"{{ [1, 2, 3] | last }}\"</code> will return <code>3</code>)</li> <li><code>length</code>: return the length of a list (e.g. <code>\"{{ [1, 2, 3] | length }}\"</code> will return <code>3</code>)</li> <li><code>list</code>: convert a string to a list (e.g. <code>\"{{ 'foo' | list }}\"</code> will return <code>['f', 'o', 'o']</code>)</li> <li><code>join</code>: join a list with a separator (e.g. <code>\"{{ [1, 2, 3] | join('.') }}\"</code> will return <code>\"1.2.3\"</code>)</li> <li><code>min</code>: return the minimum value of a list (e.g. <code>\"{{ [1, 2, 3] | min }}\"</code> will return <code>1</code>)</li> <li><code>max</code>: return the maximum value of a list (e.g. <code>\"{{ [1, 2, 3] | max }}\"</code> will return <code>3</code>)</li> <li><code>reverse</code>: reverse a list (e.g. <code>\"{{ [1, 2, 3] | reverse }}\"</code> will return <code>[3, 2, 1]</code>)</li> <li><code>sort</code>: sort a list (e.g. <code>\"{{ [3, 1, 2] | sort }}\"</code> will return <code>[1, 2, 3]</code>)</li> <li><code>trim</code>: remove leading and trailing whitespace from a string (e.g. <code>\"{{ ' foo ' | trim }}\"</code> will return <code>\"foo\"</code>)</li> <li><code>unique</code>: remove duplicates from a list (e.g. <code>\"{{ [1, 2, 1, 3] | unique }}\"</code> will return <code>[1, 2, 3]</code>)</li> <li><code>split</code>: split a string into a list (e.g. <code>\"{{ '1.2.3' | split('.') | list }}\"</code> will return <code>['1', '2', '3']</code>). By default, splits on whitespace.</li> </ul> Removed filters <p>The following filters are removed from the builtins:</p> <ul> <li><code>attr</code></li> <li><code>indent</code></li> <li><code>select</code></li> <li><code>selectattr</code></li> <li><code>dictsort</code></li> <li><code>reject</code></li> <li><code>rejectattr</code></li> <li><code>round</code></li> <li><code>map</code></li> <li><code>title</code></li> <li><code>capitalize</code></li> <li><code>urlencode</code></li> <li><code>escape</code></li> <li><code>pprint</code></li> <li><code>safe</code></li> <li><code>items</code></li> <li><code>float</code></li> <li><code>tojson</code></li> </ul>"},{"location":"reference/jinja/#extra-filters-for-recipes","title":"Extra filters for recipes","text":""},{"location":"reference/jinja/#the-version_to_buildstring-filter","title":"The <code>version_to_buildstring</code> filter","text":"<ul> <li><code>${{ python | version_to_buildstring }}</code> converts a version from the variant   to a build string (it removes the <code>.</code> character and takes only the first two   elements of the version).</li> </ul> <p>For example the following:</p> <pre><code>context:\n  cuda: \"11.2.0\"\n\nbuild:\n  string: ${{ hash }}_cuda${{ cuda_version | version_to_buildstring }}\n</code></pre> <p>Would evaluate to a <code>abc123_cuda112</code> (assuming the hash was <code>abc123</code>).</p>"},{"location":"reference/jinja/#various-remarks","title":"Various remarks","text":""},{"location":"reference/jinja/#inline-conditionals-with-jinja","title":"Inline conditionals with Jinja","text":"<p>The new recipe format allows for inline conditionals with Jinja. If they are falsey, and no <code>else</code> branch exists, they will render to an empty string (which is, for example in a list or dictionary, equivalent to a YAML <code>null</code>).</p> <p>When a recipe is rendered, all values that are <code>null</code> must be filtered from the resulting YAML.</p> <pre><code>requirements:\n  host:\n    - ${{ \"numpy\" if cuda == \"yes\" }}\n</code></pre> <p>If <code>cuda</code> is not equal to yes, the first item of the host requirements will be empty (null) and thus filtered from the final list.</p> <p>This must also work for dictionary values. For example:</p> <pre><code>build:\n  number: ${{ 100 if cuda == \"yes\" }}\n  # or an `else` branch can be used, of course\n  number: ${{ 100 if cuda == \"yes\" else 0 }}\n</code></pre>"},{"location":"reference/jinja/#slicing-lists","title":"Slicing lists","text":"<p>Lists can be spliced using the regular Python <code>[i:j]</code> syntax.  Note that when lists are obtained through using filters such as <code>split</code>, the whole filter expression needs to be parenthesized.</p> <p>For example, to slice a version string from <code>x.y.z</code> to <code>x.y</code>:</p> <pre><code>${{ (version | split('.'))[:2] | join('.') }}\n</code></pre>"},{"location":"reference/python_bindings/","title":"Python bindings","text":"<p>These are the API docs for the <code>rattler_build</code> Python bindings.</p>"},{"location":"reference/python_bindings/#rattler_build.build_recipes","title":"build_recipes","text":"<pre><code>build_recipes(\n    recipes,\n    up_to=None,\n    build_platform=None,\n    target_platform=None,\n    host_platform=None,\n    channel=None,\n    variant_config=None,\n    variant_overrides=None,\n    ignore_recipe_variants=False,\n    render_only=False,\n    with_solve=False,\n    keep_build=False,\n    no_build_id=False,\n    package_format=None,\n    compression_threads=None,\n    io_concurrency_limit=None,\n    no_include_recipe=False,\n    test=None,\n    output_dir=None,\n    auth_file=None,\n    channel_priority=None,\n    skip_existing=None,\n    noarch_build_platform=None,\n    allow_insecure_host=None,\n    continue_on_failure=False,\n    debug=False,\n    error_prefix_in_binary=False,\n    allow_symlinks_on_windows=False,\n    exclude_newer=None,\n    use_bz2=True,\n    use_zstd=True,\n    use_jlap=False,\n    use_sharded=True,\n)\n</code></pre> <p>Build packages from a list of recipes.</p> <p>Parameters:</p> Name Type Description Default <code>recipes</code> <code>List[Union[str, Path]]</code> <p>The recipe files or directories containing <code>recipe.yaml</code>.</p> required <code>up_to</code> <code>Union[str, None]</code> <p>Build recipes up to the specified package.</p> <code>None</code> <code>build_platform</code> <code>Union[str, None]</code> <p>The build platform to use for the build (e.g. for building with emulation, or rendering).</p> <code>None</code> <code>target_platform</code> <code>Union[str, None]</code> <p>The target platform for the build.</p> <code>None</code> <code>host_platform</code> <code>Union[str, None]</code> <p>The host platform for the build. If set, it will be used to determine also the target_platform (as long as it is not noarch).</p> <code>None</code> <code>channel</code> <code>Union[List[str], None]</code> <p>Add a channel to search for dependencies in.</p> <code>None</code> <code>variant_config</code> <code>Union[List[str], None]</code> <p>Variant configuration files for the build.</p> <code>None</code> <code>variant_overrides</code> <code>Union[Dict[str, List[str]], None]</code> <p>A dictionary of variant key-value pairs to override. Keys are strings, values are lists of strings.</p> <code>None</code> <code>ignore_recipe_variants</code> <code>bool</code> <p>Do not read the <code>variants.yaml</code> file next to a recipe.</p> <code>False</code> <code>render_only</code> <code>bool</code> <p>Render the recipe files without executing the build.</p> <code>False</code> <code>with_solve</code> <code>bool</code> <p>Render the recipe files with solving dependencies.</p> <code>False</code> <code>keep_build</code> <code>bool</code> <p>Keep intermediate build artifacts after the build.</p> <code>False</code> <code>no_build_id</code> <code>bool</code> <p>Don't use build id(timestamp) when creating build directory name.</p> <code>False</code> <code>package_format</code> <code>Union[str, None]</code> <p>The package format to use for the build. Can be one of <code>tar-bz2</code> or <code>conda</code>. You can also add a compression level to the package format, e.g. <code>tar-bz2:&lt;number&gt;</code> (from 1 to 9) or <code>conda:&lt;number&gt;</code> (from -7 to 22).</p> <code>None</code> <code>compression_threads</code> <code>Union[int, None]</code> <p>The number of threads to use for compression (only relevant when also using <code>--package-format conda</code>).</p> <code>None</code> <code>io_concurrency_limit</code> <code>Union[int, None]</code> <p>The maximum number of concurrent I/O operations. This is useful for limiting the number of concurrent file operations.</p> <code>None</code> <code>no_include_recipe</code> <code>bool</code> <p>Don't store the recipe in the final package.</p> <code>False</code> <code>test</code> <code>Union[str, None]</code> <p>The strategy to use for running tests.</p> <code>None</code> <code>output_dir</code> <code>Union[str, Path, None]</code> <p>The directory to store the output.</p> <code>None</code> <code>auth_file</code> <code>Union[str, Path, None]</code> <p>The authentication file.</p> <code>None</code> <code>channel_priority</code> <code>Union[str, None]</code> <p>The channel priority.</p> <code>None</code> <code>skip_existing</code> <code>Union[str, None]</code> <p>Whether to skip packages that already exist in any channel. If set to <code>none</code>, do not skip any packages, default when not specified. If set to <code>local</code>, only skip packages that already exist locally, default when using <code>--skip-existing</code>. If set to <code>all</code>, skip packages that already exist in any channel.</p> <code>None</code> <code>noarch_build_platform</code> <code>Union[str, None]</code> <p>Define a \"noarch platform\" for which the noarch packages will be built for. The noarch builds will be skipped on the other platforms.</p> <code>None</code> <code>allow_insecure_host</code> <code>Union[List[str], None]</code> <p>Allow insecure hosts for the build.</p> <code>None</code> <code>continue_on_failure</code> <code>bool</code> <p>Continue building other recipes even if one fails. (default: False)</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Enable or disable debug mode. (default: False)</p> <code>False</code> <code>error_prefix_in_binary</code> <code>bool</code> <p>Do not allow the $PREFIX to appear in binary files. (default: False)</p> <code>False</code> <code>allow_symlinks_on_windows</code> <code>bool</code> <p>Allow symlinks on Windows and <code>noarch</code> packages. (default: False)</p> <code>False</code> <code>exclude_newer</code> <code>Union[datetime, None]</code> <p>Exclude any packages that were released after the specified date when solving the build, host and test environments. (default: None)</p> <code>None</code> <code>use_bz2</code> <code>bool</code> <p>Allow the use of bzip2 compression when downloading repodata. (default: True)</p> <code>True</code> <code>use_zstd</code> <code>bool</code> <p>Allow the use of zstd compression when downloading repodata. (default: True)</p> <code>True</code> <code>use_jlap</code> <code>bool</code> <p>Allow the use of jlap compression when downloading repodata. (default: False)</p> <code>False</code> <code>use_sharded</code> <code>bool</code> <p>Allow the use of sharded repodata when downloading repodata. (default: True)</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/python_bindings/#rattler_build.test_package","title":"test_package","text":"<pre><code>test_package(\n    package_file,\n    channel=None,\n    compression_threads=None,\n    auth_file=None,\n    channel_priority=None,\n    allow_insecure_host=None,\n    debug=False,\n    test_index=None,\n    use_bz2=True,\n    use_zstd=True,\n    use_jlap=False,\n    use_sharded=True,\n)\n</code></pre> <p>Run a test for a single package.</p> <p>Parameters:</p> Name Type Description Default <code>package_file</code> <code>Union[str, Path]</code> <p>The package file to test.</p> required <code>channel</code> <code>Union[List[str], None]</code> <p>Channels to use when testing.</p> <code>None</code> <code>compression_threads</code> <code>Union[int, None]</code> <p>The number of threads to use for compression.</p> <code>None</code> <code>auth_file</code> <code>Union[str, Path, None]</code> <p>The authentication file.</p> <code>None</code> <code>channel_priority</code> <code>Union[str, None]</code> <p>The channel priority.</p> <code>None</code> <code>allow_insecure_host</code> <code>Union[List[str], None]</code> <p>Allow insecure hosts for the build.</p> <code>None</code> <code>debug</code> <code>bool</code> <p>Enable or disable debug mode. (default: False)</p> <code>False</code> <code>test_index</code> <code>Union[int, None]</code> <p>The test to run, selected by index. (default: None - run all tests)</p> <code>None</code> <code>use_bz2</code> <code>bool</code> <p>Allow the use of bzip2 compression when downloading repodata. (default: True)</p> <code>True</code> <code>use_zstd</code> <code>bool</code> <p>Allow the use of zstd compression when downloading repodata. (default: True)</p> <code>True</code> <code>use_jlap</code> <code>bool</code> <p>Allow the use of jlap compression when downloading repodata. (default: False)</p> <code>False</code> <code>use_sharded</code> <code>bool</code> <p>Allow the use of sharded repodata when downloading repodata. (default: True)</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/python_bindings/#rattler_build.upload_package_to_quetz","title":"upload_package_to_quetz","text":"<pre><code>upload_package_to_quetz(\n    package_files,\n    url,\n    channels,\n    api_key=None,\n    auth_file=None,\n)\n</code></pre> <p>Upload to a Quetz server. Authentication is used from the keychain / auth-file.</p> <p>Parameters:</p> Name Type Description Default <code>package_files</code> <code>List[str]</code> <p>The package files to upload.</p> required <code>url</code> <code>str</code> <p>The URL of the Quetz server.</p> required <code>channels</code> <code>str</code> <p>The channels to upload the package to.</p> required <code>api_key</code> <code>Union[str, None]</code> <p>The API key for authentication.</p> <code>None</code> <code>auth_file</code> <code>Union[str, Path, None]</code> <p>The authentication file.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/python_bindings/#rattler_build.upload_package_to_artifactory","title":"upload_package_to_artifactory","text":"<pre><code>upload_package_to_artifactory(\n    package_files, url, channels, token=None, auth_file=None\n)\n</code></pre> <p>Upload to an Artifactory channel. Authentication is used from the keychain / auth-file.</p> <p>Parameters:</p> Name Type Description Default <code>package_files</code> <code>List[str]</code> <p>The package files to upload.</p> required <code>url</code> <code>str</code> <p>The URL to your Artifactory server.</p> required <code>channels</code> <code>str</code> <p>The URL to your channel.</p> required <code>token</code> <code>Union[str, None]</code> <p>Your Artifactory token.</p> <code>None</code> <code>auth_file</code> <code>Union[str, Path, None]</code> <p>The authentication file.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/python_bindings/#rattler_build.upload_package_to_prefix","title":"upload_package_to_prefix","text":"<pre><code>upload_package_to_prefix(\n    package_files,\n    url,\n    channels,\n    api_key=None,\n    auth_file=None,\n    skip_existing=False,\n)\n</code></pre> <p>Upload to a prefix.dev server. Authentication is used from the keychain / auth-file.</p> <p>Parameters:</p> Name Type Description Default <code>package_files</code> <code>List[str]</code> <p>The package files to upload.</p> required <code>url</code> <code>str</code> <p>The URL to the prefix.dev server (only necessary for self-hosted instances).</p> required <code>channels</code> <code>str</code> <p>The channel to upload the package to.</p> required <code>api_key</code> <code>Union[str, None]</code> <p>The prefix.dev API key, if none is provided, the token is read from the keychain / auth-file.</p> <code>None</code> <code>auth_file</code> <code>Union[str, Path, None]</code> <p>The authentication file.</p> <code>None</code> <code>skip_existing</code> <code>bool</code> <p>Skip upload if package is existed.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/python_bindings/#rattler_build.upload_package_to_anaconda","title":"upload_package_to_anaconda","text":"<pre><code>upload_package_to_anaconda(\n    package_files,\n    owner,\n    channel=None,\n    api_key=None,\n    url=None,\n    force=False,\n    auth_file=None,\n)\n</code></pre> <p>Upload to an Anaconda.org server.</p> <p>Parameters:</p> Name Type Description Default <code>package_files</code> <code>List[str]</code> <p>The package files to upload.</p> required <code>owner</code> <code>str</code> <p>The owner of the Anaconda.org account.</p> required <code>channel</code> <code>Union[List[str], None]</code> <p>The channels to upload the package to.</p> <code>None</code> <code>api_key</code> <code>Union[str, None]</code> <p>The Anaconda.org API key.</p> <code>None</code> <code>url</code> <code>Union[str, None]</code> <p>The URL to the Anaconda.org server.</p> <code>None</code> <code>force</code> <code>bool</code> <p>Whether to force the upload.</p> <code>False</code> <code>auth_file</code> <code>Union[str, Path, None]</code> <p>The authentication file.</p> <code>None</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/python_bindings/#rattler_build.upload_packages_to_conda_forge","title":"upload_packages_to_conda_forge","text":"<pre><code>upload_packages_to_conda_forge(\n    package_files,\n    staging_token,\n    feedstock,\n    feedstock_token,\n    staging_channel=None,\n    anaconda_url=None,\n    validation_endpoint=None,\n    provider=None,\n    dry_run=False,\n)\n</code></pre> <p>Upload to conda forge.</p> <p>Parameters:</p> Name Type Description Default <code>package_files</code> <code>List[Union[str, Path]]</code> <p>The package files to upload.</p> required <code>staging_token</code> <code>str</code> <p>The staging token for conda forge.</p> required <code>feedstock</code> <code>str</code> <p>The feedstock repository.</p> required <code>feedstock_token</code> <code>str</code> <p>The feedstock token.</p> required <code>staging_channel</code> <code>Union[str, None]</code> <p>The staging channel for the upload.</p> <code>None</code> <code>anaconda_url</code> <code>Union[str, None]</code> <p>The URL to the Anaconda.org server.</p> <code>None</code> <code>validation_endpoint</code> <code>Union[str, None]</code> <p>The validation endpoint.</p> <code>None</code> <code>provider</code> <code>Union[str, None]</code> <p>The provider for the upload.</p> <code>None</code> <code>dry_run</code> <code>bool</code> <p>Whether to perform a dry run.</p> <code>False</code> <p>Returns:</p> Type Description <code>None</code> <p>None</p>"},{"location":"reference/recipe_file/","title":"The recipe spec","text":"<p><code>rattler-build</code> implements a new recipe spec, different from the traditional \"<code>meta.yaml</code>\" file used in <code>conda-build</code>. A recipe has to be stored as a <code>recipe.yaml</code> file.</p>"},{"location":"reference/recipe_file/#history","title":"History","text":"<p>A discussion was started on what a new recipe spec could or should look like. The fragments of this discussion can be found here.</p> <p>The reason for a new spec are:</p> <ul> <li>make it easier to parse (i.e. \"pure YAML\"); <code>conda-build</code> uses a mix of comments   and Jinja to achieve a great deal of flexibility, but it's hard to parse the   recipe with a computer</li> <li>iron out some inconsistencies around multiple outputs (<code>build</code> vs. <code>build/script</code>   and more)</li> <li>remove any need for recursive parsing &amp; solving</li> <li>finally, the initial implementation in <code>boa</code> relied on <code>conda-build</code>;   <code>rattler-build</code> removes any dependency on Python or <code>conda-build</code> and   reimplements everything in Rust</li> </ul>"},{"location":"reference/recipe_file/#major-differences-from-conda-build","title":"Major differences from <code>conda-build</code>","text":"<ul> <li>recipe filename is <code>recipe.yaml</code>, not <code>meta.yaml</code></li> <li>outputs have less complicated behavior, keys are same as top-level recipe   (e.g. <code>build/script</code>, not just <code>script</code> and <code>package/name</code>, not just <code>name</code>)</li> <li>no implicit meta-packages in outputs</li> <li>no full Jinja2 support: no conditional or <code>{% set ...</code> support, only string   interpolation; variables can be set in the toplevel \"context\" which is valid   YAML</li> <li>Jinja string interpolation needs to be preceded by a dollar sign at the   beginning of a string, e.g. <code>- ${{ version }}</code> in order for it to be valid   YAML</li> <li> <p>selectors use a YAML dictionary style (vs. comments in conda-build). Instead   of <code>- somepkg  #[osx]</code> we use:   <pre><code>if: osx\nthen:\n  - somepkg\n</code></pre></p> </li> <li> <p><code>skip</code> instruction uses a list of skip conditions and not the selector syntax   from <code>conda-build</code> (e.g. <code>skip: [\"osx\", \"win and py37\"]</code>)</p> </li> </ul>"},{"location":"reference/recipe_file/#spec","title":"Spec","text":"<p>The recipe spec has the following parts:</p> <ul> <li> <code>context</code>: to set up variables that can later be used in Jinja string   interpolation</li> <li> <code>package</code>: defines name, version etc. of the top-level package</li> <li> <code>source</code>: points to the sources that need to be downloaded in order to   build the recipe</li> <li> <code>build</code>: defines how to build the recipe and what build number to use</li> <li> <code>requirements</code>: defines requirements of the top-level package</li> <li> <code>tests</code>: defines tests for the top-level package</li> <li> <code>outputs</code>: a recipe can have multiple outputs. Each output can and should   have a <code>package</code>, <code>requirements</code> and <code>test</code> section</li> </ul>"},{"location":"reference/recipe_file/#spec-reference","title":"Spec reference","text":"<p>The spec is also made available through a JSON Schema (which is used for validation). The schema (and <code>pydantic</code> source file) can be found in this repository: <code>recipe-format</code></p> <p>See more in the automatic linting chapter.</p>"},{"location":"reference/recipe_file/#examples","title":"Examples","text":"recipe.yaml<pre><code># this sets up \"context variables\" (in this case name and version) that\n# can later be used in Jinja expressions\ncontext:\n  version: 1.1.0\n  name: imagesize\n\n# top level package information (name and version)\npackage:\n  name: ${{ name }}\n  version: ${{ version }}\n\n# location to get the source from\nsource:\n  url: https://pypi.io/packages/source/${{ name[0] }}/${{ name }}/${{ name }}-${{ version }}.tar.gz\n  sha256: f3832918bc3c66617f92e35f5d70729187676313caa60c187eb0f28b8fe5e3b5\n\n# build number (should be incremented if a new build is made, but version is not incrementing)\nbuild:\n  number: 1\n  script: python -m pip install .\n\n# the requirements at build and runtime\nrequirements:\n  host:\n    - python\n    - pip\n  run:\n    - python\n\n# tests to validate that the package works as expected\ntests:\n  - python:\n      imports:\n        - imagesize\n\n# information about the package\nabout:\n  homepage: https://github.com/shibukawa/imagesize_py\n  license: MIT\n  summary: 'Getting image size from png/jpeg/jpeg2000/gif file'\n  description: |\n    This module analyzes jpeg/jpeg2000/png/gif image header and\n    return image size.\n  repository: https://github.com/shibukawa/imagesize_py\n  documentation: https://pypi.python.org/pypi/imagesize\n\n# the below is conda-forge specific!\nextra:\n  recipe-maintainers:\n    - somemaintainer\n</code></pre>"},{"location":"reference/recipe_file/#package-section","title":"Package section","text":"<p>Specifies package information.</p> <pre><code>package:\n  name: bsdiff4\n  version: \"2.1.4\"\n</code></pre> <ul> <li>name: The lower case name of the package. It may contain \"<code>-</code>\", but no   spaces.</li> <li>version: The version number of the package. Use the PEP-386 verlib   conventions. Cannot contain \"<code>-</code>\". YAML interprets version numbers such as 1.0   as floats, meaning that 0.10 will be the same as 0.1. To avoid this, put the   version number in quotes so that it is interpreted as a string.</li> </ul>"},{"location":"reference/recipe_file/#source-section","title":"Source section","text":"<p>Specifies where the source code of the package is coming from. The source may come from a tarball file, <code>git</code>, <code>hg</code>, or <code>svn</code>. It may be a local path and it may contain patches.</p>"},{"location":"reference/recipe_file/#source-from-tarball-or-zip-archive","title":"Source from tarball or <code>zip</code> archive","text":"<pre><code>source:\n  url: https://pypi.python.org/packages/source/b/bsdiff4/bsdiff4-1.1.4.tar.gz\n  md5: 29f6089290505fc1a852e176bd276c43\n  sha1: f0a2c9a30073449cfb7d171c57552f3109d93894\n  sha256: 5a022ff4c1d1de87232b1c70bde50afbb98212fd246be4a867d8737173cf1f8f\n</code></pre> <p>If an extracted archive contains only 1 folder at its top level, its contents will be moved 1 level up, so that the extracted package contents sit in the root of the work folder.</p>"},{"location":"reference/recipe_file/#specifying-a-file-name","title":"Specifying a file name","text":"<p>For URL and local paths you can specify a file name. If the source is an archive and a file name is set, automatic extraction is disabled.</p> <pre><code>source:\n  url: https://pypi.python.org/packages/source/b/bsdiff4/bsdiff4-1.1.4.tar.gz\n  # will put the file in the work directory as `bsdiff4-1.1.4.tar.gz`\n  file_name: bsdiff4-1.1.4.tar.gz\n</code></pre>"},{"location":"reference/recipe_file/#source-from-git","title":"Source from <code>git</code>","text":"<pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  # branch: master # note: defaults to fetching the repo's default branch\n</code></pre> <p>You can use <code>rev</code> to pin the commit version directly:</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  rev: \"50a1f7ed6c168eb0815d424cba2df62790f168f0\"\n</code></pre> <p>Or you can use the <code>tag</code>:</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  tag: \"1.1.4\"\n</code></pre> <p><code>git</code> can also be a relative path to the recipe directory:</p> <pre><code>source:\n  git: ../../bsdiff4/.git\n  tag: \"1.1.4\"\n</code></pre> <p>Furthermore, if you want to fetch just the current \"<code>HEAD</code>\" (this may result in non-deterministic builds), then you can use <code>depth</code>.</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  depth: 1 # note: the behaviour defaults to -1\n</code></pre> <p>Note: <code>tag</code> or <code>rev</code> may not be available within commit depth range, hence we don't allow using <code>rev</code> or the <code>tag</code> and <code>depth</code> of them together if not set to <code>-1</code>.</p> <pre><code>source:\n  git: https://github.com/ilanschnell/bsdiff4.git\n  tag: \"1.1.4\"\n  depth: 1 # error: use of `depth` with `rev` is invalid, they are mutually exclusive\n</code></pre> <p>When you want to use <code>git-lfs</code>, you need to set <code>lfs: true</code>. This will also pull the <code>lfs</code> files from the repository.</p> <pre><code>source:\n  git: ../../bsdiff4/.git\n  tag: \"1.1.4\"\n  lfs: true # note: defaults to false\n</code></pre>"},{"location":"reference/recipe_file/#source-from-a-local-path","title":"Source from a local path","text":"<p>If the path is relative, it is taken relative to the recipe directory. The source is copied to the work directory before building.</p> <pre><code>  source:\n    path: ../src\n    use_gitignore: false # note: defaults to true\n</code></pre> <p>By default, all files in the local path that are ignored by <code>git</code> are also ignored by <code>rattler-build</code>. You can disable this behavior by setting <code>use_gitignore</code> to <code>false</code>.</p>"},{"location":"reference/recipe_file/#patches","title":"Patches","text":"<p>Patches may optionally be applied to the source.</p> <pre><code>  source:\n    #[source information here]\n    patches:\n      - my.patch # the patch file is expected to be found in the recipe\n</code></pre>"},{"location":"reference/recipe_file/#destination-path","title":"Destination path","text":"<p>Within <code>rattler-build</code>'s work directory, you may specify a particular folder to place the source into. <code>rattler-build</code> will always drop you into the same folder (<code>[build folder]/work</code>), but it's up to you whether you want your source extracted into that folder, or nested deeper. This feature is particularly useful when dealing with multiple sources, but can apply to recipes with single sources as well.</p> <pre><code>source:\n  #[source information here]\n  target_directory: my-destination/folder\n</code></pre>"},{"location":"reference/recipe_file/#source-from-multiple-sources","title":"Source from multiple sources","text":"<p>Some software is most easily built by aggregating several pieces.</p> <p>The syntax is a list of source dictionaries. Each member of this list follows the same rules as the single source. All features for each member are supported.</p> <p>Example:</p> <pre><code>source:\n  - url: https://package1.com/a.tar.bz2\n    target_directory: stuff\n  - url: https://package1.com/b.tar.bz2\n    target_directory: stuff\n  - git: https://github.com/mamba-org/boa\n    target_directory: boa\n</code></pre> <p>Here, the two URL tarballs will go into one folder, and the <code>git</code> repo is checked out into its own space. <code>git</code> will not clone into a non-empty folder.</p>"},{"location":"reference/recipe_file/#include-only-certain-files-from-source","title":"Include only certain files from source","text":"<p>While you can specify only the files you need from a source, <code>source.filter</code> gives you the option to filter with globs instead.</p> recipe.yaml<pre><code>source:\n  path: /path/to/source\n  filter:\n    - list\n    - of\n    - globs\n</code></pre> <p>Glob patterns throughout the recipe file can also use a flexible <code>include</code> / <code>exclude</code> pair, such as:</p> recipe.yaml<pre><code>source:\n  path: /path/to/source\n  filter:\n    include:\n      - include/**/*.h\n    exclude:\n      - include/**/private.h\n</code></pre>"},{"location":"reference/recipe_file/#build-section","title":"Build section","text":"<p>Specifies build information.</p> <p>Each field that expects a path can also handle a glob pattern. The matching is performed from the top of the build environment, so to match files inside your project you can use a pattern similar to the following one: <code>\"**/myproject/**/*.txt\"</code>. This pattern will match any <code>.txt</code> file found in your project. Quotation marks (<code>\"\"</code>) are required for patterns that start with a <code>*</code>.</p> <p>Recursive globbing using <code>**</code> is also supported.</p>"},{"location":"reference/recipe_file/#build-number-and-string","title":"Build number and string","text":"<p>The build number should be incremented for new builds of the same version. The number defaults to <code>0</code>. The build string cannot contain \"<code>-</code>\". The string defaults to the default <code>rattler-build</code> build string plus the build number.</p> <pre><code>build:\n  number: 1\n  string: abc\n</code></pre>"},{"location":"reference/recipe_file/#dynamic-linking","title":"Dynamic linking","text":"<p>This section contains settings for the shared libraries and executables.</p> <pre><code>build:\n  dynamic_linking:\n    rpath_allowlist: [\"/usr/lib/**\"]\n</code></pre>"},{"location":"reference/recipe_file/#script","title":"Script","text":"<p>By default, <code>rattler-build</code> uses a <code>build.sh</code> file on Unix (macOS and Linux) and a <code>build.bat</code> file on Windows, if they exist in the same folder as the <code>recipe.yaml</code> file. With the script parameter you can either supply a different filename or write out short build scripts. You may need to use selectors to use different scripts for different platforms.</p> <pre><code>build:\n  # A very simple build script\n  script: pip install .\n\n  # The build script can also be a list\n  script:\n    - pip install .\n    - echo \"hello world\"\n    - if: unix\n      then:\n        - echo \"unix\"\n</code></pre> <p>There are many other configurable settings, such as environment variables and secrets. Please see Build script for more information.</p>"},{"location":"reference/recipe_file/#skipping-builds","title":"Skipping builds","text":"<p>Lists conditions under which <code>rattler-build</code> should skip the build of this recipe. Particularly useful for defining recipes that are platform-specific. By default, a build is never skipped.</p> <pre><code>build:\n  skip:\n    - win\n    ...\n</code></pre>"},{"location":"reference/recipe_file/#architecture-independent-packages","title":"Architecture-independent packages","text":"<p>Allows you to specify \"no architecture\" when building a package, thus making it compatible with all platforms and architectures. Architecture-independent packages can be installed on any platform.</p> <p>Assigning the <code>noarch</code> key as <code>generic</code> tells <code>conda</code> to not try any manipulation of the contents.</p> <pre><code>build:\n  noarch: generic\n</code></pre> <p><code>noarch: generic</code> is most useful for packages such as static JavaScript assets and source archives. For pure Python packages (similar to <code>none-any</code> wheels) that can run on any Python version, you can use the <code>noarch: python</code> value instead:</p> <pre><code>build:\n  noarch: python\n</code></pre> <p>Note</p> <p>At the time of this writing, <code>noarch</code> packages should not make use of preprocess-selectors: <code>noarch</code> packages are built with the directives which evaluate to <code>true</code> in the platform it is built on, which probably will result in incorrect/incomplete installation in other platforms.</p>"},{"location":"reference/recipe_file/#include-only-certain-files-in-the-package","title":"Include only certain files in the package","text":"<p>Sometimes you may want to include only a subset of the files installed by the build process in your package. For this, the <code>files</code> key can be used. Only new files are considered for inclusion (ie. files that were not in the host environment beforehand).</p> recipe.yaml<pre><code>build:\n  # select files to be included in the package\n  # this can be used to remove files from the package, even if they are installed in the\n  # environment\n  files:\n    - list\n    - of\n    - globs\n</code></pre> <p>Glob patterns throughout the recipe file can also use a flexible <code>include</code> / <code>exclude</code> pair, such as:</p> recipe.yaml<pre><code>build:\n  files:\n    include:\n      - include/**/*.h\n    exclude:\n      - include/**/private.h\n</code></pre>"},{"location":"reference/recipe_file/#python-specific-options","title":"Python specific options","text":""},{"location":"reference/recipe_file/#entry-points","title":"Entry points","text":"<p>The following example creates a Python entry point named \"<code>bsdiff4</code>\" that calls <code>bsdiff4.cli.main_bsdiff4()</code>. This is needed in <code>noarch: python</code> packages to create OS specific entry points at installation time.</p> <pre><code>build:\n  python:\n    entry_points:\n      - bsdiff4 = bsdiff4.cli:main_bsdiff4\n      - bspatch4 = bsdiff4.cli:main_bspatch4\n</code></pre>"},{"location":"reference/recipe_file/#version-independent-abi3-packages","title":"Version independent (ABI3) packages","text":"<p>Since rattler-build 0.35.0 and CEP 20 you can create version-independent Python packages that still contain compiled code.</p> <p>ABI3 packages support building a native Python extension using a specific Python version and running it against any later Python version. ABI3 or stable ABI is supported by only CPython - the reference Python implementation with the Global Interpreter Lock (GIL) enabled.</p> <pre><code>build:\n  python:\n    version_independent: true  # defaults to false\n</code></pre>"},{"location":"reference/recipe_file/#include-build-recipe","title":"Include build recipe","text":"<p>The recipe and rendered <code>recipe.yaml</code> file are included in the <code>package_metadata</code> by default. You can disable this by passing <code>--no-include-recipe</code> on the command line.</p> <p>Note</p> <p>There are many more options in the build section. These additional options control how variants are computed, prefix replacements, and more. See the full build options for more information.</p>"},{"location":"reference/recipe_file/#requirements-section","title":"Requirements section","text":"<p>Specifies the build and runtime requirements. Dependencies of these requirements are included automatically.</p> <p>Versions for requirements must follow the <code>conda</code>/<code>mamba</code> match specification. See <code>build-version-spec</code>.</p>"},{"location":"reference/recipe_file/#build","title":"Build","text":"<p>Tools required to build the package.</p> <p>These packages are run on the build system and include things such as version control systems (<code>git</code>, <code>svn</code>) make tools (GNU make, Autotool, CMake) and compilers (real cross, pseudo-cross, or native when not cross-compiling), and any source pre-processors.</p> <p>Packages which provide \"<code>sysroot</code>\" files, like the <code>CDT</code> packages (see below), also belong in the <code>build</code> section.</p> <pre><code>requirements:\n  build:\n    - git\n    - cmake\n</code></pre>"},{"location":"reference/recipe_file/#host","title":"Host","text":"<p>Represents packages that need to be specific to the target platform when the target platform is not necessarily the same as the native build platform. For example, in order for a recipe to be \"cross-capable\", shared libraries requirements must be listed in the <code>host</code> section, rather than the <code>build</code> section, so that the shared libraries that get linked are ones for the target platform, rather than the native build platform. You should also include the base interpreter for packages that need one. In other words, a Python package would list <code>python</code> here and an R package would list <code>mro-base</code> or <code>r-base</code>.</p> <pre><code>requirements:\n  build:\n    - ${{ compiler('c') }}\n    - if: linux\n      then:\n        - ${{ cdt('xorg-x11-proto-devel') }}\n  host:\n    - python\n</code></pre> <p>Note</p> <p>When both \"<code>build</code>\" and \"<code>host</code>\" sections are defined, the <code>build</code> section can be thought of as \"build tools\" - things that run on the native platform, but output results for the target platform (e.g. a cross-compiler that runs on <code>linux-64</code>, but targets <code>linux-armv7</code>).</p> <p>The <code>PREFIX</code> environment variable points to the host prefix. With respect to activation during builds, both the host and build environments are activated. The build prefix is activated before the host prefix so that the host prefix has priority over the build prefix. Executables that don't exist in the host prefix should be found in the build prefix.</p> <p>The <code>build</code> and <code>host</code> prefixes are always separate when both are defined, or when <code>${{ compiler() }}</code> Jinja2 functions are used. The only time that <code>build</code> and <code>host</code> are merged is when the <code>host</code> section is absent, and no <code>${{ compiler() }}</code> Jinja2 functions are used in <code>meta.yaml</code>.</p>"},{"location":"reference/recipe_file/#run","title":"Run","text":"<p>Packages required to run the package.</p> <p>These are the dependencies that are installed automatically whenever the package is installed. Package names should follow the package match specifications.</p> <pre><code>requirements:\n  run:\n    - python\n    - six &gt;=1.8.0\n</code></pre> <p>To build a recipe against different versions of NumPy and ensure that each version is part of the package dependencies, list <code>numpy</code> as a requirement in <code>recipe.yaml</code> and use a <code>conda_build_config.yaml</code> file with multiple NumPy versions.</p>"},{"location":"reference/recipe_file/#run-constraints","title":"Run constraints","text":"<p>Packages that are optional at runtime but must obey the supplied additional constraint if they are installed.</p> <p>Package names should follow the package match specifications.</p> <pre><code>requirements:\n  run_constraints:\n    - optional-subpackage ==${{ version }}\n</code></pre> <p>For example, let's say we have an environment that has package \"a\" installed at version 1.0. If we install package \"b\" that has a <code>run_constraints</code> entry of \"<code>a &gt;1.0</code>\", then <code>mamba</code> would need to upgrade \"a\" in the environment in order to install \"b\".</p> <p>This is especially useful in the context of virtual packages, where the <code>run_constraints</code> dependency is not a package that <code>mamba</code> manages, but rather a virtual package that represents a system property that <code>mamba</code> can't change. For example, a package on Linux may impose a <code>run_constraints</code> dependency on <code>__glibc &gt;=2.12</code>. This is the version bound consistent with CentOS 6. Software built against glibc 2.12 will be compatible with CentOS 6. This <code>run_constraints</code> dependency helps <code>mamba</code>, <code>conda</code> or <code>pixi</code> tell the user that a given package can't be installed if their system glibc version is too old.</p>"},{"location":"reference/recipe_file/#run-exports","title":"Run exports","text":"<p>Packages may have runtime requirements such as shared libraries (e.g. <code>zlib</code>), which are required for linking at build time, and for resolving the link at run time. With <code>run_exports</code> packages runtime requirements can be implicitly added. <code>run_exports</code> are weak by default, these two requirements for the <code>zlib</code> package are therefore equivalent:</p> recipe.yaml for zlib<pre><code>  requirements:\n    run_exports:\n      - ${{ pin_subpackage('libzlib', exact=True) }}\n</code></pre> recipe.yaml for zlib<pre><code>  requirements:\n    run_exports:\n      weak:\n        - ${{ pin_subpackage('libzlib', exact=True) }}\n</code></pre> <p>The alternative to <code>weak</code> is <code>strong</code>. For <code>gcc</code> this would look like this:</p> recipe.yaml for gcc<pre><code>  requirements:\n    run_exports:\n      strong:\n        - ${{ pin_subpackage('libgcc', exact=True) }}\n</code></pre> <p><code>weak</code> exports will only be implicitly added as runtime requirement, if the package is a host dependency. <code>strong</code> exports will be added for both build and host dependencies. In the following example you can see the implicitly added runtime dependencies.</p> recipe.yaml of some package using gcc and zlib<pre><code>  requirements:\n    build:\n      - gcc            # has a strong run export\n    host:\n      - zlib           # has a (weak) run export\n      # - libgcc       &lt;-- implicitly added by gcc\n    run:\n      # - libgcc       &lt;-- implicitly added by gcc\n      # - libzlib      &lt;-- implicitly added by libzlib\n</code></pre>"},{"location":"reference/recipe_file/#ignore-run-exports","title":"Ignore run exports","text":"<p>There maybe cases where an upstream package has a problematic <code>run_exports</code> constraint. You can ignore it in your recipe by listing the upstream package name in the <code>ignore_run_exports</code> section in <code>requirements</code>.</p> <p>You can ignore them by package name, or by naming the runtime dependency directly.</p> <pre><code>  requirements:\n    ignore_run_exports:\n      from_package:\n        - zlib\n</code></pre> <p>Using a runtime dependency name:</p> <pre><code>  requirements:\n    ignore_run_exports:\n      by_name:\n        - libzlib\n</code></pre> <p>Note</p> <p><code>ignore_run_exports</code> only applies to runtime dependencies coming from an upstream package.</p>"},{"location":"reference/recipe_file/#tests-section","title":"Tests section","text":"<p><code>rattler-build</code> supports four different types of tests. The \"script test\" installs the package and runs a list of commands. The \"Python test\" attempts to import a list of Python modules and runs <code>pip check</code>. The \"downstream test\" runs the tests of a downstream package that reverse depends on the package being built. And lastly, the \"package content test\" checks if the built package contains the mentioned items.</p> <p>The <code>tests</code> section is a list of these items:</p> <pre><code>tests:\n  - script:\n      - echo \"hello world\"\n    requirements:\n      run:\n        - pytest\n    files:\n      source:\n        - test-data.txt\n\n  - python:\n      imports:\n        - bsdiff4\n      pip_check: true  # this is the default\n  - downstream: numpy\n</code></pre>"},{"location":"reference/recipe_file/#script-test","title":"Script test","text":"<p>The script test has 3 top-level keys: <code>script</code>, <code>files</code> and <code>requirements</code>. Only the <code>script</code> key is required.</p>"},{"location":"reference/recipe_file/#test-commands","title":"Test commands","text":"<p>Commands that are run as part of the test.</p> <pre><code>tests:\n  - script:\n      - echo \"hello world\"\n      - bsdiff4 -h\n      - bspatch4 -h\n</code></pre>"},{"location":"reference/recipe_file/#external-scripts","title":"External scripts","text":"<p>You can also easily run a script from your recipe directory. Note that your package should either depend on the interpreter (e.g. Python or R) or you need to add a <code>requirements</code> section to the test that installs the interpreter.</p> <pre><code>tests:\n  - script: tests/run_test.py\n  - script: tests/run_test.R\n  - script: tests/run_test.sh\n</code></pre>"},{"location":"reference/recipe_file/#extra-test-files","title":"Extra test files","text":"<p>Test files that are copied from the source work directory into the temporary test directory and are needed during testing (note that the source work directory is otherwise not available at all during testing).</p> <p>You can also include files that come from the <code>recipe</code> folder. They are copied into the test directory as well.</p> <p>At test execution time, the test directory is the current working directory.</p> <pre><code>tests:\n  - script:\n      - ls\n    files:\n      source:\n        - myfile.txt\n        - tests/\n        - some/directory/pattern*.sh\n      recipe:\n        - extra-file.txt\n</code></pre>"},{"location":"reference/recipe_file/#test-requirements","title":"Test requirements","text":"<p>In addition to the runtime requirements, you can specify requirements needed during testing. The runtime requirements that you specified in the \"<code>run</code>\" section described above are automatically included during testing (because the built package is installed as it regularly would be).</p> <p>In the <code>build</code> section you can specify additional requirements that are only needed on the build system for cross-compilation (e.g. emulators or compilers).</p> <pre><code>tests:\n  - script:\n      - echo \"hello world\"\n    requirements:\n      build:\n        - myemulator\n      run:\n        - nose\n</code></pre>"},{"location":"reference/recipe_file/#python-tests","title":"Python tests","text":"<p>For this test type you can list a set of Python modules that need to be importable. The test will fail if any of the modules cannot be imported.</p> <p>The test will also automatically run <code>pip check</code> to check for any broken dependencies. This can be disabled by setting <code>pip_check: false</code> in the YAML.</p> <pre><code>tests:\n  - python:\n      imports:\n        - bsdiff4\n        - bspatch4\n      pip_check: true  # can be left out because this is the default\n      python_version: 3.12.*  # optional: use list for multiple versions, default resolves to environment\n</code></pre> <p>Internally this will write a small Python script that imports the modules:</p> <pre><code>import bsdiff4\nimport bspatch4\n</code></pre>"},{"location":"reference/recipe_file/#perl-tests","title":"Perl tests","text":"<p>For this test type you can list a set of Perl modules that need to be importable. The test will fail if any of the modules cannot be imported.</p> <pre><code>tests:\n  - perl:\n      uses:\n        - Call::Context\n</code></pre> <p>Internally this will write a small Perl script that imports the modules:</p> <pre><code>use Call::Context;\n</code></pre>"},{"location":"reference/recipe_file/#r-tests","title":"R tests","text":"<p>For this test type you can list a set of R modules that need to be importable. The test will fail if any of the modules cannot be imported.</p> <pre><code>- r:\n    libraries:\n      - knitr\n</code></pre> <p>Internally this will write a small R script that imports the modules:</p> <pre><code>library(knitr)\n</code></pre>"},{"location":"reference/recipe_file/#check-for-package-contents","title":"Check for package contents","text":"<p>Checks if the built package contains the mentioned items. These checks are executed directly at the end of the build process to make sure that all expected files are present in the package.</p> <pre><code>tests:\n  - package_contents:\n      # checks for the existence of files inside $PREFIX or %PREFIX%\n      # or, checks that there is at least one file matching the specified `glob`\n      # pattern inside the prefix\n      files:\n        - etc/libmamba/test.txt\n        - etc/libmamba\n        - etc/libmamba/*.mamba.txt\n\n      # For more advanced cases, you can use the expanded form with exists and not_exists:\n      # files:\n      #   exists:\n      #     - etc/libmamba/test.txt\n      #     - etc/libmamba\n      #     - etc/libmamba/*.mamba.txt\n      #   not_exists:\n      #     - etc/libmamba/unwanted.txt\n\n      # checks for the existence of `mamba/api/__init__.py` inside of the\n      # Python site-packages directory (note: also see Python import checks)\n      site_packages:\n        - mamba.api\n\n\n      # looks in $PREFIX/bin/mamba for unix and %PREFIX%\\Library\\bin\\mamba.exe on Windows\n      # note: also check the `commands` and execute something like `mamba --help` to make\n      # sure things work fine\n      bin:\n        - mamba\n\n      # enable strict mode: error if any file in the package is not matched by one of the globs\n      # (default: false)\n      strict: true\n\n      # searches for `$PREFIX/lib/libmamba.so` or `$PREFIX/lib/libmamba.dylib` on Linux or macOS,\n      # on Windows for %PREFIX%\\Library\\lib\\mamba.dll &amp; %PREFIX%\\Library\\bin\\mamba.bin\n      lib:\n        - mamba\n\n      # searches for `$PREFIX/include/libmamba/mamba.hpp` on unix, and\n      # on Windows for `%PREFIX%\\Library\\include\\libmamba\\mamba.hpp`\n      include:\n        - libmamba/mamba.hpp\n</code></pre>"},{"location":"reference/recipe_file/#downstream-tests","title":"Downstream tests","text":"<p>Warning</p> <p>Downstream tests are not yet implemented in <code>rattler-build</code>.</p> <p>A downstream test can mention a single package that has a dependency on the package being built. The test will install the package and run the tests of the downstream package with our current package as a dependency.</p> <p>Sometimes downstream packages do not resolve. In this case, the test is ignored.</p> <pre><code>tests:\n  - downstream: numpy\n</code></pre>"},{"location":"reference/recipe_file/#outputs-section","title":"Outputs section","text":"<p>Explicitly specifies packaging steps. This section supports multiple outputs, as well as different package output types. The format is a list of mappings.</p> <p>When using multiple outputs, certain top-level keys are \"forbidden\": <code>package</code> and <code>requirements</code>. Instead of <code>package</code>, a top-level <code>recipe</code> key can be defined. The <code>recipe.name</code> is ignored but the <code>recipe.version</code> key is used as default version for each output. Other \"top-level\" keys are merged into each output (e.g. the <code>about</code> section) to avoid repetition. Each output is a complete recipe, and can have its own <code>build</code>, <code>requirements</code>, and <code>test</code> sections.</p> <pre><code>recipe:\n  # the recipe name is ignored\n  name: some\n  version: 1.0\n\noutputs:\n  - package:\n      # version is taken from recipe.version (1.0)\n      name: some-subpackage\n\n  - package:\n      name: some-other-subpackage\n      version: 2.0\n</code></pre> <p>Each output acts like an independent recipe and can have their own <code>script</code>, <code>build_number</code>, and so on.</p> <pre><code>outputs:\n  - package:\n      name: subpackage-name\n    build:\n      script: install-subpackage\n</code></pre> <p>If <code>script</code> lacks a file extension, the appropriate extension for the platform will be appended, e.g. the above will run <code>install-subpackage.sh</code> in <code>bash</code> on most platforms and <code>install-subpackage.bat</code> in <code>cmd.exe</code> on Windows.</p> <p>Each output is built independently. You should take care of not packaging the same files twice.</p>"},{"location":"reference/recipe_file/#subpackage-requirements","title":"Subpackage requirements","text":"<p>Like a top-level recipe, a subpackage may have zero or more dependencies listed as build, host or run requirements.</p> <p>The dependencies listed as subpackage build requirements are available only during the packaging phase of that subpackage.</p> <pre><code>outputs:\n  - package:\n      name: subpackage-name\n    requirements:\n      build:\n        - some-dep\n      run:\n        - some-dep\n</code></pre> <p>You can also use the <code>pin_subpackage</code> function to pin another output from the same recipe.</p> <pre><code>outputs:\n  - package:\n      name: libtest\n  - package:\n      name: test\n    requirements:\n      build:\n        - ${{ pin_subpackage('libtest', upper_bound='x.x') }}\n</code></pre> <p>The outputs are topologically sorted by the dependency graph which is taking the <code>pin_subpackage</code> invocations into account. When using <code>pin_subpackage(name, exact=True)</code> a special behavior is used where the <code>name</code> package is injected as a \"variant\" and the variant matrix is expanded appropriately. For example, when you have the following situation, with a <code>variant_config.yaml</code> file that contains <code>openssl: [1, 3]</code>:</p> <pre><code>outputs:\n  - package:\n      name: libtest\n    requirements:\n      host:\n        - openssl\n  - package:\n      name: test\n    requirements:\n      build:\n        - ${{ pin_subpackage('libtest', exact=True) }}\n</code></pre> <p>Due to the variant config file, this will build two versions of <code>libtest</code>. We will also build two versions of <code>test</code>, one that depends on <code>libtest (openssl 1)</code> and one that depends on <code>libtest (openssl 3)</code>.</p>"},{"location":"reference/recipe_file/#about-section","title":"About section","text":"<p>Specifies identifying information about the package. The information displays in the package server.</p> <pre><code>about:\n  homepage: https://example.com/bsdiff4\n  license: BSD-3-Clause # (1)!\n  license_file: LICENSE\n  summary: binary diff and patch using the BSDIFF4-format\n  description: |\n    Long description of bsdiff4 ...\n  repository: https://github.com/ilanschnell/bsdiff4\n  documentation: https://docs.com\n</code></pre> <ol> <li>Only the SPDX specifiers are allowed, more info here: SPDX     If you want another license type <code>LicenseRef-&lt;YOUR-LICENSE&gt;</code> can be used, e.g. <code>license: LicenseRef-Proprietary</code></li> </ol>"},{"location":"reference/recipe_file/#license-file","title":"License file","text":"<p>Adds a file containing the software license to the package metadata. Many licenses require the license statement to be distributed with the package. The filename is relative to the source or recipe directory. The value can be a single filename or a YAML list for multiple license files. Values can also point to directories with license information. Directory entries must end with a <code>/</code> suffix (this is to lessen unintentional inclusion of non-license files; all the directory's contents will be unconditionally and recursively added).</p> <p>If a license file is found in both the source and recipe directories, the file from the recipe directory is used (you should see a warning about this in the build log).</p> <pre><code>about:\n  license_file:\n    - LICENSE\n    - vendor-licenses/\n</code></pre>"},{"location":"reference/recipe_file/#extra-section","title":"Extra section","text":"<p>A schema-free area for storing non-<code>conda</code>-specific metadata in standard YAML form.</p> Example: To store recipe maintainers information <pre><code>extra:\n  maintainers:\n   - name of maintainer\n</code></pre>"},{"location":"reference/recipe_file/#templating-with-jinja","title":"Templating with Jinja","text":"<p><code>rattler-build</code> supports limited Jinja templating in the <code>recipe.yaml</code> file.</p> <p>You can set up Jinja variables in the <code>context</code> section:</p> <pre><code>context:\n  name: \"test\"\n  version: \"5.1.2\"\n  # later keys can reference previous keys\n  # and use jinja functions to compute new values\n  major_version: ${{ version.split('.')[0] }}\n  tests_to_skip:\n    # fails for one reason\n    - test_foo\n    # fails for another reason\n    - test_bar\n</code></pre> <p>Later in your <code>recipe.yaml</code> you can use these values in string interpolation with Jinja:</p> <pre><code>source:\n  url: https://github.com/mamba-org/${{ name }}/v${{ version }}.tar.gz\n\ntests:\n  - script:\n    - pytest -k \"not (${{ tests_to_skip | join(\" or \")\" }})\"\n</code></pre> <p>Jinja has built-in support for some common string manipulations.</p> <p>In rattler-build, complex Jinja is completely disallowed as we try to produce YAML that is valid at all times. So you should not use any <code>{% if ... %}</code> or similar Jinja constructs that produce invalid YAML. Furthermore, instead of plain double curly brackets Jinja statements need to be prefixed by <code>$</code>, e.g. <code>${{ ... }}</code>:</p> <pre><code>package:\n  name: {{ name }}   # WRONG: invalid yaml\n  name: ${{ name }} # correct\n</code></pre> <p>For more information, see the Jinja template documentation and the list of available environment variables <code>env-vars</code>.</p> <p>Jinja templates are evaluated during the build process.</p>"},{"location":"reference/recipe_file/#additional-jinja2-functionality-in-rattler-build","title":"Additional Jinja2 functionality in rattler-build","text":"<p>Besides the default Jinja2 functionality, additional Jinja functions are available during the <code>rattler-build</code> process: <code>pin_compatible</code>, <code>pin_subpackage</code>, and <code>compiler</code>.</p> <p>The compiler function takes <code>c</code>, <code>cxx</code>, <code>fortran</code> and other values as argument and automatically selects the right (cross-)compiler for the target platform.</p> <pre><code>build:\n  - ${{ compiler('c') }}\n</code></pre> <p>The <code>pin_subpackage</code> function pins another package produced by the recipe with the supplied parameters.</p> <p>Similarly, the <code>pin_compatible</code> function will pin a package according to the specified rules.</p>"},{"location":"reference/recipe_file/#pin-expressions","title":"Pin expressions","text":"<p><code>rattler-build</code> knows pin expressions. A pin expression can have a <code>lower_bound</code>, <code>upper_bound</code> and <code>exact</code> value. A <code>upper_bound</code> and <code>lower_bound</code> are specified with a string containing only <code>x</code> and <code>.</code>, e.g. <code>upper_bound=\"x.x.x\"</code> would signify to pin the given package to <code>&lt;1.2.3</code> (if the package version is <code>1.2.2</code>, for example).</p> <p>A pin with <code>lower_bound=\"x.x\",upper_bound=\"x.x\"</code> for a package of version <code>1.2.2</code> would evaluate to <code>&gt;=1.2,&lt;1.3.0a0</code>.</p> <p>If <code>exact=true</code>, then the <code>hash</code> is included, and the package is pinned exactly, e.g. <code>==1.2.2 h1234</code>. This is a unique package variant that cannot exist more than once, and thus is \"exactly\" pinned.</p> <p>You can also hard-code version strings into <code>lower_bound</code> and <code>upper_bound</code>. See the Jinja Reference for more information.</p>"},{"location":"reference/recipe_file/#pin-subpackage","title":"Pin subpackage","text":"<p>Pin subpackage refers to another package from the same recipe file. It is commonly used in the <code>build/run_exports</code> section to export a run export from the package, or with multiple outputs to refer to a previous build.</p> <p>It looks something like:</p> <pre><code>package:\n  name: mypkg\n  version: \"1.2.3\"\n\nrequirements:\n  run_exports:\n    # this will evaluate to `mypkg &lt;1.3`\n    - ${{ pin_subpackage(name, upper_bound='x.x') }}\n</code></pre>"},{"location":"reference/recipe_file/#pin-compatible","title":"Pin compatible","text":"<p>Pin compatible lets you pin a package based on the version retrieved from the variant file (if the pinning from the variant file needs customization).</p> <p>For example, if the variant specifies a pin for <code>numpy: 1.11</code>, one can use <code>pin_compatible</code> to relax it:</p> <pre><code>requirements:\n  host:\n    # this will select numpy 1.11\n    - numpy\n  run:\n    # this will export `numpy &gt;=1.11,&lt;2`, instead of the stricter `1.11` pin\n    - ${{ pin_compatible('numpy', min_pin='x.x', upper_bound='x') }}\n</code></pre>"},{"location":"reference/recipe_file/#the-env-jinja-functions","title":"The env Jinja functions","text":"<p>You can access the current environment variables using the <code>env</code> object in Jinja.</p> <p>There are three functions:</p> <ul> <li><code>env.get(\"ENV_VAR\")</code> will insert the value of \"ENV_VAR\" into the recipe.</li> <li><code>env.get(\"ENV_VAR\", default=\"undefined\")</code> will insert the value of <code>ENV_VAR</code>   into the recipe or, if <code>ENV_VAR</code> is not defined, the specified default value   (in this case \"undefined\")</li> <li><code>env.exists(\"ENV_VAR\")</code> returns a boolean true of false if the env var is set   to any value</li> </ul> <p>This can be used for some light templating, for example:</p> <pre><code>build:\n  string: ${{ env.get(\"GIT_BUILD_STRING\") }}_${{ hash }}\n</code></pre>"},{"location":"reference/recipe_file/#match-function","title":"<code>match</code> function","text":"<p>This function matches the first argument (the package version) against the second argument (the version spec) and returns the resulting boolean. This only works for packages defined in the \"variant_config.yaml\" file.</p> recipe.yaml<pre><code>match(python, '&gt;=3.4')\n</code></pre> <p>For example, you could require a certain dependency only for builds against python 3.4 and above:</p> recipe.yaml<pre><code>requirements:\n  build:\n    - if: match(python, '&gt;=3.4')\n      then:\n        - some-dep\n</code></pre> <p>With a corresponding variant config that looks like the following:</p> variant_config.yaml<pre><code>python: [\"3.2\", \"3.4\", \"3.6\"]\n</code></pre> <p>Example: <code>match</code> usage example</p>"},{"location":"reference/recipe_file/#cdt-function","title":"<code>cdt</code> function","text":"<p>This function helps add Core Dependency Tree packages as dependencies by converting packages as required according to hard-coded logic.</p> <pre><code># on x86_64 system\ncdt('package-name') # outputs: package-name-cos6-x86_64\n# on aarch64 system\ncdt('package-name') # outputs: package-name-cos6-aarch64\n</code></pre> <p>Example: <code>cdt</code> usage example</p>"},{"location":"reference/recipe_file/#preprocessing-selectors","title":"Preprocessing selectors","text":"<p>You can add selectors to any item, and the selector is evaluated in a preprocessing stage. If a selector evaluates to <code>true</code>, the item is flattened into the parent element. If a selector evaluates to <code>false</code>, the item is removed.</p> <p>Selectors can use <code>if ... then ... else</code> as follows:</p> <pre><code>source:\n  - if: not win\n    then:\n      - url: http://path/to/unix/source\n    else:\n      - url: http://path/to/windows/source\n\n# or the equivalent with two if conditions:\n\nsource:\n  - if: unix\n    then:\n      - url: http://path/to/unix/source\n  - if: win\n    then:\n      - url: http://path/to/windows/source\n</code></pre> <p>A selector is a valid Python statement that is executed. You can read more about them in the \"Selectors in recipes\" chapter.</p> <p>The use of the Python version selectors, <code>py27</code>, <code>py34</code>, etc. is discouraged in favor of the more general comparison operators. Additional selectors in this series will not be added to <code>conda-build</code>.</p> <p>Because the selector is any valid Python expression, complicated logic is possible:</p> <pre><code>- if: unix and not win\n  then: ...\n- if: (win or linux) and not py27\n  then: ...\n</code></pre> <p>Lists are automatically \"merged\" upwards, so it is possible to group multiple items under a single selector:</p> <pre><code>tests:\n  - script:\n    - if: unix\n      then:\n      - test -d ${PREFIX}/include/xtensor\n      - test -f ${PREFIX}/lib/cmake/xtensor/xtensorConfigVersion.cmake\n    - if: win\n      then:\n      - if not exist %LIBRARY_PREFIX%\\include\\xtensor\\xarray.hpp (exit 1)\n      - if not exist %LIBRARY_PREFIX%\\lib\\cmake\\xtensor\\xtensorConfigVersion.cmake (exit 1)\n\n# On unix this is rendered to:\ntests:\n  - script:\n    - test -d ${PREFIX}/include/xtensor\n    - test -f ${PREFIX}/lib/cmake/xtensor/xtensorConfigVersion.cmake\n</code></pre>"},{"location":"reference/recipe_file/#experimental-features","title":"Experimental features","text":"<p>Warning</p> <p>These are experimental features of <code>rattler-build</code> and may change or go away completely.</p>"},{"location":"reference/recipe_file/#jinja-functions","title":"Jinja functions","text":"<ul> <li><code>load_from_file</code></li> <li><code>git.*</code> functions</li> </ul>"},{"location":"tutorials/cpp/","title":"Packaging a C++ package","text":"<p>This tutorial will guide you though making a C++ package with <code>rattler-build</code>.</p>"},{"location":"tutorials/cpp/#building-a-header-only-library","title":"Building a Header-only Library","text":"<p>To build a package for the header-only library <code>xtensor</code>, you need to manage dependencies and ensure proper installation paths.</p>"},{"location":"tutorials/cpp/#key-steps","title":"Key Steps","text":"<ol> <li> <p>Dependencies:    Ensure <code>cmake</code>, <code>ninja</code>, and a <code>compiler</code> are available as dependencies.</p> </li> <li> <p>CMake Installation Prefix:    Use the <code>CMAKE_INSTALL_PREFIX</code> setting to instruct <code>CMake</code> to install the headers in the correct location.</p> </li> <li> <p>Unix Systems:        Follow the standard Unix prefix:        <pre><code>$PREFIX/include\n$PREFIX/lib\n</code></pre></p> </li> <li> <p>Windows Systems:      Use a Unix-like prefix but nested in a <code>Library</code> directory:      <pre><code>$PREFIX/Library/include\n$PREFIX/Library/lib\n</code></pre>      Utilize the handy variables <code>%LIBRARY_PREFIX%</code> and <code>%LIBRARY_BIN%</code> to guide <code>CMake</code> to install the headers and libraries correctly.</p> </li> </ol> <p>This approach ensures that the headers and libraries are installed in the correct directories on both Unix and Windows systems.</p>"},{"location":"tutorials/cpp/#recipe","title":"Recipe","text":"recipe.yaml<pre><code>context:\n  version: \"0.24.6\"\n\npackage:\n  name: xtensor\n  version: ${{ version }}\n\nsource:\n  url: https://github.com/xtensor-stack/xtensor/archive/${{ version }}.tar.gz\n  sha256: f87259b51aabafdd1183947747edfff4cff75d55375334f2e81cee6dc68ef655\n\nbuild:\n  number: 0\n  script:\n    - if: win # (1)!\n      then: |\n        cmake -GNinja ^\n            -D BUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=%LIBRARY_PREFIX% ^\n            %SRC_DIR%\n        ninja install\n      else: |\n        cmake -GNinja \\\n              -DBUILD_TESTS=OFF -DCMAKE_INSTALL_PREFIX=$PREFIX \\\n              $SRC_DIR\n        ninja install\n\nrequirements:\n  build:\n    - ${{ compiler('cxx') }} # (2)!\n    - cmake\n    - ninja\n  host:\n    - xtl &gt;=0.7,&lt;0.8\n  run:\n    - xtl &gt;=0.7,&lt;0.8\n  run_constraints: # (3)!\n    - xsimd &gt;=8.0.3,&lt;10\n\ntests:\n  - package_contents:\n      include: # (4)!\n        - xtensor/xarray.hpp\n      files: # (5)!\n        exists:\n          - ${{ \"Library/\" if win }}share/cmake/xtensor/xtensorConfig.cmake\n          - ${{ \"Library/\" if win }}share/cmake/xtensor/xtensorConfigVersion.cmake\n\nabout:\n  homepage: https://github.com/xtensor-stack/xtensor\n  license: BSD-3-Clause\n  license_file: LICENSE\n  summary: The C++ tensor algebra library\n  description: Multi dimensional arrays with broadcasting and lazy computing\n  documentation: https://xtensor.readthedocs.io\n  repository: https://github.com/xtensor-stack/xtensor\n\nextra:\n  recipe-maintainers:\n    - some-maintainer\n</code></pre> <ol> <li>The <code>if:</code> condition allows the user to switch behavior of the build based on some checks like, the operating system.</li> <li>The <code>compiler</code> function is used to get the C++ compiler for the build system.</li> <li>The <code>run_constraints</code> section specifies the version range of a package which the package can run \"with\". But which the package doesn't depend on itself.</li> <li>The <code>include</code> section specifies the header file to tested for existence.</li> <li>The <code>files</code> section specifies the files to be tested for existence, using a glob pattern.</li> </ol> <p><code>CMAKE_ARGS</code></p> <p>It can be tedious to remember all the different variables one needs to pass to CMake to create the perfect build. The <code>cmake</code> package on conda-forge introduces the<code>CMAKE_ARGS</code> environment variable. This variable contains the necessary flags to make the package build correctly, also when cross-compiling from one machine to another. Therefore, it is often not necessary to pass any additional flags to the <code>cmake</code> command. However, because this is a tutorial we will show how to pass the necessary flags to <code>cmake</code> manually.</p> <p>For more information please refer to the conda-forge documentation.</p>"},{"location":"tutorials/cpp/#building-a-c-application","title":"Building A C++ application","text":"<p>In this example, we'll build <code>poppler</code>, a C++ application for manipulating PDF files from the command line. The final package will install several tools into the <code>bin/</code> folder. We'll use external build scripts and run actual scripts in the test.</p>"},{"location":"tutorials/cpp/#key-steps_1","title":"Key Steps","text":"<ol> <li> <p>Dependencies:</p> <ul> <li>Build Dependencies: These are necessary for the building process, including <code>cmake</code>, <code>ninja</code>, and <code>pkg-config</code>.</li> <li>Host Dependencies: These are the libraries <code>poppler</code> links against, such as <code>cairo</code>, <code>fontconfig</code>, <code>freetype</code>, <code>glib</code>, and others.</li> </ul> </li> <li> <p>Compiler Setup:    We use the <code>compiler</code> function to obtain the appropriate C and C++ compilers.</p> </li> <li> <p>Build Script:    The <code>build.script</code> field points to an external script (<code>poppler-build.sh</code>) which contains the build commands.</p> </li> <li> <p>Testing:    Simple tests are included to verify that the installed tools (<code>pdfinfo</code>, <code>pdfunite</code>, <code>pdftocairo</code>) are working correctly by running them, and expecting an exit code <code>0</code>.</p> </li> </ol>"},{"location":"tutorials/cpp/#recipe_1","title":"Recipe","text":"recipe.yaml<pre><code>context:\n  version: \"24.01.0\"\n\npackage:\n  name: poppler\n  version: ${{ version }}\n\nsource:\n  url: https://poppler.freedesktop.org/poppler-${{ version }}.tar.xz\n  sha256: c7def693a7a492830f49d497a80cc6b9c85cb57b15e9be2d2d615153b79cae08\n\nbuild:\n  script: poppler-build.sh\n\nrequirements:\n  build:\n    - ${{ compiler('c') }} # (1)!\n    - ${{ compiler('cxx') }}\n    - pkg-config\n    - cmake\n    - ninja\n  host:\n    - cairo # (2)!\n    - fontconfig\n    - freetype\n    - glib\n    - libboost-headers\n    - libjpeg-turbo\n    - lcms2\n    - libiconv\n    - libpng\n    - libtiff\n    - openjpeg\n    - zlib\n\ntests:\n  - script:\n      - pdfinfo -listenc  # (3)!\n      - pdfunite --help\n      - pdftocairo --help\n</code></pre> <ol> <li>The <code>compiler</code> jinja function to get the correct compiler for C and C++ on the build system.</li> <li>These are all the dependencies that the library links against.</li> <li>The script test just executes some of the installed tools to check if they    are working. These can be as complex as you want. (<code>bash</code> or <code>cmd.exe</code>)</li> </ol>"},{"location":"tutorials/cpp/#external-build-script","title":"External Build Script","text":"<p>We've defined an external build script in the recipe. This will be searched next to the recipe by the file name given, or the default name <code>build.sh</code> on <code>unix</code> or <code>build.bat</code> on windows are searched for.</p> poppler-build.sh<pre><code>#! /bin/bash\n\nextra_cmake_args=(\n    -GNinja\n    -DCMAKE_INSTALL_LIBDIR=lib\n    -DENABLE_UNSTABLE_API_ABI_HEADERS=ON\n    -DENABLE_GPGME=OFF\n    -DENABLE_LIBCURL=OFF\n    -DENABLE_LIBOPENJPEG=openjpeg2\n    -DENABLE_QT6=OFF\n    -DENABLE_QT5=OFF\n    -DENABLE_NSS3=OFF\n)\n\nmkdir build &amp;&amp; cd build\n\ncmake ${CMAKE_ARGS} \"${extra_cmake_args[@]}\" \\\n    -DCMAKE_PREFIX_PATH=$PREFIX \\\n    -DCMAKE_INSTALL_PREFIX=$PREFIX \\\n    -DTIFF_INCLUDE_DIR=$PREFIX/include \\\n    $SRC_DIR\n\nninja\n\n# The `install` command will take care of copying the files to the right place\nninja install\n</code></pre>"},{"location":"tutorials/cpp/#parsing-the-rattler-build-build-output","title":"Parsing the <code>rattler-build build</code> Output","text":"<p>When running the <code>rattler-build</code> command, you might notice some interesting information in the output. Our package will have some <code>run</code> dependencies, even if we didn't specify any.</p> <p>These come from the <code>run-exports</code> of the packages listed in the <code>host</code> section of the recipe. This is indicated by <code>\"RE of [host: package]\"</code> in the output.</p> <p>For example, <code>libcurl</code> specifies that if you depend on it in the host section, you should also depend on it during runtime with specific version ranges. This ensures proper linking to shared libraries.</p> <pre><code>Run dependencies:\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Name                  \u2506 Spec                                         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 libcurl               \u2506 &gt;=8.5.0,&lt;9.0a0 (RE of [host: libcurl])       \u2502\n\u2502 fontconfig            \u2506 &gt;=2.14.2,&lt;3.0a0 (RE of [host: fontconfig])   \u2502\n\u2502 fonts-conda-ecosystem \u2506 (RE of [host: fontconfig])                   \u2502\n\u2502 lcms2                 \u2506 &gt;=2.16,&lt;3.0a0 (RE of [host: lcms2])          \u2502\n\u2502 gettext               \u2506 &gt;=0.21.1,&lt;1.0a0 (RE of [host: gettext])      \u2502\n\u2502 freetype              \u2506 &gt;=2.12.1,&lt;3.0a0 (RE of [host: freetype])     \u2502\n\u2502 openjpeg              \u2506 &gt;=2.5.0,&lt;3.0a0 (RE of [host: openjpeg])      \u2502\n\u2502 libiconv              \u2506 &gt;=1.17,&lt;2.0a0 (RE of [host: libiconv])       \u2502\n\u2502 cairo                 \u2506 &gt;=1.18.0,&lt;2.0a0 (RE of [host: cairo])        \u2502\n\u2502 libpng                \u2506 &gt;=1.6.42,&lt;1.7.0a0 (RE of [host: libpng])     \u2502\n\u2502 libzlib               \u2506 &gt;=1.2.13,&lt;1.3.0a0 (RE of [host: zlib])       \u2502\n\u2502 libtiff               \u2506 &gt;=4.6.0,&lt;4.7.0a0 (RE of [host: libtiff])     \u2502\n\u2502 libjpeg-turbo         \u2506 &gt;=3.0.0,&lt;4.0a0 (RE of [host: libjpeg-turbo]) \u2502\n\u2502 libglib               \u2506 &gt;=2.78.3,&lt;3.0a0 (RE of [host: glib])         \u2502\n\u2502 libcxx                \u2506 &gt;=16 (RE of [build: clangxx_osx-arm64])      \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre> <p>You can also see \"linking\" information in the output, for example on macOS:</p> <pre><code>[lib/libpoppler-glib.8.26.0.dylib] links against:\n \u251c\u2500 @rpath/libgio-2.0.0.dylib\n \u251c\u2500 @rpath/libgobject-2.0.0.dylib\n \u251c\u2500 /usr/lib/libSystem.B.dylib\n \u251c\u2500 @rpath/libglib-2.0.0.dylib\n \u251c\u2500 @rpath/libpoppler.133.dylib\n \u251c\u2500 @rpath/libfreetype.6.dylib\n \u251c\u2500 @rpath/libc++.1.dylib\n \u251c\u2500 @rpath/libpoppler-glib.8.dylib\n \u2514\u2500 @rpath/libcairo.2.dylib\n</code></pre> <p><code>rattler-build</code> ensures that:</p> <ol> <li>All shared libraries linked against are present in the run dependencies. Missing libraries trigger an <code>overlinking</code> warning.</li> <li>You don't require any packages in the host that you are not linking against. This triggers an <code>overdepending</code> warning.</li> </ol>"},{"location":"tutorials/go/","title":"Packaging a Go package","text":"<p>This tutorial will guide you through making a Go package with <code>rattler-build</code>.</p> <p>When building a recipe for Go, most Go dependencies are linked statically. That means, we should collect their licenses and add them in the package. The <code>go-licenses</code> tool can help you with this task - as shown in the example below.</p>"},{"location":"tutorials/go/#the-different-go-compilers","title":"The different Go compilers","text":"<p>The <code>conda-forge</code> ecosystem provides two go compilers: <code>go-cgo</code> and <code>go-nocgo</code>.</p> <p>By default, if you do not need to link against C libraries, it's recommended to use the <code>go-nocgo</code> compiler. It generates fat binaries without libc dependencies. The compiler activation scripts will set your <code>CC</code>, <code>CXX</code> and related flags to invalid values.</p> <p>The <code>go-cgo</code> compiler can generate fat binaries that depend on conda-forge's libc. You should use this compiler if the underlying program needs to link against other C libraries, in which case make sure to add <code>${{ compiler('c') }}</code> (<code>cxx</code>, <code>fortran</code>, ...) for unix and the <code>m2w64</code> equivalent for windows.</p>"},{"location":"tutorials/go/#example-go-recipe","title":"Example Go recipe","text":"<p>This example shows how to package the Temporal CLI.</p> recipe.yaml<pre><code>context:\n    version: \"0.13.1\"\n\npackage:\n  name: temporal\n  version: ${{ version }}\n\nsource:\n  url: https://github.com/temporalio/cli/archive/refs/tags/v${{ version }}.tar.gz\n  sha256: 9d8812c96d3404490659fec3915dcd23c4142b421ef4cb7e9622bd9a459e1f74\n\nbuild:\n  number: 0\n\nrequirements:\n  build:\n    - ${{ compiler('go-nocgo') }}\n    - go-licenses\n\ntests:\n  - script:\n      - temporal --version\n\nabout:\n  homepage: https://temporal.io\n  repository: https://github.com/temporalio/cli\n  documentation: https://docs.temporal.io/cli\n  summary: Temporal CLI\n  description: |\n    Command-line interface for running Temporal Server and interacting with\n    Workflows, Activities, Namespaces, and other parts of Temporal.\n  license: MIT\n  license_file:\n    - LICENSE\n    # These license files are generated at build time in the `build.sh` script\n    # from all the dependencies of `temporal.io`.\n    - license-files/\n</code></pre> <p>The build script (on Unix) should look something like this:</p> build.sh<pre><code># The LDFLAGS are used to set the version of the `temporal` binary. This is a common practice in Go.\nexport LDFLAGS=\"${LDFLAGS} -s -w -X github.com/temporalio/cli/temporalcli.Version=${PKG_VERSION}\"\n\n# Build the `temporal` binary and store it in the `$PREFIX/bin` directory.\ngo build -ldflags \"$LDFLAGS\" -o $PREFIX/bin/temporal ./cmd/temporal\n\n# Store the license files in a separate directory in the $SRC_DIR. These are embedded in the package\n# in the `license_file` section.\ngo-licenses save ./cmd/temporal --save_path=\"$SRC_DIR/license-files/\" || true\n</code></pre>"},{"location":"tutorials/javascript/","title":"Packaging a Javascript (NPM/NodeJS) package","text":"<p>This tutorial will guide you though making a NodeJS package with <code>rattler-build</code>. Please note that, while packaging executable applications is possible, the conda ecosystem is not ideal for NPM libraries. NPM supports a number of features that cannot easily be modeled in the conda ecosystem, such as peer dependencies, optional dependencies, and the ability to install multiple versions of the same package.</p> <p>However, if you need to package a NodeJS application, <code>rattler-build</code> can help!</p>"},{"location":"tutorials/javascript/#building-a-nodejs-package","title":"Building a NodeJS Package","text":"<p>In this example, we will build a package for the NodeJS package <code>bibtex-tidy</code>. We use <code>nodejs</code> in build and run requirements, and install the package using <code>npm</code>. NPM comes as part of the NodeJS installation, so we do not need to install it separately.</p> recipe.yaml<pre><code>context:\n  version: \"1.14.0\"\n\npackage:\n  name: bibtex-tidy\n  version: ${{ version }}\n\nsource:\n  url: https://registry.npmjs.org/bibtex-tidy/-/bibtex-tidy-${{ version }}.tgz\n  sha256: 0a2c1bb73911a7cee36a30ce1fc86feffe39b2d39acd4c94d02aac6f84a00285\n  # we do not extract the source code and install the tarball directly as that works better\n  file_name: bibtex-tidy-${{ version }}.tgz\n\nbuild:\n  number: 0\n  script:\n    # we use NPM to globally install the bibtex-tidy package\n    - npm install -g bibtex-tidy-${{ version }}.tgz --prefix ${{ PREFIX }}\n\nrequirements:\n  build:\n    - nodejs\n  run:\n    - nodejs\n\ntests:\n  - script:\n    - bibtex-tidy --version\n</code></pre>"},{"location":"tutorials/perl/","title":"Packaging a Perl (CPAM) package","text":"<p>Packaging a Perl package is similar to packaging a Python package!</p>"},{"location":"tutorials/perl/#building-a-perl-package","title":"Building a Perl Package","text":""},{"location":"tutorials/perl/#a-perl-noarch-generic-package","title":"A perl <code>noarch: generic</code> package","text":"<p>The following recipe is for the Perl package <code>Call::Context</code>. We use <code>perl</code> in the <code>host</code> requirements, and install the package using <code>make</code>. The <code>noarch: generic</code> is used to indicate that the package is architecture-independent - since this is a pure Perl package, it can be installed and run on any platform (<code>noarch</code>).</p> recipe.yaml<pre><code>context:\n  version: 0.03\n\npackage:\n  name: perl-call-context\n  version: ${{ version }}\n\nsource:\n  url: https://cpan.metacpan.org/authors/id/F/FE/FELIPE/Call-Context-${{ version }}.tar.gz\n  sha256: 0ee6bf46bc72755adb7a6b08e79d12e207de5f7809707b3c353b58cb2f0b5a26\n\nbuild:\n  number: 0\n  noarch: generic\n  script:\n    - perl Makefile.PL INSTALLDIRS=vendor NO_PERLLOCAL=1 NO_PACKLIST=1\n    - make\n    - make test\n    - make install\n\nrequirements:\n  build:\n    - make\n  host:\n    - perl\n\ntests:\n  - perl:\n      uses:\n        - Call::Context\n\nabout:\n  license: GPL-1.0-or-later OR Artistic-1.0-Perl\n  summary: Sanity-check calling context\n  homepage: http://metacpan.org/pod/Call-Context\n</code></pre>"},{"location":"tutorials/perl/#a-perl-package-with-a-c-extension","title":"A perl package with a C extension","text":"<p>Some <code>perl</code> packages have native code extensions. In this example, we will build a package for the Perl package <code>Data::Dumper</code> using the <code>C</code> compiler. The <code>c</code> compiler and <code>make</code> are required at build time in the <code>build</code> requirements to compile the native code extension. We use <code>perl</code> in the <code>host</code> requirements, and install the package using <code>make</code>.</p> recipe.yaml<pre><code>context:\n  version: \"2.183\"\n\npackage:\n  name: \"perl-data-dumper\"\n  version: ${{ version }}\n\nsource:\n  url: https://cpan.metacpan.org/authors/id/N/NW/NWCLARK/Data-Dumper-${{ version }}.tar.gz\n  sha256: e42736890b7dae1b37818d9c5efa1f1fdc52dec04f446a33a4819bf1d4ab5ad3\n\nbuild:\n  number: 0\n  script:\n    - perl Makefile.PL INSTALLDIRS=vendor NO_PERLLOCAL=1 NO_PACKLIST=1\n    - make\n    - make test\n    - make install VERBINST=1\n\nrequirements:\n  build:\n    - ${{ compiler('c') }}\n    - make\n  host:\n    - perl\n    - perl-extutils-makemaker\n\ntests:\n  - perl:\n      uses:\n        - Data::Dumper\n\nabout:\n  homepage: https://metacpan.org/pod/Data::Dumper\n  license: GPL-1.0-or-later OR Artistic-1.0-Perl\n  summary: 'seeds germane, yet not germinated'\n</code></pre>"},{"location":"tutorials/python/","title":"Writing a Python package","text":"<p>Writing a Python package is fairly straightforward, especially for \"Python-only\" packages. In the second example we will build a package for <code>numpy</code> which contains compiled code.</p>"},{"location":"tutorials/python/#generating-a-starter-recipe","title":"Generating a starter recipe","text":"<p>Rattler-build provides a command to generate a recipe for a package from PyPI. The generated recipe can be used as a starting point for your recipe. The recipe generator will fetch the metadata from PyPI and generate a recipe that will build the package from the <code>sdist</code> source distriution.</p> <pre><code>rattler-build generate-recipe pypi ipywidgets\n# select an older version of the package\nrattler-build generate-recipe pypi ipywidgets --version 8.0.0\n</code></pre>"},{"location":"tutorials/python/#a-python-only-package","title":"A Python-only package","text":"<p>The following recipe uses the <code>noarch: python</code> setting to build a <code>noarch</code> package that can be installed on any platform without modification. This is very handy for packages that are pure Python and do not contain any compiled extensions.</p> <p>Additionally, <code>noarch: python</code> packages work with a range of Python versions (contrary to packages with compiled extensions that are tied to a specific Python version).</p> recipe.yaml<pre><code>context:\n  version: \"8.1.2\"\n\npackage:\n  name: ipywidgets\n  version: ${{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/i/ipywidgets/ipywidgets-${{ version }}.tar.gz\n  sha256: d0b9b41e49bae926a866e613a39b0f0097745d2b9f1f3dd406641b4a57ec42c9\n\nbuild:\n  noarch: python # (1)!\n  script: pip install . -v\n\nrequirements:\n  # note that there is no build section\n  host:\n    - pip\n    - python &gt;=3.7\n    - setuptools\n    - wheel\n  run:\n    - comm &gt;=0.1.3\n    - ipython &gt;=6.1.0\n    - jupyterlab_widgets &gt;=3.0.10,&lt;3.1.0\n    - python &gt;=3.7\n    - traitlets &gt;=4.3.1\n    - widgetsnbextension &gt;=4.0.10,&lt;4.1.0\n\ntests:\n  - python:\n      imports:\n        - ipywidgets # (2)!\n\nabout:\n  homepage: https://github.com/ipython/ipywidgets\n  license: BSD-3-Clause\n  license_file: LICENSE\n  summary: Jupyter Interactive Widgets\n  description: |\n    ipywidgets are interactive HTML widgets for Jupyter notebooks and the IPython kernel.\n  documentation: https://ipywidgets.readthedocs.io/en/latest/\n</code></pre> <ol> <li>The <code>noarch: python</code> line tells <code>rattler-build</code> that this package is pure    Python and can be one-size-fits-all. <code>noarch</code> packages can be installed on any    platform without modification which is very handy.</li> <li>The <code>imports</code> section in the tests is used to check that the package is    installed correctly and can be imported.</li> </ol>"},{"location":"tutorials/python/#running-the-recipe","title":"Running the recipe","text":"<p>To build this recipe, simply run:</p> <pre><code>rattler-build build --recipe ./ipywidgets\n</code></pre>"},{"location":"tutorials/python/#a-python-package-with-compiled-extensions","title":"A Python package with compiled extensions","text":"<p>We will build a package for <code>numpy</code> \u2013 which contains compiled code. Since compiled code is <code>python</code> version-specific, we will need to specify the <code>python</code> version explicitly.</p> <p>The best way to do this is with a \"variants.yaml\" file. The variant config file allows us to easily compile the package against multiple Python versions.</p> variants.yaml<pre><code>python:\n  - 3.11\n  - 3.12\n</code></pre> <p>This will replace any <code>python</code> found in the recipe with the versions specified in the <code>variants.yaml</code> file.</p> recipe.yaml<pre><code>context:\n  version: 2.0.1\n  default_abi_level: 1.21\n\npackage:\n  name: numpy\n  version: ${{ version }}\n\nsource:\n  - url: https://github.com/numpy/numpy/releases/download/v${{ version }}/numpy-${{ version }}.tar.gz\n    sha256: 485b87235796410c3519a699cfe1faab097e509e90ebb05dcd098db2ae87e7b3\n\nbuild:\n  python:\n    entry_points:\n      - f2py = numpy.f2py.f2py2e:main  # [win]\n      - numpy-config = numpy._configtool:main\n\nrequirements:\n  build:\n    - ${{ compiler('c') }}\n    - ${{ compiler('cxx') }}\n    # note: some `host` dependencies that run at build time (e.g., `cython`, `meson-python`)\n    #       should ideally be in `build` instead, this is because cross compilation of\n    #       Python packages in conda-forge uses `crossenv` rather than regular cross compilation.\n  host:\n    # note: variant is injected here!\n    - python\n    - pip\n    - meson-python\n    - pkg-config\n    - python-build\n    - cython\n    - libblas\n    - libcblas\n    - liblapack\n  run:\n    - python\n  run_exports:\n    - numpy &gt;=${{ default_abi_level }},&lt;3.0.0a0\n\ntests:\n  - python:\n      imports:\n        - numpy\n        - numpy.fft\n        - numpy.linalg\n        - numpy.random\n        - numpy.ctypeslib\n\n  - script:\n    - f2py -v\n    - numpy-config --cflags\n\nabout:\n  homepage: http://numpy.org/\n  license: BSD-3-Clause\n  license_file: LICENSE.txt\n  summary: The fundamental package for scientific computing with Python.\n  documentation: https://numpy.org/doc/stable/\n  repository: https://github.com/numpy/numpy\n</code></pre> <p>The build script for Unix:</p> build.sh<pre><code>mkdir builddir\n\n$PYTHON -m build -w -n -x \\\n    -Cbuilddir=builddir \\\n    -Csetup-args=-Dblas=blas \\\n    -Csetup-args=-Dlapack=lapack\n\n$PYTHON -m pip install dist/numpy*.whl\n</code></pre> <p>The build script for Windows:</p> build.bat<pre><code>mkdir builddir\n\n%PYTHON% -m build -w -n -x ^\n    -Cbuilddir=builddir ^\n    -Csetup-args=-Dblas=blas ^\n    -Csetup-args=-Dlapack=lapack\nif %ERRORLEVEL% neq 0 exit 1\n\n:: `pip install dist\\numpy*.whl` does not work on windows,\n:: so use a loop; there's only one wheel in dist/ anyway\nfor /f %%f in ('dir /b /S .\\dist') do (\n    pip install %%f\n    if %ERRORLEVEL% neq 0 exit 1\n)\n</code></pre>"},{"location":"tutorials/python/#running-the-recipe_1","title":"Running the recipe","text":"<p>Running this recipe with the variant config file will build a total of 2 <code>numpy</code> packages:</p> <pre><code>rattler-build build --recipe ./numpy\n</code></pre> <p>At the beginning of the build process, <code>rattler-build</code> will print the following message to show you the variants it found:</p> <pre><code>Found variants:\n\nnumpy-1.26.4-py311h5f8ada8_0\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Variant         \u2506 Version   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 python          \u2506 3.11      \u2502\n\u2502 target_platform \u2506 osx-arm64 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n\nnumpy-1.26.4-py312h440f24a_0\n\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 Variant         \u2506 Version   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 python          \u2506 3.12      \u2502\n\u2502 target_platform \u2506 osx-arm64 \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"tutorials/python/#an-abi3-compatible-package","title":"An ABI3-compatible package","text":"<p>Certain packages contain compiled code that is compatible with multiple Python versions. This is the case e.g. for a lot of Rust / PyO3 based Python extensions.</p> <p>In this case, you can use the special <code>abi3</code> settings to build a package that is specific to a certain operating system and architecture, but compatible with multiple Python versions.</p> <p>Note: this feature relies on the <code>python-abi3</code> package which exists in the <code>conda-forge</code> channel. The full recipe can be found on <code>conda-forge/py-rattler-feedstock</code></p> recipe.yaml<pre><code>context:\n  name: py-rattler\n  python_name: py_rattler\n  version: \"0.11.0\"\n  python_min: \"3.8\"\n\npackage:\n  name: py-rattler\n  version: ${{ version }}\n\nsource:\n  url: https://pypi.org/packages/source/${{ name[0] }}/${{ name }}/${{ python_name }}-${{ version }}.tar.gz\n  sha256: b00f91e19863741ce137a504eff3082c0b0effd84777444919bd83357530867f\n\nbuild:\n  number: 0\n  script: build.sh\n  python:\n    version_independent: true\n\nrequirements:\n  build:\n    - ${{ compiler('c') }}\n    - ${{ compiler('rust') }}\n    - cargo-bundle-licenses\n  host:\n    - python      ${{ python_min }}.*\n    - python-abi3 ${{ python_min }}.*  # (1)!\n    - maturin &gt;=1.2.2,&lt;2\n    - pip\n    - if: unix\n      then:\n        - openssl\n  run:\n    - python &gt;=${{ python_min }}\n\ntests:\n  - python:\n      imports:\n        - rattler\n      python_version: [\"${{ python_min ~ '.*' }}\"]  # (2)!\n  # You could run `abi3audit` here, but it is not necessary\n  # - script:\n  #     - abi3audit ${{ SP_DIR }}/spam.abi3.so -s -v --assume-minimum-abi3 ${{ python_min }}\n  #   requirements:\n  #     run:\n  #       - abi3audit\n\nabout:\n  homepage: https://github.com/conda/rattler\n  license: BSD-3-Clause\n  license_file:\n    - LICENSE\n    - py-rattler/THIRDPARTY.yml\n  summary: A blazing fast library to work with the conda ecosystem\n  description: |\n    Rattler is a library that provides common functionality used within the conda\n    ecosystem. The goal of the library is to enable programs and other libraries to\n    easily interact with the conda ecosystem without being dependent on Python. Its\n    primary use case is as a library that you can use to provide conda related\n    workflows in your own tools.\n  repository: https://github.com/conda/rattler\n</code></pre> <ol> <li>The <code>python-abi3</code> package is a special package that ensures that the   run dependencies    are compatible with the ABI3 standard.</li> <li>The <code>python_version</code> setting is used to test against the oldest compatible Python version.</li> </ol>"},{"location":"tutorials/python/#testing-python-packages","title":"Testing Python packages","text":"<p>Testing Python packages is done using the <code>tests</code> section of the recipe. We can either use a special \"python\" test or a regular script test to test the package.</p> <p>All tests will have the current package and all it's run dependencies installed in an isolated environment.</p> recipe.yaml<pre><code># contents of the recipe.yaml file\ntests:\n  - python:\n      # The Python test type will simply import packages as a sanity check.\n      imports:\n        - rattler\n        - rattler.version.Version\n      pip_check: true # (4)!\n      # You can select different Python versions to test against.\n      python_version: [\"${{ python_min ~ '.*' }}\", \"3.12.*\"]  # (1)!\n\n  # You can run a script test to run arbitrary code.\n  - script:\n      - pytest ./tests\n    requirements:  # (2)!\n      run:\n         - pytest\n    files:  # (3)!\n      source:\n        - tests/\n  # You can also directly execute a Python script and run some tests from it.\n  # The script is searched in the `recipe` directory.\n  - script: mytest.py\n</code></pre> <ol> <li>The <code>python_version</code> setting is used to test against different Python versions. It is useful to test against the minimum version of Python that the package supports.</li> <li>We can add additional requirements for the test run. such as pytest, pytest-cov, ... \u2013 you can also specify a <code>python</code> version here by adding e.g. <code>python 3.12.*</code> to the run requirements.</li> <li>This will copy over the tests from the source directory into the package. Note that this makes the package larger, so you might want to use a different approach for larger packages.</li> <li>The <code>pip_check</code> will run <code>pip check</code> in the environment to make sure that all dependencies are installed correctly. By default, this is set to <code>true</code>.</li> </ol>"},{"location":"tutorials/r/","title":"Packaging a R (CRAN) package","text":"<p>Packaging a R package is similar to packaging a Python package!</p>"},{"location":"tutorials/r/#generating-a-starting-point","title":"Generating a starting point","text":"<p>You can use rattler-build to generate a starting point for your recipe from the metadata on CRAN.</p> <pre><code>rattler-build generate-recipe cran r-knitr\n</code></pre>"},{"location":"tutorials/r/#building-a-r-package","title":"Building a R Package","text":"recipe.yaml<pre><code>context:\n  version: \"1.47\"\n\npackage:\n  name: r-knitr\n  version: ${{ version }}\n  noarch: generic  # (4)!\n\nsource:\n- url: https://cran.r-project.org/src/contrib/Archive/knitr/knitr_${{ version }}.tar.gz\n  sha256: fadd849bf94a4e02520088a6626577c3c636227fe11c5cd7e8fcc5d51a7aa6cf\n\nbuild:\n  script: R CMD INSTALL --build .  # (1)!\n\nrequirements:\n  host:\n  - r-base  # (2)!\n  - r-evaluate &gt;=0.15\n  - r-highr &gt;=0.11\n  - r-xfun &gt;=0.44\n  - r-yaml &gt;=2.1.19\n  run:\n  - r-base\n  - r-evaluate &gt;=0.15\n  - r-highr &gt;=0.11\n  - r-xfun &gt;=0.44\n  - r-yaml &gt;=2.1.19\n\ntests:\n# This is a shorthand test for R packages to ensure that the library loads correctly.\n- r:\n    libraries:\n      - knitr\n# You can also run arbitrary R code in the test section.\n- script: test_package.R  # (3)!\n\nabout:\n  homepage: https://yihui.org/knitr/\n  summary: A General-Purpose Package for Dynamic Report Generation in R\n  description: |-\n    Provides a general-purpose tool for dynamic report\n    generation in R using Literate Programming techniques.\n  license: GPL-2.0\n  repository: https://github.com/cran/knitr\n</code></pre> <ol> <li>The <code>script</code> section is where you specify the build commands to run. In this case, we are using <code>R CMD INSTALL --build .</code> to build the package.</li> <li>The <code>r-base</code> package is required to run R and is specified in the <code>host</code> requirements.</li> <li>The <code>script</code> key automatically detects the language based on the file extension. In the case of <code>.R</code>, it will execute the R script with <code>rscript</code>.</li> <li>The <code>noarch: generic</code> directive indicates that the package is architecture-independent. This is useful for R packages that do not contain compiled code and can run on any architecture. It allows the package to be installed on any platform without needing to rebuild it for each architecture.</li> </ol>"},{"location":"tutorials/repackaging/","title":"Repackaging existing software","text":"<p>It's totally possible to repackage existing software using rattler-build, and make it easy to install with conda, mamba or pixi.</p> <p>Repackaging existing binaries is not recommended on <code>conda-forge</code>, but totally acceptable for your own channels / repositories.</p>"},{"location":"tutorials/repackaging/#example-for-linkerd","title":"Example for <code>linkerd</code>","text":"<p>This example shows how to repackage the <code>linkerd</code> binary. The <code>linkerd</code> binary is a command line tool that is used to manage and monitor Kubernetes clusters, and a pre-built binary is available for download from Github releases. Alternatively, you could also follow the Go packaging tutorial to build linkerd from source!</p> <pre><code>package:\n  name: linkerd\n  version: 25.5.2\n\nsource:\n  - if: target_platform == \"linux-64\"\n    then:\n      url: https://github.com/linkerd/linkerd2/releases/download/edge-25.5.2/linkerd2-cli-edge-25.5.2-linux-amd64\n      sha256: 55e7721ab0eb48217f239628b55517b7d663a962df18cdab180e5d42e45f83cb\n      file_name: linkerd\n  - if: target_platform == \"osx-arm64\"\n    then:\n      url: https://github.com/linkerd/linkerd2/releases/download/edge-25.5.2/linkerd2-cli-edge-25.5.2-darwin-arm64\n      sha256: 405ddf3af0089bfece93d811c9bfb9f63e3a000e3f423163fc56690ef4d427cf\n      file_name: linkerd\n  # To support other platforms you can add more `if` statements here\n\nbuild:\n  script:\n    # make linkerd binary executable\n    - chmod +x linkerd\n    # make sure that the `$PREFIX/bin` directory exists\n    - mkdir -p $PREFIX/bin\n    # move or copy the binary to the `$PREFIX/bin` directory\n    - mv linkerd $PREFIX/bin/\n\ntests:\n  - script:\n      - linkerd version\n      # you can add more tests here\n\nabout:\n  homepage: https://linkerd.io/\n  license: Apache-2.0\n  summary: Linkerd is an ultralight service mesh for Kubernetes.\n  description: |\n    Linkerd is an ultralight service mesh for Kubernetes.\n    It adds observability, reliability, and security to your\n    applications without requiring any code changes.\n    Linkerd is open source and free to use.\n  # Note: since we are downloading a binary, we don't have a license file.\n  # You can put the license in the recipe directory, and it will be picked up from there.\n  license_file: LICENSE\n  # documentation: ...\n  repository: https://github.com/linkerd/linkerd2\n</code></pre> <p>Note</p> <p>To repackage the <code>linkerd</code> package on <code>osx-arm64</code> for <code>linux-64</code>, you can pass the <code>--target-platform</code> argument to <code>rattler-build</code>:</p> <pre><code>rattler-build build --target-platform linux-64 linkerd\n</code></pre>"},{"location":"tutorials/repackaging/#adding-system-requirements","title":"Adding system requirements","text":"<p>Some packages have system requirements (e.g. on <code>glibc</code> on Linux, or the macOS SDK on macOS).</p> <p>You can add system requirements like this to the <code>run</code> section by depending on virtual packages:</p> <pre><code>requirements:\n  run:\n    - ${{ \"__glibc &gt;=2.17\" if linux }}\n    - ${{ \"__osx &gt;=10.15\" if osx }}\n</code></pre>"},{"location":"tutorials/rust/","title":"Building a Rust package","text":"<p>We're using <code>rattler-build</code> to build a Rust package for the <code>cargo-edit</code> utility. This utility manages Cargo dependencies from the command line.</p> recipe.yaml<pre><code>context:\n  version: \"0.11.9\"\n\npackage:\n  name: cargo-edit\n  version: ${{ version }}\n\nsource:\n  url: https://github.com/killercup/cargo-edit/archive/refs/tags/v${{ version }}.tar.gz\n  sha256: 46670295e2323fc2f826750cdcfb2692fbdbea87122fe530a07c50c8dba1d3d7\n\nbuild:\n  script:\n    - cargo-bundle-licenses --format yaml --output ${SRC_DIR}/THIRDPARTY.yml  # !(1)\n    - $BUILD_PREFIX/bin/cargo install --locked --bins --root ${PREFIX} --path .\n\nrequirements:\n  build:\n    - ${{ compiler('rust') }}\n    - cargo-bundle-licenses\n\ntests:\n  - script:\n      - cargo-upgrade --help # !(2)\n\nabout:\n  homepage: https://github.com/killercup/cargo-edit\n  license: MIT\n  license_file:\n    - LICENSE\n    - THIRDPARTY.yml\n  description: \"A utility for managing cargo dependencies from the command line.\"\n  summary: \"A utility for managing cargo dependencies from the command line.\"\n</code></pre> <p>Note</p> <p>The <code>${{ compiler(...) }}</code> functions are very useful in the context of cross-compilation. When the function is evaluated it will insert the correct compiler (as selected with the variant config) as well the <code>target_platform</code>. The \"rendered\" compiler will look like <code>rust_linux-64</code> when you are targeting the <code>linux-64</code> platform.</p> <p>You can read more about this in the cross-compilation section.</p> <ol> <li>The <code>cargo-bundle-licenses</code> utility is used to bundle all the licenses of the dependencies into a <code>THIRDPARTY.yml</code> file.    This file is then included in the package. You should always include this file in your package when you are redistributing it.</li> <li>Running scripts in <code>bash</code> or <code>cmd.exe</code> to test the package build well, expects an exit code of <code>0</code> to pass the test.</li> </ol> <p>To build this recipe, simply run:</p> <pre><code>rattler-build build \\\n    --recipe ./cargo-edit/recipe.yaml\n</code></pre>"}]}